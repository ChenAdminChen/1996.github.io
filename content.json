{"meta":{"title":"chen","subtitle":null,"description":null,"author":"chen","url":"https://chenadminchen.github.io"},"pages":[{"title":"About","date":"2019-07-06T08:45:58.790Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"about/index.html","permalink":"https://chenadminchen.github.io/about/index.html","excerpt":"","text":""},{"title":"测试","date":"2019-07-06T08:45:58.790Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"categories/index.html","permalink":"https://chenadminchen.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2019-07-06T08:45:58.790Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"tags/index.html","permalink":"https://chenadminchen.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"consul-upsync-nginx","slug":"consul-upsync-nginx","date":"2020-02-10T14:35:34.000Z","updated":"2020-02-14T09:25:05.924Z","comments":true,"path":"2020/02/10/consul-upsync-nginx/","link":"","permalink":"https://chenadminchen.github.io/2020/02/10/consul-upsync-nginx/","excerpt":"","text":"consul-upsync-nginx如果 Nginx 遇到大流量和高负载，修改配置文件重启可能并不总是那么方便，因为恢复 Nginx 并重载配置会进一步增加系统负载，并很可能暂时降低性能。而一个个修改配置文件也是很容易出错和费时间的操作。consul+nginx-upsync-module 实现 Nginx 的动态负载。 consulinstall consuldownload: https://www.consul.io/downloads.html start consul script1&gt;./consul agent -dev stop consul script1&gt;./consul stop reload consul script1&gt;./consul reload stop consulscript1./consul leave UIui web address: http://localhost:8500/ http api add servicecurl -X PUT http://192.168.212.131:8500/v1/catalog/register json body:1234567&#123;\"Datacenter\": \"dc1\", \"Node\":\"tomcat\", \"Address\":\"192.168.5.165\", \"Service\": &#123; \"Id\" :\"192.168.5.165:8080\", \"Service\": \"itmayiedu\",\"tags\": [\"dev\"], \"Port\": 8080 &#125;&#125; Datacenter指定数据中心，Address指定服务IP，Service.Id指定服务唯一标识，Service.Service指定服务分组，Service.tags指定服务标签（如测试环境、预发环境等），Service.Port指定服务端口。 ui web address: http://localhost:8500/ui/dc1/services http api add key/valuecurl -X PUT http://127.0.0.1:8500/v1/kv/upstreams/tcp/127.0.0.1:6662 ui web address: http://localhost:8500/ui/dc1/kv/upstreams add service configuration file in consulref: https://learn.hashicorp.com/consul/getting-started/services script12345678910&gt;mkdir ./consul.d&gt;echo '&#123;\"service\": &#123;\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80 &#125; &#125;' &gt; ./consul.d/web.json&gt;./consul agent -dev -config-dir=./consul.d nginx-upsync-module nginx version nginx version is 1.14.0 nginx-stream-upsync-module version nginx-stream-upsync-module version is 1.2.2 nginx-upsync-modul version nginx-upsync-modul version is 2.1.2 afresh configuration nginx from github clone nginx-stream-upsync-module: https://github.com/xiaokai-wang/nginx-stream-upsync-module/releasesfrom github clone nginx-upsync-module: https://github.com/weibocom/nginx-upsync-module/releases script123456nginx-1.14.0&gt; mkdir addonsnginx-1.14.0&gt;mv nginx-stream-upsync-module addnos/nginx-1.14.0&gt;mv nginx-upsync-module addons/# --with-stream is not dynamicnginx-1.14.0&gt;./configure --with-cc-opt='-g -O2 -fdebug-prefix-map=/build/nginx-GkiujU/nginx-1.14.0=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -Wdate-time -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -fPIC' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --modules-path=/usr/lib/nginx/modules --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_v2_module --with-http_dav_module --with-http_slice_module --with-threads --with-http_addition_module --with-http_geoip_module=dynamic --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module=dynamic --with-http_sub_module --with-http_xslt_module=dynamic --with-stream_ssl_module --with-mail=dynamic --with-mail_ssl_module --with-stream_realip_module --without-http_rewrite_module --add-module=addons/nginx-upsync-module-2.1.2 --add-module=addons/nginx-stream-upsync-module-1.2.2 --with-stream make &amp;&amp; make install configuration file ++ http upstreamupsteram name is web in consul nano /etc/nginx/sites-available/defaultscript1234567upstream backend &#123; server 127.0.0.1:3001; server 127.0.0.1:3002; upsync 127.0.0.1:8500/v1/kv/upstreams/web upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/servers/servers_test.con;&#125; ++ tcp upstream upsteram name is tcp in consul nano /etc/nginx/nginx.conf script123456789101112131415161718192021222324user www-data;worker_processes auto;pid /run/nginx.pid;include /etc/nginx/modules-enabled/*.conf;stream &#123; upstream tcpserver &#123; server 127.0.0.1:6661; server 127.0.0.1:6662; upsync 127.0.0.1:8500/v1/kv/upstreams/tcp upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/servers/servers_tcp.con; &#125; server &#123; listen 7777; proxy_connect_timeout 10s; proxy_timeout 5m; proxy_pass tcpserver; &#125; &#125; reload nginx","categories":[],"tags":[{"name":"consul","slug":"consul","permalink":"https://chenadminchen.github.io/tags/consul/"},{"name":"upsync","slug":"upsync","permalink":"https://chenadminchen.github.io/tags/upsync/"},{"name":"nginx","slug":"nginx","permalink":"https://chenadminchen.github.io/tags/nginx/"}]},{"title":"nginx","slug":"nginx","date":"2020-02-10T14:35:34.000Z","updated":"2020-02-14T07:42:24.440Z","comments":true,"path":"2020/02/10/nginx/","link":"","permalink":"https://chenadminchen.github.io/2020/02/10/nginx/","excerpt":"","text":"nginxnginx学习地址: http://nginx.org/ install nginxfirst methodscript1chen&gt;sudo apt install nginx second methoddownload: http://nginx.org/en/download.html example: nginx-1.14.0 configuration module script12nginx-1.14.0&gt;./configure --with-cc-opt='-g -O2 -fdebug-prefix-map=/build/nginx-GkiujU/nginx-1.14.0=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -Wdate-time -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -fPIC' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --modules-path=/usr/lib/nginx/modules --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_v2_module --with-http_dav_module --with-http_slice_module --with-threads --with-http_addition_module --with-http_geoip_module=dynamic --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module=dynamic --with-http_sub_module --with-http_xslt_module=dynamic --with-stream=static --with-stream_ssl_module --with-mail=dynamic --with-mail_ssl_module --with-stream_realip_module --without-http_rewrite_module make script1nginx-1.14.0&gt;make make install script123nginx-1.14.0&gt;sudo make installnginx-1.14.0&gt; ll /usr/share/nginx nginx informationscript1234567nginx-1.14.0&gt;./objs/nginx -Vnginx version: nginx/1.14.0built by gcc 7.4.0 (Ubuntu 7.4.0-1ubuntu1~18.04.1) built with OpenSSL 1.1.1 11 Sep 2018TLS SNI support enabledconfigure arguments: --with-cc-opt='-g -O2 -fdebug-prefix-map=/build/nginx-GkiujU/nginx-1.14.0=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -Wdate-time -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-z,now -fPIC' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --modules-path=/usr/lib/nginx/modules --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_v2_module --with-http_dav_module --with-http_slice_module --with-threads --with-http_addition_module --with-http_geoip_module=dynamic --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module=dynamic --with-http_sub_module --with-http_xslt_module=dynamic --with-stream=dynamic --with-stream_ssl_module --with-mail=dynamic --with-mail_ssl_module --with-stream_realip_module nginx start/stop/reloadscript12345nginx-1.14.0&gt;./objs/nginx #startnginx-1.14.0&gt;./objs/nginx -s stop #stopnginx-1.14.0&gt;./objs/nginx -s reload #reload nginx http load-balancingconfiguration default.confscript123456789101112131415161718192021222324252627nginx-1.14.0&gt;cat /etc/nginx/sites-available/defaultserver &#123; listen 80 default_server; listen [::]:80 default_server; # root /var/www/html; # Add index.php to the list if you are using PHP# index index.html index.htm index.nginx-debian.html; server_name _; location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. proxy_pass http://backend;# try_files $uri $uri/ =404; &#125;&#125;upstream backend &#123; server 127.0.0.1:3001; server 127.0.0.1:3002;&#125; nginx tcp/udp load-balancingTCP/UDP load-balancing use stream at nginx 1.9.0 version or last version nginx add ngx-stream-core-module, it config –with-stream=dynamic script1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465nginx-1.14.0&gt;cat /etc/nginx/nginx.confuser www-data;worker_processes auto;pid /run/nginx.pid;include /etc/nginx/modules-enabled/*.conf;# load ngx_stream_module.soload_module /usr/lib/nginx/modules/ngx_stream_module.so;...stream &#123;# 默认的方式: 轮询的方式 upstream tcpserver &#123; server 127.0.0.1:6661; server 127.0.0.1:6662; server 127.0.0.1:6663; &#125;# least_conn 最少连接数配置,采用一种固定的负载策略,最少连接数策略,也就是选择连接数最少的后台服务 upstream tcpserver_least_conn &#123; least_conn; server 127.0.0.1:6664; server 127.0.0.1:6665; server 127.0.0.1:6666; &#125;# 权轮询配置,在轮询策略的基础上给每个后台服务加上权重，权重越大，访问的概率越大 upstream tcpserver_weight &#123; server 127.0.0.1:6667 weight=5; server 127.0.0.1:6668; server 127.0.0.1:6669; &#125;# 最低平均延时配置(商业订阅的一部分提供)#上面策略配置表示的是对于每个请求，可通过最低平均延时来选择后台服务，而这个最低平均延时则是看 least_time 指令中指定的参数计算出来的，主要有下面三个参数： # connect：连接到后台服务花的时间# first_byte：接收到第一个字节花的时间# last_byte：接收到最后一个字节花的时间，也就是全部接收完的时间 upstream tcpserver_least_time &#123; hash $remote_addr consistent; server 127.0.0.1:6670; server 127.0.0.1:6671; server 127.0.0.1:6672; &#125;# 采用的是 hash 算法策略，对客户端的 IP 进行 hash，让每台客户端固定访问到后台的一台服务。 upstream tcpserver_hash &#123; hash $remote_addr consistent; server 127.0.0.1:6673; server 127.0.0.1:6674; server 127.0.0.1:6675; &#125; server &#123; listen 7777; proxy_connect_timeout 10s; proxy_timeout 5m; proxy_pass tcpserver; &#125; &#125; nginx configuration testscript1234nginx-1.14.0&gt;sudo ./objs/nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful nginx平滑添加模块1、先查看nginx版本和已支持的模块2、官网下载相同版本nginx3、添加模块,重复 nginx http load-balancing4、编译成功后make，记住千万不要make install,这样会覆盖你以前的nginx5、备份nginx script1mv /usr/local/nginx /usr/local/nginx.bak 6、复制编译目录下的nginx启动文件 script1cp ./objs/nginx /usr/local/nginx/sbin/ 7、启动测试script1./nginx - 8、重启script1./nginx -s reload nginx learn addressref1: https://ciphertrick.com/load-balancing-apis-using-nginx-with-example/ref2: http://nginx.org/en/docs/stream/stream_processing.htmlref3: http://rookiezhou.top/nginx-%E5%AE%9E%E7%8E%B0-TCP-%E4%BB%A3%E7%90%86%E5%8F%8A%E5%85%B6%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B9%8B-stream-%E6%A8%A1%E5%9D%97/ref4: https://bVlog.csdn.net/slovyz/article/details/53839488","categories":[],"tags":[{"name":"load balancing","slug":"load-balancing","permalink":"https://chenadminchen.github.io/tags/load-balancing/"},{"name":"proxy","slug":"proxy","permalink":"https://chenadminchen.github.io/tags/proxy/"}]},{"title":"linux-crontab","slug":"linux-crontab","date":"2019-12-17T02:35:34.000Z","updated":"2020-02-10T13:02:20.551Z","comments":true,"path":"2019/12/17/linux-crontab/","link":"","permalink":"https://chenadminchen.github.io/2019/12/17/linux-crontab/","excerpt":"","text":"linux 定时任务定时执行的任务 automatic-refund.shscript123456789101112#!/bin/bash#获取系统当前时间start=`date -d yesterday +\"%Y-%m-%d\"`end=`date -d today +\"%Y-%m-%d %H:%M:%S\"`echo $&#123;start&#125; - $&#123;end&#125;result=`curl -X POST 'http://localhost:8080/automatic-refund?start='+$&#123;start&#125;+'&amp;end='+$&#123;end&#125; -H 'Content-Type: application/json' -v`# curl -d \"start=$&#123;start&#125;&amp;end=$&#123;end&#125;\" http://localhost:8080/automatic-refund -v#输出日志到日志文件echo $&#123;end&#125;:$&#123;result&#125; &gt;&gt; /home/chen/work/autorefund.log 设定定时器 crontab -escript123456789101112131415161718192021222324252627282930# Edit this file to introduce tasks to be run by cron.# # Each task to run has to be defined through a single line# indicating with different fields when the task will be run# and what command to run for the task# # To define the time you can provide concrete values for# minute (m), hour (h), day of month (dom), month (mon),# and day of week (dow) or use '*' in these fields (for 'any').# # Notice that tasks will be started based on the cron's system# daemon's notion of time and timezones.# # Output of the crontab jobs (including errors) is sent through# email to the user the crontab file belongs to (unless redirected).# # For example, you can run a backup of all your user accounts# at 5 a.m every week with:# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/# # For more information see the manual pages of crontab(5) and cron(8)# # m h dom mon dow command#基本格式 :#* * * * * command#分 时 日 月 周 命令#脚本所在的位置 写绝对路径最好#每天的15点 35分 35 15 * * * bash /home/chen/work/automatic-refund.sh 查看定时任务 crontab -l 错误解决若定时任务设定好后，没有按设定的执行时，可检查系统时间是否存在不一致的问题","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/tags/linux/"}]},{"title":"mongodb","slug":"install-mongodb","date":"2019-12-16T09:35:34.000Z","updated":"2020-02-10T13:02:20.535Z","comments":true,"path":"2019/12/16/install-mongodb/","link":"","permalink":"https://chenadminchen.github.io/2019/12/16/install-mongodb/","excerpt":"","text":"install mongodbinstall address configuration /etc/mongodb.confscript1234567891011121314151617181920212223242526272829303132333435363738394041424344# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/# where to write logging data.systemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.log# Where and how to store data.storage: dbPath: /var/lib/mongo journal: enabled: true# engine:# wiredTiger:# how the process runsprocessManagement: fork: true # fork and run in background pidFilePath: /var/run/mongodb/mongod.pid # location of pidfile timeZoneInfo: /usr/share/zoneinfo# network interfacesnet: port: 27017 #bindIp: 127.0.0.1 bindIp: 0.0.0.0 # Enter 0.0.0.0,:: to bind to all IPv4 and IPv6 addresses or, alternatively, use the net.bindIpAll setting.#security:# authorization: 'enabled'#operationProfiling:#replication:#sharding:## Enterprise-Only Options#auditLog:#snmp: mongodb install address script1&gt;whereis mongo start mongodb script123sudo service mongod startsystemctl start mongod.service stop mongodb script123sudo service mongod stopsystemctl stop mongod.service mongodb listener script1netstat -anp |grep 27017 mongodb clientmongodb client download","categories":[],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/tags/mongodb/"}]},{"title":"big-data-hbase-hive","slug":"big-data-hbase-hive","date":"2019-11-25T07:35:34.000Z","updated":"2020-02-10T13:02:20.535Z","comments":true,"path":"2019/11/25/big-data-hbase-hive/","link":"","permalink":"https://chenadminchen.github.io/2019/11/25/big-data-hbase-hive/","excerpt":"","text":"hbase-hivelearn address hbase table information describe ‘f’123456Table f is ENABLED f COLUMN FAMILIES DESCRIPTION &#123;NAME =&gt; 'f', VERSIONS =&gt; '1', EVICT_BLOCKS_ON_CLOSE =&gt; 'false', NEW_VERSION_BEHAVIOR =&gt; 'false', KEEP_DELETED_CELLS =&gt; 'FALSE', CACHE_DATA_ON_WRITE =&gt; 'false', DATA_BLOCK_ENCODING =&gt; 'NONE', TTL =&gt; 'FOREVER', MIN_VERSIONS =&gt; '0', REPLICATION_SCOPE =&gt; '0', BLOOMFILTER =&gt; 'ROW', CACHE_INDEX_ON_WRITE =&gt; 'false', IN_MEMORY =&gt; 'false', CACHE_BLOOMS_ON_WRITE =&gt; 'false', PREFETCH_BLOCKS_ON_OPEN =&gt; 'false', COMPRESSION =&gt; 'NONE', BLOCKCACHE =&gt; 'true', BLOCKSIZE =&gt; '65536'&#125; scan ‘f’1234ROW COLUMN+CELL row1 column=f:name, timestamp=1574480231593, value=chen row2 column=f:age, timestamp=1574660750499, value=11 row3 column=f:name, timestamp=1574666237806, value=kevin put12put &apos;f&apos;,&apos;row6&apos;,&apos;f:age&apos;,34put &apos;f&apos;,&apos;row6&apos;,&apos;f:name&apos;,&apos;qi&apos; scan ‘f’ 12345678910ROW COLUMN+CELL row1 column=f:name, timestamp=1574480231593, value=chen row2 column=f:age, timestamp=1574660750499, value=11 row3 column=f:name, timestamp=1574666237806, value=kevin row4 column=f:age, timestamp=1574668813422, value=12 row4 column=f:name, timestamp=1574668813422, value=test row5 column=f:age, timestamp=1574669091951, value=13 row5 column=f:name, timestamp=1574669091951, value=li row6 column=f:age, timestamp=1574672582983, value=34 row6 column=f:name, timestamp=1574672608454, value=qi hivehive table information from hbase create ‘hive_f’12345CREATE EXTERNAL TABLE hive_f(id string, value string,age int) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES (\"hbase.columns.mapping\" = \":key,f:name,f:age\")TBLPROPERTIES(\"hbase.table.name\" = \"f\", \"hbase.mapred.output.outputtable\" = \"f\"); select * from hive_f123row1 chen NULLrow2 NULL 11row3 kevin NULL insert into hive_f(id,value,age) values(‘row4’,’test’,12) error 12345678910111213141516Application Timeout (Remaining Time): UnlimitedDiagnostics: Application application_1574645197988_0001 failed 2 times due to AM Container for appattempt_1574645197988_0001_000002 exited with exitCode: 1Failing this attempt.Diagnostics: [2019-11-25 15:33:38.304]Exception from container-launch.Container id: container_1574645197988_0001_02_000001Exit code: 1[2019-11-25 15:33:38.306]Container exited with a non-zero exit code 1. Error file: prelaunch.err.Last 4096 bytes of prelaunch.err :Last 4096 bytes of stderr :错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster[2019-11-25 15:33:38.307]Container exited with a non-zero exit code 1. Error file: prelaunch.err.Last 4096 bytes of prelaunch.err :Last 4096 bytes of stderr :错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMasterFor more detailed output, check the application tracking page: http://localhost:8088/cluster/app/application_1574645197988_0001 Then click on links to logs of each attempt.. Failing the application. fix (configuration hadoop) + get hadoop classpath./bin/hadoop classpath 123456/home/chen/work/service/hadoop-3.0.0/etc/hadoop:/home/chen/work/service/hadoop-3.0.0/share/hadoop/common/lib/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/common/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/hdfs:/home/chen/work/service/hadoop-3.0.0/share/hadoop/hdfs/lib/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/hdfs/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/mapreduce/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/yarn:/home/chen/work/service/hadoop-3.0.0/share/hadoop/yarn/lib/*:/home/chen/work/service/hadoop-3.0.0/share/hadoop/yarn/* configuration hadoop mapred-site.xml 1234&lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_HOME/share/hadoop/mapreduce/*&lt;/value&gt;&lt;/property&gt; hbase scan ‘f’ 123456789ROW COLUMN+CELL row1 column=f:name, timestamp=1574480231593, value=chen row2 column=f:age, timestamp=1574660750499, value=11 row3 column=f:name, timestamp=1574666237806, value=kevin row4 column=f:age, timestamp=1574668813422, value=12 row4 column=f:name, timestamp=1574668813422, value=test row5 column=f:age, timestamp=1574669091951, value=13 row5 column=f:name, timestamp=1574669091951, value=li 5 row(s)","categories":[],"tags":[{"name":"big-data","slug":"big-data","permalink":"https://chenadminchen.github.io/tags/big-data/"}]},{"title":"linux","slug":"linux-command-2","date":"2019-11-22T11:35:34.000Z","updated":"2020-02-10T13:02:20.551Z","comments":true,"path":"2019/11/22/linux-command-2/","link":"","permalink":"https://chenadminchen.github.io/2019/11/22/linux-command-2/","excerpt":"","text":"Limits on Number of Files and Processes (ulimit) user can open file that size &lt; ?? script123ulimit -u# result : 1024 user can create process(nproc) script12345# select all user create processps h -Led -o user | sort | uniq -c | sort -n# select one user create processps -o nlwp,pid,lwp,args -u chen | sort -n update process number if command print error, that can change user can process numberscript12Cannot create GC thread. Out of system resources java.lang.OutOfMemoryError: unable to create new native thread 需要先看linux操作系统内核版本，通过uname -a查看内核版本，因为2.6版本的内核默认是在/etc/security/limits.d/90-nproc.conf里的配置会覆盖/etc/security/limits.conf的配置 uname -a Linux hadoop219 2.6.32-431.el6.x86_64 #1 SMP Fri Nov 22 03:15:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux 修改配置文件 vi /etc/security/limits.d/90-nproc.conf 注释掉 * soft nproc 1024 修改limits.conf文件 vi /etc/security/limits.conf添加 soft nproc 655350 在控制台执行(修改这个不需要重启) ulimit -u 655350 5.检查下是否生效，在控制台切到该用户下 ulimit -u sshadd ssh key learn address script12345#dbssh-keygen -t rsa -b 4096# generat ssh keyssh-copy-id root@192.168.4.214 DNSNTPNTP(network time protocol)","categories":[],"tags":[{"name":"linux command","slug":"linux-command","permalink":"https://chenadminchen.github.io/tags/linux-command/"}]},{"title":"big-data-environment set-up","slug":"big-data","date":"2019-11-06T07:35:34.000Z","updated":"2020-02-10T13:02:20.587Z","comments":true,"path":"2019/11/06/big-data/","link":"","permalink":"https://chenadminchen.github.io/2019/11/06/big-data/","excerpt":"","text":"big-data environment zookeeper(apache-zookeeper-3.5.6-bin) hadoop(hadoop-3.2.1) hbase(hbase-2.2.2) 运行于单机环境中 安装地址：/home/chen/work/service/ zookeeperzookeeper 学习地址 configurationconf/zoo.cfg123456789101112131415161718192021tickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.# dataDir=/tmp/zookeeperdataDir=/home/chen/work/service/apache-zookeeper-3.5.6-bin/zookeeperdir/zookeeper-datadataLogDir=/home/chen/work/service/apache-zookeeper-3.5.6-bin/zookeeperdir/logs# the port at which the clients will connectclientPort=2181# 集群的配置server.1=127.0.0.1:2888:3888 start ./bin/zkServer.sh start stop ./bin/zkServer.sh stop client connection ./bin/zkCli.sh hbase support hadoop versionhbase support hadoop version hadoop(3.2.1/3.0.0)hadoop history version hadoop 3.1.x and hadoop 3.2.x not use in hbase This command that can check hadoop&gt; bin/hdfs getconf -backupNodes hadoop can not use~~123456789101112131415161718~~HDFS_GETCONF_USER~~~~0.0.0.0~~~~```~~~~hadoop can use~~~~```~~~~0.0.0.0~~~~```~~### ssh localhost### export #### sudo nano /etc/profile```shell scriptexport HADOOP_HOME=/home/chen/work/service/hadoop-3.2.1 source /etc/profile sudo nano ~/.barshrcscript1export HADOOP_HOME=/home/chen/work/service/hadoop-3.2.1 source ~/.barshrc etc/hadoop configurationhadoop-env.shscript1234567891011export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64#export HDFS_NAMENODE_USER=\"root\"#export HDFS_DATANODE_USER=\"root\"#export HDFS_SECONDARYNAMENODE_USER=\"root\"#export YARN_RESOURCEMANAGER_USER=\"root\"#export YARN_NODEMANAGER_USER=\"root\" hdfs-site.xml1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;file:///home/chen/work/service/hadoop-3.2.1/hdfs/namenode-test&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;file:///home/chen/work/service/hadoop-3.2.1/hdfs/datanode-test&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; ./bin/hadoop namenode -format core-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml1234567891011121314151617181920212223&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;http://localhost:49001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/hadoop-3.2.1/local-dir&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; yarn-site.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD &lt;!-- &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; --&gt; &lt;!-- 这里设置主节点 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;node01&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt; &lt;/property&gt;======= &lt;!-- 这里设置主节点 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt; &lt;/property&gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt; a592b6d835aac4590431219b3a2377e915609018 &lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt; &lt;/property&gt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD======= &lt;!-- &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; --&gt; &lt;!-- 这里设置主节点 --&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; a592b6d835aac4590431219b3a2377e915609018&lt;/configuration&gt; start./sbin/start-all.sh web urlhttp://localhost:8088/cluster hbase(2.2.2)configurationhbase-env.shscript12345&lt;!-- # HBASE_MANAGES_ZK=false 表示启动的是独立的zookeeper,而配置成true则是hbase自带的zookeeper --&gt;export HBASE_MANAGES_ZK=falseexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 hbase-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;configuration&gt;&lt;!--hdfs://localhost:9000 is hadoop storage data address,you must config address in hadoop core-site.xml --&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt;&lt;!-- open web page --&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;!-- distributed = true , hbase use external zookeeper --&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 分布式zookeeper configuration &lt;value&gt;127.0.0.1,192.168.1.1,192.168.1.2&lt;/value&gt; --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/hbase-2.2.2/hbase-zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Controls whether HBase will check for stream capabilities (hflush/hsync). Disable this if you intend to run on LocalFileSystem, denoted by a rootdir with the 'file://' scheme, but be mindful of the NOTE below. WARNING: Setting this to false blinds you to potential data loss and inconsistent system state in the event of process and/or node failures. If HBase is complaining of an inability to use hsync or hflush it's most likely not a false positive. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; start ./bin/start-hbase.sh stop ./bin/stop-hbase.sh client connection ./bin/hbase shell error fixCould not initialize class org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper error script12345678910111213141516171819202122232019-01-16 15:26:44,501 ERROR [RS_OPEN_META-regionserver/shizhi002:16020-0] handler.OpenRegionHandler: Failed open of region=hbase:meta,,1.1588230740java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper at org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.createOutput(AsyncFSOutputHelper.java:51) at org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.initOutput(AsyncProtobufLogWriter.java:167) at org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:166) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:113) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:612) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:124) at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:756) at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:486) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.&lt;init&gt;(AsyncFSWAL.java:251) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:73) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:48) at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:152) at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:60) at org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:284) at org.apache.hadoop.hbase.regionserver.HRegionServer.getWAL(HRegionServer.java:2104) at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:284) at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:108) at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:104) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) fix WAL(Write-Ahead-Log)是HBase的RegionServer在处理数据插入和删除的过程中用来记录操作内容的一种日志hbase.wal.provider=multiwal，支持的值还有defaultProvider和filesystem1234&lt;property&gt; &lt;name&gt;hbase.wal.provider&lt;/name&gt; &lt;value&gt;filesystem&lt;/value&gt; &lt;/property&gt; WAL的持久化的级别有如下几种： SKIP_WAL：不写wal日志,这种可以较大提高写入的性能，但是会存在数据丢失的危险，只有在大批量写入的时候才使用(出错了可以重新运行)，其他情况不建议使用。ASYNC_WAL：异步写入SYNC_WAL：同步写入wal日志文件，保证数据写入了DataNode节点。FSYNC_WAL: 目前不支持了，表现是与SYNC_WAL是一致的USE_DEFAULT: 如果没有指定持久化级别，则默认为USE_DEFAULT, 这个为使用HBase全局默认级别(SYNC_WAL) start order hadoop -&gt; zookeeper -&gt; hbasezookeeper -&gt; hadoop -&gt; hbase jps jps`shell script6608 DataNode6817 SecondaryNameNode7939 HRegionServer2019 org.eclipse.equinox.launcher_1.5.600.v20191014-2022.jar7783 HMaster6440 NameNode7576 QuorumPeerMain #使用外部的zookeeper时,启用QuorumPeerMain，否则使用QuorumPeer25401 Main7305 NodeManager7050 ResourceManager8334 Main8814 Jps ` kafkasparkhive###","categories":[],"tags":[{"name":"big-data","slug":"big-data","permalink":"https://chenadminchen.github.io/tags/big-data/"}]},{"title":"big-data-environment set-up","slug":"big-data-environment","date":"2019-11-06T07:35:34.000Z","updated":"2020-02-10T13:02:20.535Z","comments":true,"path":"2019/11/06/big-data-environment/","link":"","permalink":"https://chenadminchen.github.io/2019/11/06/big-data-environment/","excerpt":"","text":"big-data environment zookeeper(apache-zookeeper-3.5.6-bin) hadoop(hadoop-3.2.1) hbase(hbase-2.2.2) 运行于单机环境中 安装地址：/home/chen/work/service/ zookeeperzookeeper 学习地址 configurationconf/zoo.cfg123456789101112131415161718192021tickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.# dataDir=/tmp/zookeeperdataDir=/home/chen/work/service/apache-zookeeper-3.5.6-bin/zookeeperdir/zookeeper-datadataLogDir=/home/chen/work/service/apache-zookeeper-3.5.6-bin/zookeeperdir/logs# the port at which the clients will connectclientPort=2181# 集群的配置server.1=127.0.0.1:2888:3888 start ./bin/zkServer.sh start stop ./bin/zkServer.sh stop client connection ./bin/zkCli.sh hbase support hadoop versionhbase support hadoop version hadoop(3.2.1/3.0.0)hadoop history version hadoop 3.1.x and hadoop 3.2.x not use in hbase This command that can check hadoop&gt; bin/hdfs getconf -backupNodes hadoop can not use~~123456789101112131415161718~~HDFS_GETCONF_USER~~~~0.0.0.0~~~~```~~~~hadoop can use~~~~```~~~~0.0.0.0~~~~```~~### ssh localhost### export #### sudo nano /etc/profile```shell scriptexport HADOOP_HOME=/home/chen/work/service/hadoop-3.2.1 source /etc/profile sudo nano ~/.barshrcscript1export HADOOP_HOME=/home/chen/work/service/hadoop-3.2.1 source ~/.barshrc etc/hadoop configurationhadoop-env.shscript1234567891011export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64#export HDFS_NAMENODE_USER=\"root\"#export HDFS_DATANODE_USER=\"root\"#export HDFS_SECONDARYNAMENODE_USER=\"root\"#export YARN_RESOURCEMANAGER_USER=\"root\"#export YARN_NODEMANAGER_USER=\"root\" hdfs-site.xml12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;file:///home/chen/work/service/hadoop-3.2.1/hdfs/namenode-test&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;file:///home/chen/work/service/hadoop-3.2.1/hdfs/datanode-test&lt;/value&gt; &lt;/property&gt; &lt;!--web request hdfs,but not must --&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:50070&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; ./bin/hadoop namenode -format core-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml1234567891011121314151617181920212223&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;http://localhost:49001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/hadoop-3.2.1/local-dir&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt; &lt;/property&gt; --&gt;&lt;/configuration&gt; yarn-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里设置主节点 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; --&gt; &lt;!-- 这里设置主节点 --&gt;&lt;/configuration&gt; start./sbin/start-all.sh web urlhttp://localhost:8088/cluster hbase(2.2.2)configurationhbase-env.shscript12345&lt;!-- # HBASE_MANAGES_ZK=false 表示启动的是独立的zookeeper,而配置成true则是hbase自带的zookeeper --&gt;export HBASE_MANAGES_ZK=falseexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 hbase-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;configuration&gt;&lt;!--hdfs://localhost:9000 is hadoop storage data address,you must config address in hadoop core-site.xml --&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt; &lt;/property&gt;&lt;!-- open web page --&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;!-- distributed = true , hbase use external zookeeper --&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 分布式zookeeper configuration &lt;value&gt;127.0.0.1,192.168.1.1,192.168.1.2&lt;/value&gt; --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;127.0.0.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/hbase-2.2.2/hbase-zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Controls whether HBase will check for stream capabilities (hflush/hsync). Disable this if you intend to run on LocalFileSystem, denoted by a rootdir with the 'file://' scheme, but be mindful of the NOTE below. WARNING: Setting this to false blinds you to potential data loss and inconsistent system state in the event of process and/or node failures. If HBase is complaining of an inability to use hsync or hflush it's most likely not a false positive. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; start ./bin/start-hbase.sh stop ./bin/stop-hbase.sh client connection ./bin/hbase shell error fixCould not initialize class org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper error script12345678910111213141516171819202122232019-01-16 15:26:44,501 ERROR [RS_OPEN_META-regionserver/shizhi002:16020-0] handler.OpenRegionHandler: Failed open of region=hbase:meta,,1.1588230740java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.hbase.io.asyncfs.FanOutOneBlockAsyncDFSOutputHelper at org.apache.hadoop.hbase.io.asyncfs.AsyncFSOutputHelper.createOutput(AsyncFSOutputHelper.java:51) at org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.initOutput(AsyncProtobufLogWriter.java:167) at org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:166) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:113) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:612) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:124) at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:756) at org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:486) at org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.&lt;init&gt;(AsyncFSWAL.java:251) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:73) at org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:48) at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:152) at org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:60) at org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:284) at org.apache.hadoop.hbase.regionserver.HRegionServer.getWAL(HRegionServer.java:2104) at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.openRegion(OpenRegionHandler.java:284) at org.apache.hadoop.hbase.regionserver.handler.OpenRegionHandler.process(OpenRegionHandler.java:108) at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:104) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) fix WAL(Write-Ahead-Log)是HBase的RegionServer在处理数据插入和删除的过程中用来记录操作内容的一种日志hbase.wal.provider=multiwal，支持的值还有defaultProvider和filesystem1234&lt;property&gt; &lt;name&gt;hbase.wal.provider&lt;/name&gt; &lt;value&gt;filesystem&lt;/value&gt; &lt;/property&gt; WAL的持久化的级别有如下几种： SKIP_WAL：不写wal日志,这种可以较大提高写入的性能，但是会存在数据丢失的危险，只有在大批量写入的时候才使用(出错了可以重新运行)，其他情况不建议使用。ASYNC_WAL：异步写入SYNC_WAL：同步写入wal日志文件，保证数据写入了DataNode节点。FSYNC_WAL: 目前不支持了，表现是与SYNC_WAL是一致的USE_DEFAULT: 如果没有指定持久化级别，则默认为USE_DEFAULT, 这个为使用HBase全局默认级别(SYNC_WAL) start order hadoop -&gt; zookeeper -&gt; hbasezookeeper -&gt; hadoop -&gt; hbase jps jpsscript123456789101112131415161718192021222324252627282930313233343536373839404142436608 DataNode6817 SecondaryNameNode7939 HRegionServer2019 org.eclipse.equinox.launcher_1.5.600.v20191014-2022.jar7783 HMaster6440 NameNode7576 QuorumPeerMain #使用外部的zookeeper时,启用QuorumPeerMain，否则使用QuorumPeer25401 Main7305 NodeManager7050 ResourceManager8334 Main8814 Jps``` test环境redis信息：redis-cli -h 121.40.83.65 auth Yftestredis123redis-cli -h 121.40.83.65 -p 6379 -a Yftestredis123## kafka## spark## hive## configuration hive-env.sh```shell scriptHADOOP_HOME=/home/chen/work/service/hadoop-3.0.0HBASE_HOME=/home/chen/work/service/hbase-2.2.2JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64HIVE_HOME=/home/chen/work/service/apache-hive-3.1.2-binexport HIVE_CONF_DIR=$HIVE_HOME/confexport HIVE_AUX_JARS_PATH=$HBASE_HOME/libexport CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$HADOOP_HOME/lib:$HIVE_HOME/lib hive-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hivedbH?createDatabaseIfNotExist=true&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt; &lt;!-- 如果 mysql 和 hive 在同一个服务器节点，那么请更改 hadoop02 为 localhost --&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;username to use against metastore database&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;as1996&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.autoCreateSchema&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.autoCreateTables&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;datanucleus.autoCreateColumns&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 设置 hive仓库的HDFS上的位置 --&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/data&lt;/value&gt; &lt;description&gt;location of default database for the warehouse&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/resources&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt; &lt;/property&gt; &lt;!-- 修改日志位置 --&gt; &lt;property&gt; &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/HiveJobsLog&lt;/value&gt; &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/ResourcesLog&lt;/value&gt; &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/HiveRunLog&lt;/value&gt; &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/hive/OpertitionLog&lt;/value&gt; &lt;description&gt;Top level directory where operation tmp are stored if logging functionality is enabled&lt;/description&gt; &lt;/property&gt; &lt;!-- 配置HWI接口 --&gt; &lt;property&gt; &lt;name&gt;hive.hwi.war.file&lt;/name&gt; &lt;value&gt;/home/chen/work/service/apache-hive-3.1.2-bin/lib/hive-hwi-2.1.1.jar&lt;/value&gt; &lt;description&gt;This sets the path to the HWI war file, relative to $&#123;HIVE_HOME&#125;. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.hwi.listen.host&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;description&gt;This is the host address the Hive Web Interface will listen on&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.hwi.listen.port&lt;/name&gt; &lt;value&gt;9999&lt;/value&gt; &lt;description&gt;This is the port the Hive Web Interface will listen on&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.port&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.http.port&lt;/name&gt; &lt;value&gt;10001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.http.path&lt;/name&gt; &lt;value&gt;cliservice&lt;/value&gt; &lt;/property&gt; &lt;!-- HiveServer2的WEB UI --&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.host&lt;/name&gt; &lt;value&gt;localhost&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.port&lt;/name&gt; &lt;value&gt;10002&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.scratch.dir.permission&lt;/name&gt; &lt;value&gt;755&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.auto.convert.join&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.dynamicAllocation.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;动态分配资源&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.execution.engine&lt;/name&gt; &lt;value&gt;spark&lt;/value&gt; &lt;description&gt;这个值可以使mr/tez/spark中的一个作为hive的执行引擎，mr是默认值，而tez仅hadoop 2支持&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.enable.spark.execution.engine&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.home&lt;/name&gt; &lt;value&gt;/home/chen/work/service/spark-2.3.0-bin-hadoop2.7&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.master&lt;/name&gt; &lt;value&gt;spark://127.0.0.1:7077&lt;/value&gt; &lt;!-- &lt;value&gt;yarn-client&lt;/value&gt; --&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.serializer&lt;/name&gt; &lt;value&gt;org.apache.spark.serializer.KryoSerializer&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.executor.memeory&lt;/name&gt; &lt;value&gt;1g&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.driver.memeory&lt;/name&gt; &lt;value&gt;1g&lt;/value&gt; &lt;/property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;spark.executor.extraJavaOptions&lt;/name&gt; &lt;value&gt;-XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"&lt;/value&gt;&lt;/property&gt; --&gt; &lt;!-- 使用Hive on spark时,若不设置下列该配置会出现内存溢出异常 --&gt; &lt;property&gt; &lt;name&gt;spark.driver.extraJavaOptions&lt;/name&gt; &lt;value&gt;-XX:PermSize=128M -XX:MaxPermSize=512M&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.submit.deployMode&lt;/name&gt; &lt;value&gt;client&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.eventLog.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.eventLog.dir&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000/spark-log&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.exec.reducers.bytes.per.reducer&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.job.reduces&lt;/name&gt; &lt;value&gt;10&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt; hive.exec.reducers.bytes.per.reducer&lt;/name&gt; &lt;value&gt;10&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;spark.yarn.jars&lt;/name&gt; &lt;value&gt;hdfs://localhost:8020/spark-jars/*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 拷贝JDBC包script1cp mysql-connector-java-5.1.19-bin.jar /hive-2.1.1/lib/ 删除Hadoop之前的jline包，拷贝Hive中jline的扩展包script1cp /hive-2.1.1/lib/jline-2.12.jar /hadoop-3.0.0/share/hadoop/yarn/lib/ 拷贝tools.jar包script1cp /java8/lib/tools.jar /hive-2.1.1/lib/ init matedata databasescript12./bin/schematool -dbType mysql -initSchema start hivescript1./bin/hive start serverhive2script123./bin/hiveserver2./bin/hiveserver2 --hiveconf hive.root.logger=INFO,console jdbc connect hivescript1./bin/beeline -u jdbc:hive2://localhost:10000/default error error 1 1234567891011121314151617181920212223java.lang.NoClassDefFoundError: org/apache/tez/dag/api/TezConfiguration at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession$AbstractTriggerValidator.startTriggerValidator(TezSessionPoolSession.java:74) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.initTriggers(TezSessionPoolManager.java:207) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.startPool(TezSessionPoolManager.java:114) ~[hive-exec-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.initAndStartTezSessionPoolManager(HiveServer2.java:839) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startOrReconnectTezSessions(HiveServer2.java:822) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.start(HiveServer2.java:745) ~[hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:1037) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.access$1600(HiveServer2.java:140) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:1305) [hive-service-3.1.2.jar:3.1.2] at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:1149) [hive-service-3.1.2.jar:3.1.2] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_222] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_222] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_222] at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_222] at org.apache.hadoop.util.RunJar.run(RunJar.java:239) [hadoop-common-2.8.5.jar:?] at org.apache.hadoop.util.RunJar.main(RunJar.java:153) [hadoop-common-2.8.5.jar:?]Caused by: java.lang.ClassNotFoundException: org.apache.tez.dag.api.TezConfiguration at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[?:1.8.0_222] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_222] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349) ~[?:1.8.0_222] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_222] ... 16 more fix error在hive-site.xml添加如下配置1234&lt;property&gt; &lt;name&gt;hive.server2.active.passive.ha.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; spark检查是否安装成功script12./bin/spark-submit --master spark://localhost:7077 --class org.apache.spark.examples.SparkPi ../examples/jars/spark-examples_2.11-2.1.1.jar 100./bin/spark-submit --master spark://localhost:7077 --class org.apache.spark.examples.SparkPi /home/chen/work/service/spark-2.3.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.1.1.jar 100","categories":[],"tags":[{"name":"big-data","slug":"big-data","permalink":"https://chenadminchen.github.io/tags/big-data/"}]},{"title":"kotlin(java)-decode-xml","slug":"java-decode-xml","date":"2019-10-28T06:02:34.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/10/28/java-decode-xml/","link":"","permalink":"https://chenadminchen.github.io/2019/10/28/java-decode-xml/","excerpt":"","text":"xml格式的数据转换成对象形式1. xml解析使用的依赖包123456implementation(\"org.jetbrains.kotlin:kotlin-reflect\")implementation(\"org.jetbrains.kotlin:kotlin-stdlib-jdk8\")implementation(\"com.fasterxml.jackson.dataformat:jackson-dataformat-xml:2.10.0.pr1\")implementation(\"com.fasterxml.jackson.core:jackson-core:2.10.0.pr1\")implementation(\"com.fasterxml.jackson.module:jackson-module-kotlin:2.10.0.pr1\") 2. 解析代码如下1234567891011121314151617181920212223242526272829303132import com.fasterxml.jackson.dataformat.xml.XmlMapperimport com.fasterxml.jackson.module.kotlin.registerKotlinModule val xml = \"\"\"&lt;xml&gt; &lt;appid&gt;&lt;![CDATA[wx2421b1c4370ec43b]]&gt;&lt;/appid&gt; &lt;mch_id&gt;&lt;![CDATA[10000100]]&gt;&lt;/mch_id&gt; &lt;nonce_str&gt;&lt;![CDATA[TeqClE3i0mvn3DrK]]&gt;&lt;/nonce_str&gt; &lt;out_refund_no_0&gt;&lt;![CDATA[1415701182]]&gt;&lt;/out_refund_no_0&gt; &lt;out_trade_no&gt;&lt;![CDATA[1415757673]]&gt;&lt;/out_trade_no&gt; &lt;refund_count&gt;1&lt;/refund_count&gt; &lt;refund_fee_0&gt;1&lt;/refund_fee_0&gt; &lt;refund_id_0&gt;&lt;![CDATA[2008450740201411110000174436]]&gt;&lt;/refund_id_0&gt; &lt;refund_status_0&gt;&lt;![CDATA[PROCESSING]]&gt;&lt;/refund_status_0&gt; &lt;refund_fee_1&gt;1&lt;/refund_fee_1&gt; &lt;refund_id_1&gt;&lt;![CDATA[2008450740201411110000174436]]&gt;&lt;/refund_id_1&gt; &lt;refund_status_1&gt;&lt;![CDATA[PROCESSING]]&gt;&lt;/refund_status_1&gt; &lt;result_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/result_code&gt; &lt;return_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/return_code&gt; &lt;return_msg&gt;&lt;![CDATA[OK]]&gt;&lt;/return_msg&gt; &lt;sign&gt;&lt;![CDATA[1F2841558E233C33ABA71A961D27561C]]&gt;&lt;/sign&gt; &lt;transaction_id&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/transaction_id&gt; &lt;coupon_type_0_0&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/coupon_type_0_0&gt; &lt;single_coupon_refund_fee_0_0&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/single_coupon_refund_fee_0_0&gt; &lt;coupon_type_0_1&gt;&lt;![CDATA[1008450740201411110005820873000____]]&gt;&lt;/coupon_type_0_1&gt; &lt;single_coupon_refund_fee_0_1&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/single_coupon_refund_fee_0_1&gt; &lt;coupon_type_1_1&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/coupon_type_1_1&gt; &lt;single_coupon_refund_fee_1_1&gt;&lt;![CDATA[1008450740201411110005820873]]&gt;&lt;/single_coupon_refund_fee_1_1&gt;&lt;/xml&gt;\"\"\"// XmlMapper().registerKotlinModule() 需要注入（否则@JsonAlias不生效）val xmlMapper = XmlMapper().registerKotlinModule()val xmlMapper = XmlMapper()var wxPayOrderQueryResult = xmlMapper.readValue(result, WxPayOrderResult::class.java) 3. 实体类代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@XmlRootElement(name = \"xml\")@JacksonXmlRootElement(localName = \"xml\")//@JsonSerialize(include = JsonSerialize.Inclusion.NON_NULL)@JsonInclude(JsonInclude.Include.NON_NULL)@JsonIgnoreProperties(ignoreUnknown = true)data class WxPayOrderResult( @JsonAlias(\"return_code\") var returnCode: String? = null, @JsonProperty(access = JsonProperty.Access.WRITE_ONLY) var appid: String? = null, @JsonAlias(\"return_msg\") var returnMsg: String? = null, @JsonProperty(access = JsonProperty.Access.WRITE_ONLY) @JsonAlias(\"mch_id\") var mchId: String? = null, @JsonAlias(\"nonce_str\") var nonce: String? = null, var sign: String? = null, @JsonAlias(\"result_code\") var resultCode: String? = null, @JsonAlias(\"err_code\") var errCode: String? = null, @JsonAlias(\"err_code_des\") var errCodeDes: String? = null, @JsonAlias(\"device_info\") var deviceInfo: String? = null, var openid: String? = null, @JsonAlias(\"trade_type\") var tradeType: String? = null, @JsonAlias(\"trade_state\") var tradeState: String? = null, @JsonAlias(\"bank_type\") var bankType: String? = null, @JsonAlias(\"total_fee\") var totalFee: String? = null, @JsonAlias(\"fee_type\") var feeType: String? = null, @JsonAlias(\"cash_fee\") var cashFee: String? = null, @JsonAlias(\"cash_fee_type\") // `cash_fee_type`xml中属性名字 var cashFeeType: String? = null, @JsonAlias(\"coupon_fee\") var couponFee: String? = null, @JsonAlias(\"settlement_total_fee\") var settlementTotalFee: String? = null, @JsonAlias(\"coupon_count\") var couponCount: String? = null, @JsonAlias(\"transaction_id\") var transactionId: String? = null, @JsonAlias(\"out_trade_no\") var outTradeNo: String? = null, var attach: String? = null, @JsonAlias(\"time_end\") var timeEnd: String? = null, @JsonAlias(\"trade_state_desc\") var tradeStateDesc: String? = null, @JsonAlias(\"prepay_id\") var prepayId: String? = null) &#123; @JsonProperty(\"is_subscribe\") var subscribe: String? = null&#125;","categories":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/categories/java/"}],"tags":[{"name":"kotlin","slug":"kotlin","permalink":"https://chenadminchen.github.io/tags/kotlin/"},{"name":"xml","slug":"xml","permalink":"https://chenadminchen.github.io/tags/xml/"}]},{"title":"spring-boot-feign","slug":"spring-boot-feign","date":"2019-10-28T06:02:34.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/10/28/spring-boot-feign/","link":"","permalink":"https://chenadminchen.github.io/2019/10/28/spring-boot-feign/","excerpt":"","text":"spring-boot-feign ssl认证身份1. feign使用的依赖包12implementation(\"org.springframework.cloud:spring-cloud-starter-openfeign\")testImplementation(\"org.springframework.boot:spring-boot-starter-test\") 2. 代码如下1234wx-pay: mch_id: 1r5gfs90rtr61trw jks: /home/work/file/apiclient_cert.p12 server_alias: tenpay certificate 12345678910111213141516import feign.Clientimport feign.Feignimport org.springframework.beans.factory.annotation.Autowiredimport org.springframework.context.annotation.Beanimport org.springframework.context.annotation.Configurationimport javax.net.ssl.SSLSocketFactory// defined feign server@Configurationclass CustomFeignConfiguration &#123; @Bean fun feignBuilder(sSLSocketFactory: SSLSocketFactory): Feign.Builder &#123; val trustSSLSockets = Client.Default(sSLSocketFactory, null) return Feign.builder().client(trustSSLSockets) &#125;&#125; //feign use ssl jks123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163import org.springframework.beans.factory.annotation.Valueimport org.springframework.stereotype.Componentimport java.io.IOExceptionimport java.io.InputStreamimport java.net.InetAddressimport java.net.Socketimport java.security.KeyStoreimport java.security.Principalimport java.security.PrivateKeyimport java.security.SecureRandomimport java.security.cert.X509Certificateimport java.util.Arraysimport javax.net.ssl.*import java.io.FileInputStream/** @mch_id: ssl password @jks: jks file @serverAlias: jks alias*/ @Componentclass TrustingSSLSocketFactory constructor(@Value(\"\\$&#123;wx-pay.mch_id&#125;\") val mch_id: String, @Value(\"\\$&#123;wx-pay.jks&#125;\") val jks: String, @Value(\"\\$&#123;wx-pay.server_alias&#125;\") val serverAlias: String) : SSLSocketFactory(), X509TrustManager, X509KeyManager &#123; private val delegate: SSLSocketFactory private val privateKey: PrivateKey? private val certificateChain: Array&lt;X509Certificate&gt;? init &#123; try &#123; val sc = SSLContext.getInstance(\"SSL\") sc.init(arrayOf&lt;KeyManager&gt;(this), arrayOf&lt;TrustManager&gt;(this), SecureRandom()) this.delegate = sc.socketFactory &#125; catch (e: Exception) &#123; throw RuntimeException(e) &#125; if (serverAlias.isEmpty()) &#123; this.privateKey = null this.certificateChain = null &#125; else &#123; try &#123; val fileInputStream = FileInputStream(jks)// val keyStore = loadKeyStore(TrustingSSLSocketFactory::class.java.getResourceAsStream(jks), mch_id) val keyStore = loadKeyStore(fileInputStream, mch_id) this.privateKey = keyStore.getKey(serverAlias, mch_id.toCharArray()) as PrivateKey val rawChain = keyStore.getCertificateChain(serverAlias) this.certificateChain = Arrays.copyOf(rawChain, rawChain.size, Array&lt;X509Certificate&gt;::class.java) &#125; catch (e: Exception) &#123; throw RuntimeException(e) &#125; &#125; &#125; companion object &#123; private val ENABLED_CIPHER_SUITES = arrayOf(\"TLS_RSA_WITH_AES_256_CBC_SHA\")// // private val sslSocketFactories = LinkedHashMap&lt;String, SSLSocketFactory&gt;()// private val KEYSTORE_PASSWORD = \"1549064361\".toCharArray()// fun get(): SSLSocketFactory &#123;// return get(\"\", \"\")// &#125; // @Synchronized// operator fun get(serverAlias: String, cert: String): SSLSocketFactory &#123;//// if (!sslSocketFactories.containsKey(serverAlias)) &#123;// sslSocketFactories[serverAlias] = TrustingSSLSocketFactory(serverAlias)// &#125;//// return sslSocketFactories[serverAlias]!!// &#125;// internal fun setEnabledCipherSuites(socket: Socket): Socket &#123; SSLSocket::class.java.cast(socket).enabledCipherSuites = ENABLED_CIPHER_SUITES return socket &#125; @Throws(IOException::class) private fun loadKeyStore(inputStream: InputStream, password: String): KeyStore &#123; try &#123; val keyStore = KeyStore.getInstance(\"PKCS12\") keyStore.load(inputStream, password.toCharArray()) return keyStore &#125; catch (e: Exception) &#123; throw RuntimeException(e) &#125; finally &#123; inputStream.close() &#125; &#125; &#125; override fun getDefaultCipherSuites(): Array&lt;String&gt; &#123; return ENABLED_CIPHER_SUITES &#125; override fun getSupportedCipherSuites(): Array&lt;String&gt; &#123; return ENABLED_CIPHER_SUITES &#125; @Throws(IOException::class) override fun createSocket(s: Socket, host: String, port: Int, autoClose: Boolean): Socket &#123; return setEnabledCipherSuites(delegate.createSocket(s, host, port, autoClose)) &#125; @Throws(IOException::class) override fun createSocket(host: String, port: Int): Socket &#123; return setEnabledCipherSuites(delegate.createSocket(host, port)) &#125; @Throws(IOException::class) override fun createSocket(host: InetAddress, port: Int): Socket &#123; return setEnabledCipherSuites(delegate.createSocket(host, port)) &#125; @Throws(IOException::class) override fun createSocket(host: String, port: Int, localHost: InetAddress, localPort: Int): Socket &#123; return setEnabledCipherSuites(delegate.createSocket(host, port, localHost, localPort)) &#125; @Throws(IOException::class) override fun createSocket(address: InetAddress, port: Int, localAddress: InetAddress, localPort: Int): Socket &#123; return setEnabledCipherSuites(delegate.createSocket(address, port, localAddress, localPort)) &#125; override fun getAcceptedIssuers(): Array&lt;X509Certificate&gt;? &#123; return null &#125; override fun checkClientTrusted(certs: Array&lt;X509Certificate&gt;, authType: String) &#123;&#125; override fun checkServerTrusted(certs: Array&lt;X509Certificate&gt;, authType: String) &#123;&#125; override fun getClientAliases(keyType: String, issuers: Array&lt;Principal&gt;): Array&lt;String&gt;? &#123; return null &#125; override fun chooseClientAlias(keyType: Array&lt;String&gt;, issuers: Array&lt;Principal&gt;, socket: Socket): String? &#123; return \"null\" &#125; override fun getServerAliases(keyType: String, issuers: Array&lt;Principal&gt;): Array&lt;String&gt;? &#123; return null &#125; override fun chooseServerAlias(keyType: String, issuers: Array&lt;Principal&gt;, socket: Socket): String &#123; return serverAlias &#125; override fun getCertificateChain(alias: String): Array&lt;X509Certificate&gt;? &#123; return certificateChain &#125; override fun getPrivateKey(alias: String): PrivateKey? &#123; return privateKey &#125;&#125;","categories":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/categories/spring-boot/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/tags/spring-boot/"},{"name":"feign","slug":"feign","permalink":"https://chenadminchen.github.io/tags/feign/"}]},{"title":"mysql partition","slug":"mysql-partition","date":"2019-10-25T06:40:45.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/10/25/mysql-partition/","link":"","permalink":"https://chenadminchen.github.io/2019/10/25/mysql-partition/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566-- create tableCREATE TABLE `test_partition` ( `name` varchar(20) DEFAULT NULL, `time_test` datetime NOT NULL);-- to_days()select to_days(\"2019-10-10\"); -- 737707： from 1970-01-01 to 2019-10-10 have 737707 day select month(\"2019-10-10\"); -- 10： from 2019-01-01 to 2019-10-10 have 10 months select year(\"2019-10-10\"); -- 2019-- `partition` can range to_days() and year()-- alter table add partitionalter table test_partition partition by range (to_days(time_test)) (partition p20191001 values less than (to_days(\"2019-10-01\")), partition p20191101 values less than (to_days(\"2019-11-01\")));alter table test_partition add partition(partition p20191201 VALUES LESS THAN (to_days(\"2019-12-01\") ) );-- alter table drop partition ,but this table must have one partitionALTER TABLE test_partition DROP PARTITION p20191201;-- select table partitionSELECT partition_name part, partition_expression expr, partition_description descr, FROM_DAYS(partition_description) lessthan_sendtime, table_rowsFROM INFORMATION_SCHEMA.partitionsWHERE TABLE_SCHEMA = SCHEMA() AND TABLE_NAME='test_partition';-- 事务DELIMITER $$USE `test`$$DROP PROCEDURE IF EXISTS `create_partition`$$/*这里复制的时候注意自己的登录用户*/CREATE DEFINER=`root`@`localhost` PROCEDURE `create_partition_test`(IN tableName VARCHAR(20),IN interval_ INT)BEGIN/* 事务回滚，其实放这里没什么作用，ALTER TABLE是隐式提交，回滚不了的 */ DECLARE EXIT HANDLER FOR SQLEXCEPTION ROLLBACK; START TRANSACTION; /* 到系统表查出这个表的最大分区，得到最大分区的日期。在创建分区的时候，名称就以日期格式存放，方便后面维护 */ SELECT REPLACE(partition_name,'p','') INTO @P12_Name FROM INFORMATION_SCHEMA.PARTITIONS WHERE table_name=tableName ORDER BY partition_ordinal_position DESC LIMIT 1; SET @Max_date= DATE(DATE_ADD(@P12_Name+0, INTERVAL interval_ DAY))+0; /* 修改表，在最大分区的后面增加一个分区，时间范围加 interval_ 天 */ SET @s1=CONCAT('ALTER TABLE ' ,tableName ,' ADD PARTITION (PARTITION p',@Max_date,' VALUES LESS THAN (TO_DAYS (''',DATE(@Max_date),''')))'); /* 输出查看增加分区语句*/ SELECT @s1; PREPARE stmt2 FROM @s1; EXECUTE stmt2; DEALLOCATE PREPARE stmt2; /* 提交 */ COMMIT ; END$$DELIMITER ;","categories":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"partition","slug":"partition","permalink":"https://chenadminchen.github.io/tags/partition/"}]},{"title":"spring-boot-eureka","slug":"spring-boot-eureka","date":"2019-10-16T07:13:45.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/10/16/spring-boot-eureka/","link":"","permalink":"https://chenadminchen.github.io/2019/10/16/spring-boot-eureka/","excerpt":"","text":"spring-boot-eurekaapplication.yml1234567891011121314151617181920212223242526272829303132333435363738394041424344server: port: 8541 #ssl ssl: enabled: true key-store: ff.jks key-alias: alias key-store-password: 123 key-password: 123 eureka:# environment: product instance: #non-secure-port-enabled: false# secure-port-enabled: true# secure-port: 8541 preferIpAddress: true #注册时使用IP地址而不是机器名 #hostname: localhost# ip-address: 192.168.1.1# instance-id: 192.168.1.1 client: registerWithEureka: false# fetchRegistry: true serviceUrl: defaultZone: http://localhost:$&#123;server.port&#125;/eureka/ zuul: retryable: true routes: user: sensitiveHeaders: #服务之间的调用将头部信息转发 serviceId: user perm: sensitiveHeaders: serviceId: permission portal: path: /portal/** url: http://localhost:8181 spring-boot-adminspring-boot-sleuth and spring-boot-zipkin and spring-boot-actuator&nbsp;&nbsp;Zipkin is a distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in service architectures. Features include both the collection and lookup of this data. sleuth学习地址zipkin学习地址 添加依赖123456789//actuator 监控和管理Spring Boot应用，比如健康检查、审计、统计和HTTP追踪 implementation(\"org.springframework.boot:spring-boot-starter-actuator\")//Spring-Cloud-Sleuth是Spring Cloud的组成部分之一，为SpringCloud应用实现了一种分布式追踪解决方案，其兼容了Zipkin, HTrace和log-based追踪implementation(\"org.springframework.cloud:spring-cloud-starter-sleuth\")implementation(\"org.springframework.cloud:spring-cloud-starter-zipkin\")//基础的依赖 implementation('org.springframework.boot:spring-boot-starter-web') application.yml配置1234567891011121314151617181920spring: # 提供application.name 方便查看日志信息 application: name: permission zipkin: base-url: http://localhost:9441#采样率 sleuth: sampler.precentage: 1# actuator 配置，配合sleuth使用management: endpoints: web: exposure: include: '*' endpoint: health: show-details: always 配置采样率日志采集的越多，追踪越全面，但是消耗也越大；反之日志追踪不够多也就失去了意义。到底追踪多少日志才是平衡点？Spring Cloud Sleuth把这个问题交给了使用者，通过配置spring.sleuth.sampler.percentage=0.1这个参数来决定了日志记录发送给采集器的概率，0-1交给使用者自己配置。开发阶段和运行初期，一般配置成1全量收集日志，到了上线后可以慢慢降低这一概率。开发者还可以直接在代码中创建AlwaysSampler实例来指定100%输出日志，效果跟spring.sleuth.sampler.percentage=1是一样的。 1234@Bean fun alwaysSampler(): Sampler &#123; return Sampler.ALWAYS_SAMPLE &#125;","categories":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/categories/spring-boot/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/tags/spring-boot/"},{"name":"eureka","slug":"eureka","permalink":"https://chenadminchen.github.io/tags/eureka/"}]},{"title":"hadoop","slug":"hadoop-command-learn-1","date":"2019-10-10T06:16:45.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/10/10/hadoop-command-learn-1/","link":"","permalink":"https://chenadminchen.github.io/2019/10/10/hadoop-command-learn-1/","excerpt":"","text":"hadoop environment setupssh authorization. set use key login linux command123ssh-keygen -t rsa cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys chmod 0600 ~/.ssh/authorized_keys . check key login is true use ssh localhost can login linux that is not input password config JAVA_HOMEyou must config JAVA_HOME environment sudo nano ~/.bashrc1export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 source ~/.bashrc echo $JAVA_HOME1/usr/lib/jvm/java-8-openjdk-amd64 hadoop start12YangTianT4900c-00:~/work/service/hadoop-3.2.1$ ./sbin/start-yarn.shYangTianT4900c-00:~/work/service/hadoop-3.2.1$ ./sbin/stop-yarn.sh hadoop command-put1YangTianT4900c-00:~/work/service/hadoop-3.2.1$ ./bin/hadoop fs -put LICENSE.txt input -ls1YangTianT4900c-00:~/work/service/hadoop-3.2.1$ ./bin/hadoop fs -ls hdfsData wordcount . wordcount can count word numbers1YangTianT4900c-00:~/work/service/hadoop-3.2.1$ ./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount hdfsData/LICENSE.txt output . show result1YangTianT4900c-00:~/work/service/hadoop-3.2.1$ cat output/part-r-00000 yarnmapmapReduce","categories":[],"tags":[{"name":"install","slug":"install","permalink":"https://chenadminchen.github.io/tags/install/"},{"name":"hadoop","slug":"hadoop","permalink":"https://chenadminchen.github.io/tags/hadoop/"},{"name":"map","slug":"map","permalink":"https://chenadminchen.github.io/tags/map/"},{"name":"mapReduce","slug":"mapReduce","permalink":"https://chenadminchen.github.io/tags/mapReduce/"},{"name":"yarn","slug":"yarn","permalink":"https://chenadminchen.github.io/tags/yarn/"}]},{"title":"markdown_preview_enhanced","slug":"markdown-preview-enhancad","date":"2019-08-28T06:35:34.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/08/28/markdown-preview-enhancad/","link":"","permalink":"https://chenadminchen.github.io/2019/08/28/markdown-preview-enhancad/","excerpt":"","text":"flowchart12345678910111213141516171819202122232425262728st=&gt;start: Improve yourl10n process!end=&gt;end: Continue to have fun!op1=&gt;operation: Go to locize.comsub1=&gt;subroutine: Read the awesomenesscond1=&gt;condition: Interested togetting started?sub2=&gt;subroutine: Read about improvingyour localizatin workflowor another sourceio1=&gt;inputoutput: Registerop2=&gt;operation: Logincond2=&gt;condition: valid passwordcond3=&gt;condition: reset passwordsub3=&gt;subroutine: Create a demo projectsub4=&gt;subroutine: start your real projectio2=&gt;inputoutput: Subscribeop3=&gt;operation: send emailst-&gt;op1-&gt;sub1-&gt;cond1cond1(yes)-&gt;io1-&gt;op2-&gt;cond2cond1(no)-&gt;sub2(bottom)-&gt;op1cond2(yes)-&gt;sub3-&gt;sub4-&gt;io2-&gt;endcond2(no)-&gt;cond3cond3(yes,right)-&gt;op3-&gt;op2cond3(no)-&gt;op2st@&gt;op1(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;sub1(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;cond1(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;io1(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;op2(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;cond2(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;sub3(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;sub4(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;io2(&#123;&quot;stroke&quot;:&quot;Red&quot;&#125;)@&gt;end(&#123;&quot;stroke&quot;:&quot;Red&quot;,&quot;stroke-width&quot;:6,&quot;arrow-end&quot;:&quot;classic-wide-long&quot;&#125;) sequence12345Title: Here is a titleA-&gt;B: Normal lineB--&gt;C: Dashed lineC-&gt;&gt;D: Open arrowD--&gt;&gt;A: Dashed open arrow Mermaid1234graph LR A --&gt; B; B --&gt; C; C --&gt; A;","categories":[{"name":"markdown","slug":"markdown","permalink":"https://chenadminchen.github.io/categories/markdown/"}],"tags":[{"name":"markdown_preview_enhanced","slug":"markdown-preview-enhanced","permalink":"https://chenadminchen.github.io/tags/markdown-preview-enhanced/"},{"name":"visual-studio-code","slug":"visual-studio-code","permalink":"https://chenadminchen.github.io/tags/visual-studio-code/"}]},{"title":"","slug":"spark-learn","date":"2019-08-27T14:50:18.984Z","updated":"2019-08-27T14:50:18.984Z","comments":true,"path":"2019/08/27/spark-learn/","link":"","permalink":"https://chenadminchen.github.io/2019/08/27/spark-learn/","excerpt":"","text":"spark learnrun shelllearn-address 12# pathon./bin/pyspark --master local[2]","categories":[],"tags":[]},{"title":"java-python-javaScript-iterator-iterable学习","slug":"java-python-javaScript-iterator-iterable","date":"2019-07-06T08:47:55.823Z","updated":"2019-07-06T08:47:55.823Z","comments":true,"path":"2019/07/06/java-python-javaScript-iterator-iterable/","link":"","permalink":"https://chenadminchen.github.io/2019/07/06/java-python-javaScript-iterator-iterable/","excerpt":"","text":"javaiteratoriterablepythoniterable/可迭代的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当对象中存在iter方法时，该对象就是iterable对象，若一般对象实现iter方法时，它将成为iterable，其在python中iterable的有以下：[列表、字典、元组] 1234567891011121314151617181920212223242526272829303132l = [1,2,3]dir(l) # _iter_iter(l) # &lt;list_iterator at 0x69c8048&gt;In [12]: iter(123)---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-12-7ce543a15833&gt; in &lt;module&gt;()----&gt; 1 iter(123)TypeError: 'int' object is not iterableIn [21]: dict = &#123;'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'&#125;In [22]: iter(dict)Out[22]: &lt;dict_keyiterator at 0x59d81d8&gt; #返回一个键的可迭代对象In [25]: next(dict) #字典不是一个迭代器，它只是一个迭代对象---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-25-9c216d0aadb1&gt; in &lt;module&gt;()----&gt; 1 next(dict)TypeError: 'dict' object is not an iteratorIn [23]: l = [1,2,3]In [24]: iter(l)Out[24]: &lt;list_iterator at 0x69ea710&gt; #返回一个值本身的可迭代对象 自定义迭代对象 12345678910111213141516171819202122In [42]: class String(object): ...: ...: def __init__(self, val): ...: ...: self.val = val ...: ...: def __str__(self): ...: ...: return self.val ...: ...: def __iter__(self): ...: ...: print(\"This is __iter__ method of String class\") ...: ...: return iter(self.val) #self.val is python string so iter() will return it's iterat ...:In [43]: s = String(\"test\")In [44]: iter(s)This is __iter__ method of String classOut[44]: &lt;str_iterator at 0x56c1400&gt; iterator/迭代器&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当对象中存在iter方法,并且存在next()方法时，它将是一个iterator,迭代器可用for lopp 进行获取值，可以调用next()方法进行获取值。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iterator对象存在一次性特点，当使用next()或next()获得值时，若对象不存在下一个值时，raise stopIteration 异常&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;iter()函数为一个可迭代对象返回一个迭代器,如果给iter函数传入一个迭代器，它就直接返回那个迭代器12345678910111213141516#迭代器 实现逻辑class Iterator: def __init__(self, iterable) self.iterable = iterable def __iter__(self): #iter should return self if called on iterator return self def next(self): #Use __next__() in python 3.x if condition: #it should raise StopIteration exception if no next element is left to return raise StopIteration javaScriptiterator1.812345678910let someString = \"someString\";typeof someString[Symbol.iterator];let iterator = someString[Symbol.iterator]();iterator + \"\";iterator.next(); iterable1.8123456789101112131415161718192021222324252627let user = &#123; \"name\": \"test1\", \"age\": 3 &#125;;userIterable = &#123; [Symbol.iterator]() &#123; let keys = Object.keys(user); var index = 0; return &#123; next() &#123; if (keys.length &gt; index) &#123; let key = keys[index++]; return &#123; value: &#123;key: key, value: user[key]&#125;, done: false &#125;; &#125; else &#123; return &#123; value: null, done: true &#125;; &#125; &#125;, return(v) &#123; console.log(\"Done\"); return &#123; value: v, done: true &#125;; &#125; &#125; &#125;&#125;;for(var s of userIterable)&#123; console.info(s);&#125;; generator1.81234567891011121314//function* defined generator functionfunction* generator()&#123; yield 1; yield 2; yield 3; yield 4;&#125;;let ge = generator();console.info(ge.next().value);//check userIterable[Symbol.iterator] typetypeof userIterable[Symbol.iterator]","categories":[{"name":"iterator","slug":"iterator","permalink":"https://chenadminchen.github.io/categories/iterator/"}],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"python","slug":"python","permalink":"https://chenadminchen.github.io/tags/python/"},{"name":"iterator","slug":"iterator","permalink":"https://chenadminchen.github.io/tags/iterator/"}]},{"title":"java-python-javaScript-iterator-iterable学习","slug":"java-python-javaScript-filter-map-reduce","date":"2019-07-06T08:45:58.790Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2019/07/06/java-python-javaScript-filter-map-reduce/","link":"","permalink":"https://chenadminchen.github.io/2019/07/06/java-python-javaScript-filter-map-reduce/","excerpt":"","text":"java&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自java更新到jdk8后，添加了lambda表达式及java.util.Stream,以下便是对此进行说明Stream对数据进行处理，但对原来的数据不进行更改 java创建stream的几种方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;From a Collection via the stream() and parallelStream() methods 12 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;From an array via Arrays.stream(Object[]) 123int[] array = &#123;1, 2, 3, 4, 5&#125;Stream stream = Arrays.stream(array) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;From static factory methods on the stream classes, such as Stream.of(Object[]), IntStream.range(int, int) or Stream.iterate(Object, UnaryOperator) 12345int[] array = &#123;1, 2, 3, 4, 5&#125;Stream stream = Stream.of(array)Stream stream = IntStream.range(3,9) //stream = &#123;3, 4, 5, 6, 7, 8, 9&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The lines of a file can be obtained from BufferedReader.lines() 123BufferedReader bufferedReader = new BufferedReader(new FileReader(\"E:\\\\tmdb_5000_movies2.json\"));Stream stream = bufferedReader.lines() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Streams of file paths can be obtained from methods in Files &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Streams of random numbers can be obtained from Random.ints() 1Random.ints().asLongStream() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Numerous other stream-bearing methods in the JDK, including BitSet.stream(), Pattern.splitAsStream(java.lang.CharSequence), and JarFile.stream() filter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对stream的对象内的内容进行对其内部的所有数据进行循环，过滤不符合条件的数据，不会带来副作用 12345int[] array = &#123;1, 2, 3, 4, 5&#125;Stream stream = Stream.of(array)stream.filter(e -&gt; e / 2 == 0).forEach(System.out::println) // --&gt; &#123;2, 4&#125; map&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;获得stream对象中的数据进行操作，对其内部的所有数据进行循环操作，若用它进行过滤，将会带来副作用，不仅能返回值，同时返回可过滤后的结果Boolean值 1234567int[] array = &#123;1, 2, 3, 4, 5&#125;Stream stream = Stream.of(array)stream.filter(e -&gt; e / 2 == 0).map(e -&gt; e*2).forEach(System.out::println) // --&gt; &#123;4, 8&#125; reduce&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该函数处于stream终端，用了reduce函数后不可再用stream的其他方法，若需要使用stream的方法时需要重新stream化.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在java8中reduce方法重载有三个，三个方法中的参数数量不同 1234567# supplier为reduce方法开始的参数，同时决定着返回值的类型# 当stream为并行化时才会调用combinerstream.parallel().reduce(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner)stream.reduce(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner)stream.reduce(BiConsumer&lt;R, ? super T&gt; accumulator) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 123stream.filter(e -&gt; e / 2 == 0).map(e -&gt; e*2).reduce() javaScriptiteratoriterable","categories":[{"name":"filter","slug":"filter","permalink":"https://chenadminchen.github.io/categories/filter/"}],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"map","slug":"map","permalink":"https://chenadminchen.github.io/tags/map/"},{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"python","slug":"python","permalink":"https://chenadminchen.github.io/tags/python/"},{"name":"filter","slug":"filter","permalink":"https://chenadminchen.github.io/tags/filter/"},{"name":"reduce","slug":"reduce","permalink":"https://chenadminchen.github.io/tags/reduce/"}]},{"title":"mongodb 基本语法学习（一）","slug":"mongodb-learn-1","date":"2019-07-06T08:45:58.790Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2019/07/06/mongodb-learn-1/","link":"","permalink":"https://chenadminchen.github.io/2019/07/06/mongodb-learn-1/","excerpt":"","text":"mongodb 基本语法操作mongodb的数据库切换操作1234show dbs; #查看mongodb数据库中存在的数据库use datebase_name; #使用指定的数据库show collections; #查看某个数据库下所有的collction 对collection操作json的数据格式1234567891011121314151617181920212223242526272829303132consult: &#123; \"_id\": 111, 'user_id':'1234@163.com', 'public': false, 'time':'2017.11.01 12:25:33' 'number':1 'title':'如果长高', 'content':'怎么才能长高？？？？', 'resouces':[ &#123; 'url':\"\" 'type':\"\" 'comment':\"\" &#125; ] 'reply':[ &#123; 'content':'test1' 'time':\"\" 'user_id': '123@yf.com' &#125;, &#123; 'content':'test2' 'time': 'user_id': '222@yf.com' &#125; ]&#125; find()操作&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以下基于该json数据进行操作 123db.consult.find().pretty(); #查看consult下的数据并以json格式展示db.consult.find(&#123;'_id':111&#125;); #查找_id为111的数据db.consult.find(&#123;'_id':111,'reply.user_id':'222@yf.com'&#125;); #查找 _id: 111,reply数据组中user_id ： '222@yf.com'的数据 remove()操作1db.consult.remove() #删除consult内的数据 update()操作123456789101112db.consult.update(&#123;'_id':111&#125;,&#123;$set:&#123;'public':false&#125;&#125;); #修改 _id : 111中字段public的值#数组修改器push() 数组中存在则修改，若不存在则添加db.conuslt.update(&#123;'_id':111,'reply.user_id':'222@yf.com'&#125;,&#123;$push:&#123;'reply.content':'测试'&#125;&#125;); #修改 '_id':111中reply中数组中'reply.user_id':'222@yf.com'的content值#对json内的数值字段进行操作，$incdb.consult.update(&#123;'_id':111&#125;,&#123;$inc:&#123;'number' : 1 &#125;&#125;); #将json内的number值加1db.consult.update(&#123;'_id':111&#125;,&#123;$inc:&#123;'number ': -1 &#125;&#125;); #将json内的number值减1#对json内普通字段进行操作，并能改变字段类型，$setdb.consult.update(&#123;'_id':111&#125;,&#123;$set:&#123;'number' : 3 &#125;&#125;); #修改number值db.consult.update(&#123;'_id':111&#125;,&#123;$set:&#123;'number' : 'test1' &#125;&#125;); #将number字段类型数值型改为字符串型","categories":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/categories/mongodb/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/tags/mongodb/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-07-06T08:45:58.774Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2019/07/06/hello-world/","link":"","permalink":"https://chenadminchen.github.io/2019/07/06/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"dart-object-copy","slug":"dart-object-copy","date":"2019-06-04T07:36:45.000Z","updated":"2019-08-27T14:50:18.984Z","comments":true,"path":"2019/06/04/dart-object-copy/","link":"","permalink":"https://chenadminchen.github.io/2019/06/04/dart-object-copy/","excerpt":"","text":"dart object copy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在创建一个普通的实体类，并且该类带有main方法，如下代码 12345678910111213141516171819202122232425262728293031323334//copy class import 'dart:math';void main() &#123; Todo todo1= Todo(\"todo1\",10); Todo todo2 = Todo.copy(todo1); print(\"todo1 == todo2 : $&#123;todo1 == todo2&#125;\"); todo2.todo = \"fffff\"; print(\"todo2 tom todo1.copy: $&#123;todo1 == todo2&#125;\"); &#125;class Todo&#123; String todo; int priority; int hash; factory Todo.copy(Todo t)&#123; return new Todo(t.todo,t.priority,hash:t.hash); &#125; Todo(this.todo,this.priority,&#123;this.hash&#125;); bool operator == (o)&#123; return o is Todo &amp;&amp; o.todo == todo &amp;&amp; o.priority == priority; &#125; int get hashCode =&gt; hash *100 ;&#125;","categories":[],"tags":[{"name":"dart","slug":"dart","permalink":"https://chenadminchen.github.io/tags/dart/"},{"name":"class","slug":"class","permalink":"https://chenadminchen.github.io/tags/class/"}]},{"title":"java chain-of-responsibility-pattern","slug":"java-Chain-of-Responsibility-Pattern","date":"2019-05-04T07:45:34.000Z","updated":"2019-08-27T14:50:18.984Z","comments":true,"path":"2019/05/04/java-Chain-of-Responsibility-Pattern/","link":"","permalink":"https://chenadminchen.github.io/2019/05/04/java-Chain-of-Responsibility-Pattern/","excerpt":"","text":"chain-of-responsibility-pattern责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。 学习地址 code implement创建抽象的记录器类1234567891011121314151617181920212223242526272829303132333435/** * abstract class can have construction */public abstract class AbstractLogger &#123; public static int INFO =1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; public AbstractLogger() &#123; &#125; public AbstractLogger(int level) &#123; this.level = level; &#125; protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger)&#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level,String message)&#123; if(this.level &lt;= level)&#123; write(message); &#125; if(nextLogger != null)&#123; nextLogger.logMessage(level,message); &#125; &#125; abstract protected void write(String message);&#125; 创建扩展该记录器类的实体类123456class ConsoleLogger(level: Int) : AbstractLogger(level) &#123; override fun write(message: String) &#123; println(\"Standard console::Logger: $message\") &#125;&#125; 123456class ErrorLogger(level:Int):AbstractLogger(level) &#123; override fun write(message: String?) &#123; println(\"Standard error::ErrorLogger: $message\") &#125;&#125; 123456class FileLogger(level: Int) : AbstractLogger(level) &#123; override fun write(message: String) &#123; println(\"Standard file::FileLogger: $message\") &#125;&#125; 调用 创建不同类型的记录器。赋予它们不同的错误级别，并在每个记录器中设置下一个记录器。每个记录器中的下一个记录器代表的是链的一部分 12345678910111213141516171819202122232425class AbstractMain &#123; companion object&#123; fun getChainOfLoggers():AbstractLogger&#123; var errorLogger:AbstractLogger = ErrorLogger(AbstractLogger.ERROR) var consoleLogger:AbstractLogger = ConsoleLogger(AbstractLogger.INFO) var fileLogger:AbstractLogger = FileLogger(AbstractLogger.DEBUG) errorLogger.setNextLogger(fileLogger) fileLogger.setNextLogger(consoleLogger) return errorLogger &#125; &#125;&#125;fun main() &#123; var loggerChain = AbstractMain.getChainOfLoggers() loggerChain.logMessage(AbstractLogger.INFO,\"this is an information\") loggerChain.logMessage(AbstractLogger.DEBUG,\"this is a debug level information.\") loggerChain.logMessage(AbstractLogger.ERROR,\"this is a error information.\")&#125; 结果输出12345678Standard console::Logger: this is an informationStandard file::FileLogger: this is a debug level information.Standard console::Logger: this is a debug level information.Standard error::ErrorLogger: this is a error information.Standard file::FileLogger: this is a error information.Standard console::Logger: this is a error information.","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"pattern","slug":"pattern","permalink":"https://chenadminchen.github.io/tags/pattern/"}]},{"title":"spring-boot-distributed-transaction-processing","slug":"spring-boot-distributed-transaction-processing","date":"2019-03-18T05:35:34.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2019/03/18/spring-boot-distributed-transaction-processing/","link":"","permalink":"https://chenadminchen.github.io/2019/03/18/spring-boot-distributed-transaction-processing/","excerpt":"","text":"XA协议（eXtended Architecture）XA协议是X/Open（the Open Group）提出的,为解决分布式事务处理（distrubuted-transaction-processing）的方案，在XA协议中使用了2pc理论实现事务管理机制，它将一个应用程序的执行流程分为如下几种： 应用程序（AP:application program） 事务管理器（TM:transaction management） 资源管理器(RM:resource management) 通信资源管理器(CRM:communication resource management) &nbsp;&nbsp;&nbsp;&nbsp;通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。 所谓全局事务，是指分布式事务处理环境中，多个数据库可能需要共同完成一个工作，这个工作即是一个全局事务，例如，一个事务中可能更新几个不同的数据库。对数据库的操作发生在系统的各处但必须全部被提交或回滚。此时一个数据库对自己内部所做操作的提交不仅依赖本身操作是否成功，还要依赖与全局事务相关的其它数据库的操作是否成功，如果任一数据库的任一操作失败，则参与此事务的所有数据库所做的所有操作都必须回滚。&nbsp;&nbsp;&nbsp;&nbsp;一般情况下，某一数据库无法知道其它数据库在做什么，因此，在一个 DTP 环境中，交易中间件是必需的，由它通知和协调相关数据库的提交或回滚。而一个数据库只将其自己所做的操作（可恢复）影射到全局事务中。 &nbsp;&nbsp;&nbsp;&nbsp;XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 2PC（Two Phase Commitment Protocol）&nbsp;&nbsp;&nbsp;&nbsp;二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。 准备阶段 事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。 可以进一步将准备阶段分为以下三个步骤： 1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。 2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作） 3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 提交阶段 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源) 接下来分两种情况分别讨论提交阶段的过程。 1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。 2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 3）参与者节点向协调者节点发送”完成”消息。 4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。 如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时： 1）协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。 2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 3）参与者节点向协调者节点发送”回滚完成”消息。 4）协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。 二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的： 同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。 3PC（Three Phase Commitment Protocol）三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 与两阶段提交不同的是，三阶段提交有两个改动点: 引入超时机制。同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。 也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。 CanCommit阶段 3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No PreCommit阶段 &nbsp;&nbsp;&nbsp;&nbsp;协调者根据参与者的反应情况来决定是否可以记性事务的PreCommit操作。根据响应情况，有以下两种可能。&nbsp;&nbsp;&nbsp;&nbsp;假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 1.发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。 2.事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 3.响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 &nbsp;&nbsp;&nbsp;&nbsp;假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 1.发送中断请求 协调者向所有参与者发送abort请求。 2.中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。 doCommit阶段 该阶段进行真正的事务提交，也可以分为以下两种情况。 1) 执行提交 1.发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。 2.事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 3.响应反馈 事务提交完之后，向协调者发送Ack响应。 4.完成事务 协调者接收到所有参与者的ack响应之后，完成事务。 2) 中断事务协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 1.发送中断请求 协调者向所有参与者发送abort请求 2.事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 3.反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息 4.中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。 &nbsp;&nbsp;&nbsp;&nbsp;在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ） 2PC与3PC的区别&nbsp;&nbsp;&nbsp;&nbsp;相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。了解了2PC和3PC之后，我们可以发现，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。后面的文章会介绍这个公认为难于理解但是行之有效的Paxos算法。 CAP理论&nbsp;&nbsp;&nbsp;&nbsp;一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 一致性（Consistency） 一致性指“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。 可用性（Availability） 可用性指“Reads and writes always succeed”，即服务一直可用，而且是正常响应时间。 分区容错性（Partition tolerance） 分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 CAP权衡:&nbsp;&nbsp;&nbsp;&nbsp;通过CAP理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ &nbsp;&nbsp;&nbsp;&nbsp;对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 Base理论&nbsp;&nbsp;&nbsp;&nbsp;eBay的架构师Dan Pritchett源于对大规模分布式系统的实践总结，在ACM上发表文章提出BASE理论，BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。 BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。 基本可用（Basically Available） 基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。 软状态（ Soft State） 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。 最终一致性（ Eventual Consistency） 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 ACID理论ACID理论是指在数据库管理系统（DBMS）中事务所具有的四个特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 原子性 &nbsp;&nbsp;&nbsp;&nbsp;事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。通常，与某个事务关联的操作具有共同的目标，并且是相互依赖的。如果系统只执行这些操作的一个子集，则可能会破坏事务的总体目标。原子性消除了系统处理操作子集的可能性。 一致性 &nbsp;&nbsp;&nbsp;&nbsp;事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构（如 B 树索引或双向链表）都必须是正确的。某些维护一致性的责任由应用程序开发人员承担，他们必须确保应用程序已强制所有已知的完整性约束。例如，当开发用于转帐的应用程序时，应避免在转帐过程中任意移动小数点。 隔离性 &nbsp;&nbsp;&nbsp;&nbsp;由并发事务所作的修改必须与任何其它并发事务所作的修改隔离。事务查看数据时数据所处的状态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看中间状态的数据。这称为可串行性，因为它能够重新装载起始数据，并且重播一系列事务，以使数据结束时的状态与原始事务执行的状态相同。当事务可序列化时将获得最高的隔离级别。在此级别上，从一组可并行执行的事务获得的结果与通过连续运行每个事务所获得的结果相同。由于高度隔离会限制可并行执行的事务数，所以一些应用程序降低隔离级别以换取更大的吞吐量。 持久性 &nbsp;&nbsp;&nbsp;&nbsp;事务完成之后，它对于系统的影响是永久性的。该修改即使出现致命的系统故障也将一直保持。 ACID和BASE的区别与联系ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。 ACID和BASE代表了两种截然相反的设计哲学 在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用。 柔性理论与刚性理论事务产生的原因 多数据源产生事务（传统项目中连接不同的数据库） 解決方案：采用jta+ Atomikos实现 微服务下的事务 解決方案： LCN框架 GTS框架 TCC补偿框架 LCNGTSTCC补偿框架","categories":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/categories/spring-boot/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"https://chenadminchen.github.io/tags/spring-boot/"},{"name":"distributed-transaction-processing","slug":"distributed-transaction-processing","permalink":"https://chenadminchen.github.io/tags/distributed-transaction-processing/"}]},{"title":"ehcache","slug":"ehcache","date":"2019-02-22T08:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2019/02/22/ehcache/","link":"","permalink":"https://chenadminchen.github.io/2019/02/22/ehcache/","excerpt":"","text":"ehcache介绍&nbsp;&nbsp;&nbsp;&nbsp;EHCache是一个非常轻量级的缓冲，是Hibernate的默认缓存。同时ehcache应该说是java范围内使用最广泛的缓存。同时它也支持分布式缓存。也提供了磁盘，内存的缓存存储。 Ehcache支持的数据存储包括：&nbsp;&nbsp;&nbsp;&nbsp;堆内存储 - 利用Java的堆内存来存储缓存条目。使用与Java应用程序相同的由JVM垃圾收集器管理的堆内存。JVM使用的堆空间越多，应用程序性能受到的垃圾收集暂停影响越大。此存储最快但空间最小。&nbsp;&nbsp;&nbsp;&nbsp;堆外存储 - 只有可用RAM限制大小。不受Java垃圾收集(GC)的影响。它的速度非常快，但比堆内存储要慢，因为数据的存储和重新访问的都要经过堆内存储层。&nbsp;&nbsp;&nbsp;&nbsp;磁盘存储 - 利用磁盘(文件系统)来存储缓存条目。这种类型的存储资源通常非常丰富，但是比基于ram的存储要慢得多。对于使用磁盘存储的所有应用程序，建议使用一个快速且专用的磁盘来优化吞吐量。&nbsp;&nbsp;&nbsp;&nbsp;集群存储 - 这个数据存储是远程服务器上的一个缓存。远程服务器可以有选择地提供一个故障转移服务器使可用性更高。集群存储由于网络延迟和建立客户机/服务器一致性等因素而受到性能的惩罚，因此这一层的性能比本地的堆外存储要慢。 ehcache与redis区别&nbsp;&nbsp;&nbsp;&nbsp;ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。&nbsp;&nbsp;&nbsp;&nbsp;redis是通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。 如果是单个应用或者对缓存访问要求很高的应用，用ehcache。如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。","categories":[],"tags":[{"name":"cache","slug":"cache","permalink":"https://chenadminchen.github.io/tags/cache/"}]},{"title":"android_mockito","slug":"android_mockito","date":"2019-01-24T05:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2019/01/24/android_mockito/","link":"","permalink":"https://chenadminchen.github.io/2019/01/24/android_mockito/","excerpt":"","text":"","categories":[],"tags":[{"name":"android","slug":"android","permalink":"https://chenadminchen.github.io/tags/android/"},{"name":"mockito","slug":"mockito","permalink":"https://chenadminchen.github.io/tags/mockito/"}]},{"title":"android_DataBinding","slug":"android_dataBinding","date":"2019-01-16T08:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2019/01/16/android_dataBinding/","link":"","permalink":"https://chenadminchen.github.io/2019/01/16/android_dataBinding/","excerpt":"","text":"DataBinding&nbsp;&nbsp;&nbsp;&nbsp;DataBinding用于Fragment与UI交互数据&nbsp;&nbsp;&nbsp;&nbsp;做法如下： build.gradle 1234567android&#123; ... dataBinding &#123; enabled = true &#125; ...&#125; .xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;layout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot; xmlns:bind=&quot;http://schemas.android.com/apk/res-auto&quot; xmlns:tools=&quot;http://schemas.android.com/tools&quot;&gt; &lt;data&gt; &lt;import type=&quot;com.yf.axworker.model.TrainingHistory&quot; /&gt; &lt;import type=&quot;android.bluetooth.BluetoothGatt&quot; /&gt; &lt;import type=&quot;android.databinding.ObservableField&quot; /&gt; &lt;variable name=&quot;conclusionH&quot; type=&quot;ObservableField&amp;lt;String&amp;gt;&quot; /&gt; &lt;variable name=&quot;bleStatus&quot; type=&quot;android.databinding.ObservableInt&quot; /&gt; &lt;variable name=&quot;angle&quot; type=&quot;android.databinding.ObservableByte&quot; /&gt; &lt;variable name=&quot;healthData&quot; type=&quot;com.yf.axworker.data.model.HealthData&quot; /&gt; &lt;/data&gt; &lt;android.support.constraint.ConstraintLayout android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;match_parent&quot; tools:context=&quot;com.yf.axworker.ui.fragment.TrainingFragment&quot;&gt; &lt;TextView android:id=&quot;@+id/lbl_cancel_training&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginTop=&quot;8dp&quot; android:text=&quot;@&#123;bleStatus&#125;&quot; app:layout_constraintEnd_toEndOf=&quot;@+id/btn_finish_training&quot; app:layout_constraintStart_toStartOf=&quot;@+id/btn_finish_training&quot; app:layout_constraintTop_toBottomOf=&quot;@+id/btn_finish_training&quot; /&gt; &lt;TextView android:id=&quot;@+id/txt_cancel_training&quot; android:layout_width=&quot;wrap_content&quot; android:layout_height=&quot;wrap_content&quot; android:layout_marginTop=&quot;8dp&quot; android:text=&quot;@&#123;healthData.id&#125;&quot; app:layout_constraintEnd_toEndOf=&quot;@+id/btn_finish_training&quot; app:layout_constraintStart_toStartOf=&quot;@+id/btn_finish_training&quot; app:layout_constraintTop_toBottomOf=&quot;@+id/btn_finish_training&quot; /&gt; &lt;/android.support.constraint.ConstraintLayout&gt;&lt;/layout&gt; .java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.yf.axworker.ui.fragment;import android.animation.Animator;import android.animation.AnimatorInflater;import android.bluetooth.BluetoothGatt;import android.content.Context;import android.databinding.DataBindingUtil;import android.databinding.Observable;import android.databinding.ObservableByte;import android.databinding.ObservableInt;import android.os.Bundle;import android.os.Handler;import android.support.annotation.NonNull;import android.support.annotation.Nullable;import android.support.design.widget.TabLayout;import android.support.v4.app.Fragment;import android.support.v7.app.ActionBar;import android.view.GestureDetector;import android.view.LayoutInflater;import android.view.MotionEvent;import android.view.View;import android.view.ViewGroup;import com.yf.axworker.R;import com.yf.axworker.data.model.HealthData;import com.yf.axworker.databinding.FragmentTrainingBinding;import com.yf.axworker.event.BleConnectionReport;import com.yf.axworker.event.BleServicesDiscoveredEvent;import com.yf.axworker.event.HrReport;import com.yf.axworker.event.HrReportEvent;import com.yf.axworker.event.PersonalHrReportEvent;import com.yf.axworker.model.TrainingHistory;import com.yf.axworker.model.User;import com.yf.axworker.ui.adapter.SafetyAidChartsAdapter;import com.yf.axworker.ui.base.BaseFragment;import com.yf.axworker.utils.Constants;import com.yf.axworker.utils.UserInfoUtil;import org.greenrobot.eventbus.EventBus;import org.greenrobot.eventbus.Subscribe;import org.greenrobot.eventbus.ThreadMode;import java.util.ArrayList;import java.util.Date;import java.util.HashMap;import java.util.List;import java.util.concurrent.TimeUnit;import lombok.extern.slf4j.Slf4j;@Slf4jpublic class TrainingFragment extends BaseFragment &#123; FragmentTrainingBinding binding; private Animator aniBleRotation; private ObservableInt bleStatus = new ObservableInt(BluetoothGatt.STATE_CONNECTED); private ObservableByte angle = new ObservableByte(); private ObservableInt duration = new ObservableInt(); private ObservableField&lt;String&gt; conclusionH = new ObservableField&lt;&gt;(); TrainingHistory trainingInfo; // public TrainingFragment() &#123; // Required empty public constructor &#125; @Override public void onAttach(Context context) &#123; super.onAttach(context); if (context instanceof FragmentAction) &#123; mListener = (FragmentAction) context; &#125; else &#123; throw new RuntimeException(context.toString() + \" must implement FragmentAction\"); &#125; baseActivity.getActivityComponent().inject(this); &#125; @Override public void onDetach() &#123; super.onDetach(); mListener = null; &#125; @Override public void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); &#125; @Override public View onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) &#123; binding = DataBindingUtil.inflate(inflater, R.layout.fragment_training, container, false); return binding.getRoot(); &#125; @Override public void init() &#123; tryGetTrainingAngle(); // binding.setController(controller); //綁定数据 binding.setBleStatus(bleStatus); binding.setTrainingInfo(trainingInfo); binding.setDuration(duration); binding.setConclusionH(conclusionH); test(); &#125; //change duration value public void test()&#123; duration.set(4); &#125;&#125;","categories":[],"tags":[{"name":"android","slug":"android","permalink":"https://chenadminchen.github.io/tags/android/"},{"name":"DataBinding","slug":"DataBinding","permalink":"https://chenadminchen.github.io/tags/DataBinding/"}]},{"title":"android_sharedPreferences","slug":"android_sharedPreferences","date":"2018-12-22T05:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/12/22/android_sharedPreferences/","link":"","permalink":"https://chenadminchen.github.io/2018/12/22/android_sharedPreferences/","excerpt":"","text":"sharedPreferences的用法&nbsp;&nbsp;&nbsp;&nbsp;sharedPreferences的类用于存储数据，共享数据","categories":[],"tags":[{"name":"android","slug":"android","permalink":"https://chenadminchen.github.io/tags/android/"}]},{"title":"android","slug":"linux_android_kvm_set","date":"2018-11-27T08:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/11/27/linux_android_kvm_set/","link":"","permalink":"https://chenadminchen.github.io/2018/11/27/linux_android_kvm_set/","excerpt":"","text":"linux-androidlinux下安装android-studio,开启模拟器时，显示/dev/kvm不存在 进入BIOS系统设置支持kvm，开启虚拟机 1Virtualization technolog = enabled 重启后，/dev/kvm存在 1.将用户添加到kvm组 1.1 kvm组不存在1234567egrep -c &apos;(vmx|svm)&apos; /proc/cpuinfosudo apt-get install cpu-checkersudo kvm-ok #检查kvm是否存在sudo apt-get install qemu-kvm #创建kvm组 1.2 kvm组存在123id #查看当前用户存在的组信息usermod -a -G kvm user_name #将user_name添加到kvm 组内 2.重启系统配置生效","categories":[],"tags":[{"name":"android","slug":"android","permalink":"https://chenadminchen.github.io/tags/android/"},{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/tags/linux/"}]},{"title":"mysql-context-search","slug":"mysql-full-text-search","date":"2018-11-22T08:00:00.000Z","updated":"2019-08-27T14:50:18.984Z","comments":true,"path":"2018/11/22/mysql-full-text-search/","link":"","permalink":"https://chenadminchen.github.io/2018/11/22/mysql-full-text-search/","excerpt":"","text":"mysql context search mysql的表中的字段进行全文搜索,(学习地址)[https://dev.mysql.com/doc/refman/8.0/en/fulltext-search.html] 建立指定需要进行全文搜索的字段的的索引 索引创建1234ALTER TABLE `user` ADD FULLTEXT INDEX `ft_user` (`name`, `email`, `phone`), ADD INDEX `index9` (`name` ASC, `email` ASC, `phone` ASC); ; 查询12345#无法查询一个字段SELECT id,name,phone,email from user where match(name,email,phone) against(&quot;张&quot; IN BOOLEAN MODE);#查询成功SELECT id,name,phone,email from user where match(name,email,phone) against(&quot;张小&quot; IN BOOLEAN MODE); window解决问题 在my.ini配置文件中添加如下 12innodb_ft_min_token_size=1ngram-token-size=1 重启mysql server reset index 123ALTER TABLE `yfaf`.`user` ADD FULLTEXT INDEX `index9` (`name`, `phone`, `email`) WITH PARSER ngram;; linux解决问题 在/etc/mysql/mysql.conf.d/mysqld.cnf配置文件中添加如下 注意项：需要在[mysqld]的组下添加1234[mysqld].....innodb_ft_min_token_size=1ngram-token-size=1 重启mysql server reset index `mysqlALTER TABLE yfaf.userADD FULLTEXT INDEX index9 (name, phone, email) WITH PARSER ngram;;","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"full-text","slug":"full-text","permalink":"https://chenadminchen.github.io/tags/full-text/"}]},{"title":"learn","slug":"learn","date":"2018-09-17T02:58:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/09/17/learn/","link":"","permalink":"https://chenadminchen.github.io/2018/09/17/learn/","excerpt":"","text":"ad-hocgrubjavajava编码规范来自Google kotlinkotlin 官方编码约定 pythonpython 编码规范官方指导 flutterflutter编码规范指导 dartdart 编码规范官方指导 javaScript javascript 编码规范 来自google来自airbnb code check代码审查中好的建议","categories":[{"name":"learn","slug":"learn","permalink":"https://chenadminchen.github.io/categories/learn/"}],"tags":[{"name":"learn","slug":"learn","permalink":"https://chenadminchen.github.io/tags/learn/"}]},{"title":"zookeeper","slug":"zookeeper-based-1-command","date":"2018-09-13T06:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/09/13/zookeeper-based-1-command/","link":"","permalink":"https://chenadminchen.github.io/2018/09/13/zookeeper-based-1-command/","excerpt":"","text":"zookeeper server start12345#start serverchen@chen:~/work/service/zookeeper-3.4.13/bin$ ./kafka-server-start.sh ../config/server.properties#start clientchen@chen:~/work/service/zookeeper-3.4.13/bin$ ./zkCli.sh -server 127.0.0.1:2181 zookeeper command123456789101112ls /#顺序节点create -s test#临时节点create -e test#持久节点create test rmr test","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"https://chenadminchen.github.io/tags/zookeeper/"}]},{"title":"mysql-8-window-function","slug":"mysql-8-window","date":"2018-09-12T06:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/09/12/mysql-8-window/","link":"","permalink":"https://chenadminchen.github.io/2018/09/12/mysql-8-window/","excerpt":"","text":"mysql window-function 介绍&nbsp;&nbsp;&nbsp;&nbsp;窗口函数早在SQL2003规范中就成为了标准SQL的一部分。而在mysql8.0带来了标准SQL的窗口函数功能，窗口函数与分组聚合函数相似的都提供了对一组行数据的统计计算。但与分组聚合函数将多行合并成一行不同是窗口函数会在结果结果集中展现每一行的聚合。窗口函数有两种使用方式，首先是常规的SQL聚合功能函数和特殊的窗口函数。 &nbsp;&nbsp;&nbsp;&nbsp;常规的聚合功能函数如：COUNT,SUM等函数。而窗口函数专有的则是RANK, DENSE_RANK, PERCENT_RANK, CUME_DIST, NTILE, ROW_NUMBER,FIRST_VALUE, LAST_VALUE, NTH_VALUE, LEADand LAG等函数。 &nbsp;&nbsp;&nbsp;&nbsp;窗口函数的主要优点是不会导致单个输出记录而进行分组。相反地，记录保留其单独的身份，并将聚合值添加到每条记录（行） films structure1234567891011121314151617181920CREATE TABLE films ( id int(11) primary key not null, release_year int(11), category_id int(11), rating decimal(3,2));insert into films (id,release_year,category_id,rating ) values(&apos;1&apos;, &apos;2015&apos;, &apos;1&apos;, &apos;8.00&apos;),(&apos;2&apos;, &apos;2015&apos;, &apos;2&apos;, &apos;8.50&apos;),(&apos;3&apos;, &apos;2015&apos;, &apos;3&apos;, &apos;9.00&apos;),(&apos;4&apos;, &apos;2016&apos;, &apos;2&apos;, &apos;8.20&apos;),(&apos;5&apos;, &apos;2016&apos;, &apos;1&apos;, &apos;8.40&apos;),(&apos;6&apos;, &apos;2017&apos;, &apos;2&apos;, &apos;7.00&apos;),(&apos;7&apos;, &apos;2015&apos;, &apos;1&apos;, &apos;7.20&apos;),(&apos;8&apos;, &apos;2015&apos;, &apos;3&apos;, &apos;5.80&apos;),(&apos;9&apos;, &apos;2016&apos;, &apos;2&apos;, &apos;7.00&apos;),(&apos;10&apos;, &apos;2017&apos;, &apos;4&apos;, &apos;8.50&apos;),(&apos;11&apos;, &apos;2017&apos;, &apos;1&apos;, &apos;9.20&apos;),(&apos;12&apos;, &apos;2015&apos;, &apos;2&apos;, &apos;8.50&apos;); select1select * from films; id release_year category_id rating 1 2015 1 8.00 2 2015 2 8.50 3 2015 3 9.00 4 2016 2 8.20 5 2016 1 8.40 6 2017 2 7.00 7 2015 1 7.20 8 2015 3 5.80 9 2016 2 7.00 10 2017 4 8.50 11 2017 1 9.20 12 2015 2 8.50 cume_dist 计算结果为相对位置/总行数,返回值为(0,1]注意：对于重复值，计算的时候，取重复值的最后一行的位置 percent_rank 计算方法为（相对位置-1）/（总行数-1）注意：对于重复值，计算的时候，取重复值的第一行的位没有重复值的排序[记录相等也是不重复的]可以进行分页使用 row_number 排序返回值 123456789-- cume_dist() / row_number() / select f.id,f.release_year,f.category_id,f.rating,-- cume_dist() OVER (order by f.rating) as sum,cume_dist() OVER w as total,row_number() over w as `row`,percent_rank() over w as dfsfrom films fWINDOW w as (order by f.rating); id release_year rating total row dfs 8 2015 3 5.80 0.08333333333333333 1 0 6 2017 2 7.00 0.25 2 0.09090909090909091 9 2016 2 7.00 0.25 3 0.09090909090909091 7 2015 1 7.20 0.3333333333333333 4 0.2727272727272727 1 2015 1 8.00 0.4166666666666667 5 0.36363636363636365 4 2016 2 8.20 0.5 6 0.45454545454545453 5 2016 1 8.40 0.5833333333333334 7 0.5454545454545454 2 2015 2 8.50 0.8333333333333334 8 0.6363636363636364 10 2017 4 8.50 0.8333333333333334 9 0.6363636363636364 12 2015 2 8.50 0.8333333333333334 10 0.6363636363636364 3 2015 3 9.00 0.9166666666666666 11 0.9090909090909091 11 2017 1 9.20 1 12 1 first_value FIRST_VALUE 返回组中数据窗口的分组中的第一个值FIRST_VALUE ( [scalar_expression )OVER ( [ partition_by_clause ] order_by_clause ) last_value LAST_VALUE返回组中数据窗口的分组中的最后一个值LAST_VALUE ( [scalar_expression )OVER ( [ partition_by_clause ] order_by_clause ) NTH_VALUE NTH_VALUE（rating, x）返回组中数据窗口的分组第x+1的rating值，没有在计算到中的为null123456789101112select *,first_value(rating) over w as `first` -- based on partition by release_year,last_value(rating) over w as `last` -- based on partition by release_year,NTH_VALUE(rating, 2) OVER w AS &apos;second&apos; from filmswindow w as (PARTITION BY release_year-- order by id ROWS --?? UNBOUNDEDPRECEDING); id release_year category_id rating first last second 1 2015 1 8.00 8.00 8.00 NULL 2 2015 2 8.50 8.00 8.50 NULL 3 2015 3 9.00 8.00 9.00 NULL 7 2015 1 7.20 8.00 7.20 7.20 8 2015 3 5.80 8.00 5.80 7.20 12 2015 2 8.50 8.00 8.50 7.20 4 2016 2 8.20 8.20 8.20 NULL 5 2016 1 8.40 8.20 8.40 NULL 9 2016 2 7.00 8.20 7.00 NULL 6 2017 2 7.00 7.00 7.00 NULL 10 2017 4 8.50 7.00 8.50 NULL 11 2017 1 9.20 7.00 9.20 NULL laglead123456select *,lag(rating) over w as `lag` -- last row rating to show lag, lag row is null, so lag is null,lead(rating) over w as `lead` -- next row rating to show lead , next row is null, so lead is null from reptile_dobao.filmswindow w as (partition by release_year) -- partition by 分区 ,lag / lead based on partition of release_year; id release_year category_id rating lag lead 1 2015 1 8.00 NULL 8.50 2 2015 2 8.50 8.00 9.00 3 2015 3 9.00 8.50 7.20 7 2015 1 7.20 9.00 5.80 8 2015 3 5.80 7.20 8.50 12 2015 2 8.50 5.80 NULL 4 2016 2 8.20 NULL 8.40 5 2016 1 8.40 8.20 7.00 9 2016 2 7.00 8.40 NULL 6 2017 2 7.00 NULL 8.50 10 2017 4 8.50 7.00 9.20 11 2017 1 9.20 8.50 NULL lag(v,n,x) ,lead(v,n,x)带参数时，v 是字段，n指分组中区间数据的行数，n+1开始给值，当计算值没有值时用x值表式123456select *,lag(rating,2,0) over w as `lag` -- last row rating to show lag, lag row is 0, so lag is 0,lead(rating,2,0) over w as `lead` -- next row rating to show lead , next row is null, so lead is null from reptile_dobao.filmswindow w as (partition by release_year) -- partition by 分区 ,lag / lead based on partition of release_year; id release_year category_id rating lag lead 1 2015 1 8.00 0.00 9.00 2 2015 2 8.50 0.00 7.20 3 2015 3 9.00 8.00 5.80 7 2015 1 7.20 8.50 8.50 8 2015 3 5.80 9.00 0.00 12 2015 2 8.50 7.20 0.00 4 2016 2 8.20 0.00 7.00 5 2016 1 8.40 0.00 0.00 9 2016 2 7.00 8.20 0.00 6 2017 2 7.00 0.00 9.20 10 2017 4 8.50 0.00 0.00 11 2017 1 9.20 7.00 0.00 RANK() 跳跃排序 NTILE() 连续排序","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"window-function","slug":"window-function","permalink":"https://chenadminchen.github.io/tags/window-function/"}]},{"title":"mysql-8.11 install","slug":"mint-install-mysql8","date":"2018-09-06T04:35:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/09/06/mint-install-mysql8/","link":"","permalink":"https://chenadminchen.github.io/2018/09/06/mint-install-mysql8/","excerpt":"","text":"download mysql deb[下载地址](https://dev.mysql.com/downloads/repo/apt/) install deb[文档地址](https://dev.mysql.com/doc/mysql-apt-repo-quick-guide/en/) apt install mysql-serverget root password登录时不需要使用密码，提示找不到 UNIX socket 123456789chen@chen-YangTianT4900c-00:~/download$ sudo mysqld_safe --skip-grant-tables --skip-syslog --skip-networkingLogging to &apos;/var/lib/mysql/chen-YangTianT4900c-00.err&apos;.2018-09-06T02:56:11.619644Z mysqld_safe Directory &apos;/var/run/mysqld&apos; for UNIX socket file don&apos;t exists.chen@chen-YangTianT4900c-00:~/download$ sudo -u mysql mysqld_safe --skip-grant-tables --skip-syslog --skip-networking2018-09-06T02:56:18.987750Z mysqld_safe Logging to &apos;/var/lib/mysql/chen-YangTianT4900c-00.err&apos;.2018-09-06T02:56:18.993047Z mysqld_safe Directory &apos;/var/run/mysqld&apos; for UNIX socket file don&apos;t exists. 创建mysqld文件夹，给与权限 12sudo mkdir /var/run/mysqldchen@chen-YangTianT4900c-00:~/download$ sudo chmod 777 /var/run/mysqld 登录1mysql -u root 修改密码,密码可从其他数据库上拷12update mysql.user set plugin=&apos;mysql_native_password&apos;, authentication_string=&apos;*8B98A17FF7D791BC9F0216DDC7658432C4B866FB&apos; where user=&apos;root&apos;; FLUSH PRIVILEGES; 12345678910111213141516171819thanks to @thusharaK I could reset the root password without knowing the old password.On ubuntu I did the following:sudo service mysql stopsudo mysqld_safe --skip-grant-tables --skip-syslog --skip-networkingThen run mysql in a new terminal:mysql -u rootAnd run the following queries to change the password:UPDATE mysql.user SET authentication_string=PASSWORD(&apos;password&apos;) WHERE User=&apos;root&apos;;FLUSH PRIVILEGES;In MySQL 5.7, the password field in mysql.user table field was removed, now the field name is &apos;authentication_string&apos;.Quit the mysql safe mode and start mysql service by:mysqladmin shutdownsudo service mysql start","categories":[],"tags":[{"name":"mysql install","slug":"mysql-install","permalink":"https://chenadminchen.github.io/tags/mysql-install/"}]},{"title":"keytool","slug":"keytool","date":"2018-08-15T06:35:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/08/15/keytool/","link":"","permalink":"https://chenadminchen.github.io/2018/08/15/keytool/","excerpt":"","text":"操作系统级别证书 操作系统的级别证书，chrome所用的证书来自于本机操作系统证书 window Internet管理内找到证书管理 linux 1/etc/default/cacerts java环境变量内的证书因为java是基于jvm上的，由于其目标是跨平台应用，因此它不依赖于其操作系统，所以它保存了一份属于自己的证书 window java管内找到证书管理 linux 123/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security/cacerts/etc/ssl/certs/java/cacerts #存放java所要的证书 keytool的使用 生成证书 123#RSA 加密#san: submitAilName 备用证书名,在导入系统级别的证书后，chrome使用时，若无该设备则会出错sudo keytool -genkey -keystore chen.keystore -alias chen -keyalg RSA -storepass changeit -ext san=dns:cas.example.org 导出证书 12#-alias 与生成时的相同sudo keytool -export -alias chen -file chen.cer -keystore chen.keystore 导入证书到java环境 1sudo keytool -import -alias chen -storepass changeit -file chen.cer -keystore &quot;/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security/cacerts&quot; 删除java环境内的证书1sudo keytool -delete -alias chen -storepass changeit -keystore &quot;/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security/cacerts&quot; ###","categories":[],"tags":[{"name":"keytool","slug":"keytool","permalink":"https://chenadminchen.github.io/tags/keytool/"}]},{"title":"apache2-proxy","slug":"apache2-proxy","date":"2018-08-09T04:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/08/09/apache2-proxy/","link":"","permalink":"https://chenadminchen.github.io/2018/08/09/apache2-proxy/","excerpt":"","text":"apache2 proxy 说明&nbsp;&nbsp;&nbsp;&nbsp;apache2 proxy的代理方便多个接口服务的管理，它可设置一台计算机中的某个一个端口可指向多个服务接口，该服务可存在于本地，也可存在于不同服务器上。 apache2 proxy service 安装说明 &nbsp;&nbsp;&nbsp;&nbsp;下载安装apach2 开启服务 1service apache2 restart 查看处理日志 1cat /var/log/apache2/error.log 查看apache软件结构 12chen@chen-T4 /etc/apache2 $ cat apache2.conf 部分结果如下： 123456789101112/etc/apache2/# |-- apache2.conf# | `-- ports.conf# |-- mods-enabled# | |-- *.load# | `-- *.conf# |-- conf-enabled# | `-- *.conf# `-- sites-enabled# `-- *.conf# – apache2.conf： 讲解了apache的目录结构，加载顺序 – ports.conf: 使用的端口地址 – mods-enabled: 加载的module – conf-enabled: 字符集的配置 – sites-enabled: proxy service的配置文件 1sudo nano 000-default.conf 查看所有可安装的module 1cd /usr/lib/apache2/modules/ 加载module 1234#加载modulea2enmod proxy 配置代理所需要的module 1ssl proxy proxy_connect proxy_balancer 配置代理 1234567891011#进入配置文件cd /etc/apache2/sites-enabled#添加访问http的代理 ProxyPass /online http://192.111.12.25:8182/api#添加访问https的代理ProxyPass /portal https://192.111.12.25/portal#项目中存在重定向的，需要再加上如下配置ProxyPassReverse /portal https://yifenganxin.com/portal","categories":[],"tags":[{"name":"apache2 proxy","slug":"apache2-proxy","permalink":"https://chenadminchen.github.io/tags/apache2-proxy/"}]},{"title":"css","slug":"css-learn","date":"2018-07-22T06:35:34.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/07/22/css-learn/","link":"","permalink":"https://chenadminchen.github.io/2018/07/22/css-learn/","excerpt":"","text":"css&nbsp;&nbsp;&nbsp;&nbsp;css风格布局grid https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout &nbsp;&nbsp;&nbsp;&nbsp;css高度/长度计算 1width: &apos;calc(100% - 48px)&apos;;","categories":[],"tags":[{"name":"css","slug":"css","permalink":"https://chenadminchen.github.io/tags/css/"}]},{"title":"javaScript","slug":"javaScript-learn","date":"2018-07-22T06:35:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/07/22/javaScript-learn/","link":"","permalink":"https://chenadminchen.github.io/2018/07/22/javaScript-learn/","excerpt":"","text":"学习资源&nbsp;&nbsp;&nbsp;&nbsp;JavaScript单线程实现ajax异步、setTimeOut的方法 https://www.cnblogs.com/Mainz/p/3552717.html","categories":[],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"}]},{"title":"java recursion","slug":"java-recursion","date":"2018-07-12T06:35:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/07/12/java-recursion/","link":"","permalink":"https://chenadminchen.github.io/2018/07/12/java-recursion/","excerpt":"","text":"项目目标&nbsp;&nbsp;&nbsp;&nbsp;一个字符串的内容转换成json对象，并根据json中的内容寻找到从起点到终点的可连通的路径 字符串内容123456789101112131415161718192021\"[ &#123;id:-1, preNode:[], nextNode:[1], branch:null&#125;, &#123;id:1, preNode:[-1], nextNode:[2], branch:null&#125;, &#123;id:2, preNode:[1], nextNode:[3], branch:null&#125;, &#123;id:3, preNode:[2], nextNode:[4,5], branch:oneofonestart&#125;, &#123;id:4, preNode:[3], nextNode:[6], branch:null&#125;, &#123;id:5, preNode:[3], nextNode:[7], branch:null&#125;, &#123;id:6, preNode:[4], nextNode:[8], branch:null&#125;, &#123;id:7, preNode:[5], nextNode:[9], branch:null&#125;, &#123;id:8, preNode:[6], nextNode:[10], branch:null&#125;, &#123;id:9, preNode:[7], nextNode:[10], branch:oneofend&#125;, &#123;id:10, preNode:[8,9], nextNode:[11], branch:null&#125;, &#123;id:11, preNode:[10], nextNode:[12,13,14], branch:oneofonestart&#125;, &#123;id:12, preNode:[11], nextNode:[15], branch:null&#125;, &#123;id:13, preNode:[11], nextNode:[16], branch:null&#125;, &#123;id:14, preNode:[11], nextNode:[17], branch:null&#125;, &#123;id:15, preNode:[12], nextNode:[-2], branch:null&#125;, &#123;id:16, preNode:[13], nextNode:[-2], branch:null&#125;, &#123;id:17, preNode:[14], nextNode:[-2], branch:null&#125;, &#123;id:-2, preNode:[15,16,17], nextNode:[], branch:oneofoneend&#125;]\" 字符串所表达的图新建项目所依赖的主要包123456789101112&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt; 创建实体类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.yf.af.junitTest;public class Node &#123; private int id; private int preNode[]; private int nextNode[]; private String branch; private boolean disable = false; public Node(int id, int[] preNode, int[] nextNode, String branch) &#123; this.id = id; this.preNode = preNode; this.nextNode = nextNode; this.branch = branch; &#125; public boolean isDisable() &#123; return disable; &#125; public void setDisable(boolean disable) &#123; this.disable = disable; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public int[] getPreNode() &#123; return preNode; &#125; public void setPreNode(int[] preNode) &#123; this.preNode = preNode; &#125; public int[] getNextNode() &#123; return nextNode; &#125; public void setNextNode(int[] nextNode) &#123; this.nextNode = nextNode; &#125; public String getBranch() &#123; return branch; &#125; public void setBranch(String branch) &#123; this.branch = branch; &#125; public Node() &#123; &#125;&#125; 具体实现java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package com.yf.af.junitTest;import com.fasterxml.jackson.core.type.TypeReference;import com.fasterxml.jackson.databind.ObjectMapper;import java.io.IOException;import java.util.*;import java.util.Stack;public class JsonTest &#123; private List&lt;Node&gt; nodes; private Map&lt;String, List&lt;Node&gt;&gt; paths; public static void main(String[] args) &#123; String nodeStr = &quot;[\\n&quot; + &quot; &#123;\\&quot;id\\&quot;:-1, \\&quot;preNode\\&quot;:[], \\&quot;nextNode\\&quot;:[1], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:1, \\&quot;preNode\\&quot;:[-1], \\&quot;nextNode\\&quot;:[2], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:2, \\&quot;preNode\\&quot;:[1], \\&quot;nextNode\\&quot;:[3], \\&quot;branch\\&quot;:null&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:3, \\&quot;preNode\\&quot;:[2], \\&quot;nextNode\\&quot;:[4,5], \\&quot;branch\\&quot;:\\&quot;oneofonestart\\&quot;&#125;,&#123;\\&quot;id\\&quot;:4, \\&quot;preNode\\&quot;:[3], \\&quot;nextNode\\&quot;:[6], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:5, \\&quot;preNode\\&quot;:[3], \\&quot;nextNode\\&quot;:[7], \\&quot;branch\\&quot;:null&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:6, \\&quot;preNode\\&quot;:[4], \\&quot;nextNode\\&quot;:[8], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:7, \\&quot;preNode\\&quot;:[5], \\&quot;nextNode\\&quot;:[9], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:8, \\&quot;preNode\\&quot;:[6], \\&quot;nextNode\\&quot;:[10], \\&quot;branch\\&quot;:null&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:9, \\&quot;preNode\\&quot;:[7], \\&quot;nextNode\\&quot;:[10], \\&quot;branch\\&quot;:\\&quot;oneofend\\&quot;&#125;,&#123;\\&quot;id\\&quot;:10, \\&quot;preNode\\&quot;:[8,9], \\&quot;nextNode\\&quot;:[11], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:11, \\&quot;preNode\\&quot;:[10], \\&quot;nextNode\\&quot;:[12,13,14], \\&quot;branch\\&quot;:\\&quot;oneofonestart\\&quot;&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:12, \\&quot;preNode\\&quot;:[11], \\&quot;nextNode\\&quot;:[15], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:13, \\&quot;preNode\\&quot;:[11], \\&quot;nextNode\\&quot;:[16], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:14, \\&quot;preNode\\&quot;:[11], \\&quot;nextNode\\&quot;:[17], \\&quot;branch\\&quot;:null&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:15, \\&quot;preNode\\&quot;:[12], \\&quot;nextNode\\&quot;:[-2], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:16, \\&quot;preNode\\&quot;:[13], \\&quot;nextNode\\&quot;:[-2], \\&quot;branch\\&quot;:null&#125;,&#123;\\&quot;id\\&quot;:17, \\&quot;preNode\\&quot;:[14], \\&quot;nextNode\\&quot;:[-2], \\&quot;branch\\&quot;:null&#125;,&quot; + &quot; &#123;\\&quot;id\\&quot;:-2, \\&quot;preNode\\&quot;:[15,16,17], \\&quot;nextNode\\&quot;:[], \\&quot;branch\\&quot;:\\&quot;oneofoneend\\&quot;&#125;&quot; + &quot;]&quot;; JsonTest jsonTest = new JsonTest(); //用于保存所有的node List&lt;Node&gt; nodes = new ArrayList&lt;&gt;(); try &#123; //将字符串转化成list&lt;Node&gt; nodes = new ObjectMapper().readValue(nodeStr, new TypeReference&lt;List&lt;Node&gt;&gt;() &#123; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; nodes.forEach(node -&gt; &#123; mappedNodes.put(node.getId(), node); &#125;); jsonTest.findPath(nodes.get(0)); for (int i = 0; i &lt; jsonTest.getPaths().size(); i++) &#123; System.out.println(jsonTest.getPaths().get(i)); &#125; &#125; // mapped nodes static Map&lt;Integer, Node&gt; mappedNodes = new HashMap&lt;&gt;(); Stack&lt;Integer&gt; path = new Stack&lt;&gt;(); Stack&lt;Integer&gt; branchs = new Stack&lt;&gt;(); //找出所有的完整的路径 public void findPath(Node node) &#123; path.push(node.getId()); // if (node.getId() == -2) &#123; System.out.println(path.toString()); System.out.println(branchs.toString()); System.out.println(&quot;found path&quot;); &#125; // int[] branches = node.getNextNode(); for (int i = 0; i &lt; branches.length; i++) &#123; Node next = mappedNodes.get(branches[i]); findPath(next); // System.out.println(&quot;return from findPath&quot;); &#125; path.pop(); &#125; public Map&lt;String, List&lt;Node&gt;&gt; getPaths() &#123; return paths; &#125; public void setPaths(String key, List&lt;Node&gt; nodes) &#123; if (this.paths == null) &#123; this.paths = new HashMap&lt;&gt;(); &#125; this.paths.put(key, nodes); &#125;&#125; 具体实现kotlin代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 //返回字符串 @Bean// @Order(value=1) fun nodesString(): String &#123; return &quot;[&quot; + &quot;&#123;\\&quot;id\\&quot;:-1, \\&quot;prev\\&quot;:[], \\&quot;next\\&quot;:[1], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:null,\\&quot;index\\&quot;:null&#125;,&quot;+ &quot;&#123;\\&quot;id\\&quot;:1, \\&quot;prev\\&quot;:[-1], \\&quot;next\\&quot;:[2], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i21 &lt; 8 &amp;&amp; i21&gt;=2\\&quot;,\\&quot;index\\&quot;:21&#125;,&quot;+ &quot;&#123;\\&quot;id\\&quot;:2, \\&quot;prev\\&quot;:[1], \\&quot;next\\&quot;:[3], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i22==1\\&quot;,\\&quot;index\\&quot;:22&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:3, \\&quot;prev\\&quot;:[2], \\&quot;next\\&quot;:[4,5], \\&quot;branch\\&quot;:\\&quot;oneofonestart\\&quot;,\\&quot;expr\\&quot;:\\&quot;i23&gt;130 &amp;&amp; i23 &lt;200\\&quot;,\\&quot;index\\&quot;:23&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:4, \\&quot;prev\\&quot;:[3], \\&quot;next\\&quot;:[6], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i24 &gt; 300\\&quot;,\\&quot;index\\&quot;:24&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:5, \\&quot;prev\\&quot;:[3], \\&quot;next\\&quot;:[7], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i25 == 1\\&quot;,\\&quot;index\\&quot;:25&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:6, \\&quot;prev\\&quot;:[4], \\&quot;next\\&quot;:[8], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i26 == 1\\&quot;,\\&quot;index\\&quot;:26&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:7, \\&quot;prev\\&quot;:[5], \\&quot;next\\&quot;:[9], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i27 &gt; 66\\&quot;,\\&quot;index\\&quot;:27&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:8, \\&quot;prev\\&quot;:[6], \\&quot;next\\&quot;:[10], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i28 == 1\\&quot;,\\&quot;index\\&quot;:28&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:9, \\&quot;prev\\&quot;:[7], \\&quot;next\\&quot;:[10], \\&quot;branch\\&quot;:\\&quot;oneofend\\&quot;,\\&quot;expr\\&quot;:\\&quot;i29 == 0\\&quot;,\\&quot;index\\&quot;:29&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:10, \\&quot;prev\\&quot;:[8,9], \\&quot;next\\&quot;:[11], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i30 &gt;=45\\&quot;,\\&quot;index\\&quot;:30&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:11, \\&quot;prev\\&quot;:[10], \\&quot;next\\&quot;:[12,13,14], \\&quot;branch\\&quot;:\\&quot;oneofonestart\\&quot;,\\&quot;expr\\&quot;:\\&quot;i31 &gt;100\\&quot;,\\&quot;index\\&quot;:31&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:12, \\&quot;prev\\&quot;:[11], \\&quot;next\\&quot;:[15], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i32&gt;256\\&quot;,\\&quot;index\\&quot;:32&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:13, \\&quot;prev\\&quot;:[11], \\&quot;next\\&quot;:[16], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i33 == 89 &amp;&amp; i32 &gt;356\\&quot;,\\&quot;index\\&quot;:33&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:14, \\&quot;prev\\&quot;:[11], \\&quot;next\\&quot;:[17], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i34 == 0\\&quot;,\\&quot;index\\&quot;:34&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:15, \\&quot;prev\\&quot;:[12], \\&quot;next\\&quot;:[-2], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i35 ==1\\&quot;,\\&quot;index\\&quot;:35&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:16, \\&quot;prev\\&quot;:[13], \\&quot;next\\&quot;:[-2], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i36 ==1 \\&quot;,\\&quot;index\\&quot;:36&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:17, \\&quot;prev\\&quot;:[14], \\&quot;next\\&quot;:[-2], \\&quot;branch\\&quot;:null,\\&quot;expr\\&quot;:\\&quot;i37 &gt;=47\\&quot;,\\&quot;index\\&quot;:37&#125;,&quot; + &quot;&#123;\\&quot;id\\&quot;:-2, \\&quot;prev\\&quot;:[15,16,17], \\&quot;next\\&quot;:[], \\&quot;branch\\&quot;:\\&quot;oneofoneend\\&quot;,\\&quot;expr\\&quot;:null,\\&quot;index\\&quot;:null&#125;&quot; + &quot;]&quot; &#125; val nodeMap: MutableMap&lt;Int, Node&gt; = mutableMapOf() val path: Stack&lt;Node&gt; = Stack() //循环获得连通的路径 fun findPath(node: Node) &#123; path.push(node) if (node.id == -2) &#123; print(&quot;&#123;\\&quot;path\\&quot;: [&quot;)// path.forEach &#123; print(&quot;&#123;\\&quot;id\\&quot;: $&#123;it.id&#125;&#125;, &quot;) &#125; path.forEach &#123; print(&quot;$&#123;it.id&#125;, &quot;) &#125; println(&quot;]&#125;, &quot;) &#125; node.next.forEach &#123; findPath(nodeMap[it]!!) &#125; path.pop() &#125;//根据字符串内容转化成json对象，并且进行第一个递归调用// @Order(value=2) @Bean fun pathFind(nodeString: String): CommandLineRunner &#123; return CommandLineRunner &#123; val nodes = ObjectMapper().readValue(nodeString, Array&lt;Node&gt;::class.java) nodes.forEach &#123; nodeMap.put(it.id!!, it) &#125; val first: Node = nodeMap[-1]!! findPath(first) &#125; &#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"json","slug":"json","permalink":"https://chenadminchen.github.io/tags/json/"}]},{"title":"svn command","slug":"svn-command","date":"2018-06-27T06:36:45.000Z","updated":"2019-08-27T14:50:18.984Z","comments":true,"path":"2018/06/27/svn-command/","link":"","permalink":"https://chenadminchen.github.io/2018/06/27/svn-command/","excerpt":"","text":"svn commit new project&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以下的操作都在本地项目new_project文件夹内操作&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;创建新的project12345678//https://127.0.0.1/svn/trunk为存放new_project项目的地方svn mkdir https://127.0.0.1/svn/trunk/new_project //检查new_projectsvn co https://127.0.0.1/svn/trunk/new_project//提交new_projectsvn import -m &quot;提交new_project&quot; https://127.0.0.1/svn/trunk/new_project svn 切换分支 1svn cp https://127.0.0.1/svn/branch/old_project/ https://127.0.0.1/svn/branch/new_project svn 改名 1svn mv https://127.0.0.1/svn/branch/old_project https://127.0.0.1/svn/branch/old_new_project svn 将未提交的代码切换到分支 1svn cp . &quot;^branch/new_project/0.6&quot; svn 合并分支 1234分支上合并主干代码3192：是指创建分支时主干版本号3225：是指当前需要合并的主干版本号-svn merge -r 3192:3225 https://192.168.1.168/svn/Yf_Server/trunk/new_project 在分支查看处理的分支是否存在没有提交的代码1svn status 切回到主分支1svn sw https://127.0.0.1/svn/trunk/new_project 合并分支代码,若存在问题时，需要合并，请按提示执行1svn merge https://127.0.0.1/svn/branch/new_project/0.5 查看当前Branch中已经有那些改动已经被合并到Trunk中1svn mergeinfo https://127.0.0.1/svn/branch/new_project/0.5 查看Branch中那些改动还未合并。1svn mergeinfo https://127.0.0.1/svn/branch/new_project/0.5 show-revs eligible 检查是否真的合并成功，若出现问题可还原继续重复操作提交合并的内容1svn ci -m &quot;合并&quot; 删除项目1svn delete https://127.0.0.1/svn/branch/new_project/0.5 -m delete 删除项目指定的文件(进入项目的目录下)12svn delete file_namesvn commit -m &quot;delete &apos;file_name&apos;&quot; 外部链接 12345svn pe svn:externals .&lt;!-- 执行命令后，编辑外部链接的地址 --&gt;com.jks https://localhost/svn/trunk/07-android_project/keystore/com.jks","categories":[],"tags":[{"name":"svn","slug":"svn","permalink":"https://chenadminchen.github.io/tags/svn/"}]},{"title":"soft install","slug":"soft-install","date":"2018-06-12T06:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/06/12/soft-install/","link":"","permalink":"https://chenadminchen.github.io/2018/06/12/soft-install/","excerpt":"","text":"Interprocess communications in Java12 activemq123chown -R activemq:activemq apache-activemq-5.15.4/sudo ./activemq console mqttfx1234#下载deb的安装文件#运行deb#下载javax --&gt;根据安装的jdk而选择#运行mqttfx","categories":[],"tags":[{"name":"soft","slug":"soft","permalink":"https://chenadminchen.github.io/tags/soft/"}]},{"title":"java command","slug":"java-command","date":"2018-06-12T06:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/06/12/java-command/","link":"","permalink":"https://chenadminchen.github.io/2018/06/12/java-command/","excerpt":"","text":"java程序启动远程调试功能123#开启java的远程调试功能，同时启动时不进行调试功能-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8000,suspend=n ### 1234#java max mem default#查看java的默认内存#-Xmx is in MaxHeapSize, -Xms is in InitialHeapSizejava -XX:+PrintFlagsFinal -version","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"}]},{"title":"linux command","slug":"linux-command","date":"2018-06-11T02:58:34.000Z","updated":"2020-07-14T14:47:45.943Z","comments":true,"path":"2018/06/11/linux-command/","link":"","permalink":"https://chenadminchen.github.io/2018/06/11/linux-command/","excerpt":"","text":"linux指令linux下运行python虚批环境开启虚拟环境 root@root#opt/py35: source ./bin/activate 退出 deactivate 后台运行python程序，将运行地址切换到需要运行的python文件下,将有日志打印在文件内 root@ nohup python main.py $ servicemix的运行进入servicemix的文件夹下 root@4xe7t:/opt/apache-servicemix-7.0.1# ./bin/servicemix tigase的运行运行 root@4xe7t:/tigase-server-7.1.0-b4379/script# ./tigase.sh start ../etc/tigase.conf 关闭 root@4xe7t:/tigase-server-7.1.0-b4379/script# ./tigase.sh stop ../etc/tigase.conf linux path 加临时性代理以下方式为session会话，关闭cmd则消息 export HTTP_PROXY=127.0.0.1:1080 export HTTPs_PROXY=127.0.0.1:1080 linux path 永久设置./profile文件内修改才行 查看进行进程123456789#查看与python相关的进程ps aux | grep python#查看正在运行的进程ps aux#杀死某个进程kill -9 id linux下对文件的操作nano123#若不存在一个文件时，创建一个requirement.txt新文件，若文件存在，则直接打开文件nano requirement.txt 两台linux系统传送文件1234567#scp local_file remote_username@remote_ip:remote_folder #将根目录下的t开头的sql传送到192.168.60.51的根目录下scp ~/t*.sql root@192.168.60.51:~/#从服务器上将文件下载下来scp -r root@192.168.60.51:~/web /home/chen/web 远程连接sevicemix12#连接smxssh smx@192.168.2.168 -p8101 远程连接另一台linux123#连接linuxssh root@192.168.2.168 -p22 查看内存使用情况12free -h 查看各进程内存使用情况12top -o %MEM linux 传送文件到window&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要window开启ftp协议，并且共享某个文件夹 chen@chen-T4 ~/work/code/yfaf $ ftp 192.168.22.168 Connected to 192.168.22.168. 220 Microsoft FTP Service Name (192.168.22.168:chen): cc 331 Password required for cc. Password: 530 User cannot log in. Login failed. Remote system type is Windows_NT. ftp> ls 530 Please login with USER and PASS. ftp: bind: Address already in use ftp> type binary //转换成 binary 200 Type set to I. ftp> put data.jar data.jar //将data.jar 传上去 需要定义新文件的名字 linux 上传文件到linux12#将yfaf*.sql 的所有文件上传到175.6.56.51服务器上scp yfaf*.sql root@175.6.56.51:~/ linux historysearchscript123456# find have 'Start datanodes' in *.shgrep -RIn 'Starting datanodes' --include=\"*\\.sh\"# find worker* filefind . -iname 'worker*' GBK covert UTF-8 Linux 下 zip 文件解压乱码如何解决: 1unzip -O cp936 xxx.zip Covert Files’ Encode From GBK to UTF-8 in One Time:12find 国外反编译工具.txt -type f -exec bash -c \"iconv -f GBK -t UTF-8 &#123;&#125; &gt; utf8_&#123;&#125;\" \\;`","categories":[{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/categories/linux/"}],"tags":[{"name":"linux command","slug":"linux-command","permalink":"https://chenadminchen.github.io/tags/linux-command/"}]},{"title":"linux mint install","slug":"linux-mint-install","date":"2018-06-06T03:58:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/06/06/linux-mint-install/","link":"","permalink":"https://chenadminchen.github.io/2018/06/06/linux-mint-install/","excerpt":"","text":"linux mint系统linux mint安装制做rufus的启动盘&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入官网下载软件 使用rufus的启动盘引导安装&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于本人的电脑为双显卡，因此在装双系统时，用refus引到盘进行安装mint时，无法进入linux系统内，原因是电脑在启动时无法正确使用显卡，因此在进入系统前，将配置信息成不使用显卡,其需要添加配置信息，可查看CUDA官方文档和Linux Mint 18.1官方文档 12nomodeset 安装linux mint时的指导文档&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;博客1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;博客2 启动linux系统时，不使用图形化界面123#与添加nomodeset的方法一样，添加如下命令single nomodeset single进入无图形化界面检查nouveau驱动是否被禁用如果有任何输出信息，表明nouveau驱动被启用。 禁用nouveau驱动（必要） 创建文件/etc/modprobe.d/blacklist-nouveau.conf，内容如下： 12blacklist nouveauoptions nouveau modeset=0 重新生成kernel initramfs，终端输入： 1sudo update-initramfs -u nomodeset模式下安装nvidia驱动1） CUDA官方文档上说，如果要安装nvidia显卡驱动，那么必须保证nouveau驱动被禁用。可是nvidia驱动还没安装上，那岂不是没有显卡驱动了吗？幸运的是，这里可以让系统临时进入nomodeset模式，它采用了一种”软显示“模式。 重启系统进入nomodeset模式：参考https://www.linuxmint.com/rel_serena_cinnamon.php里的Solving freezes部分。 2） 在nomodeset模式下，先按步骤1检查nouveau驱动是否被禁用，确保其禁用。再安装nvidia驱动 #### #### 安装好重启电脑 grub rescue 学习地址1234567891011121314151617#获得分区信息grub rescue&gt;ls (hd1,msdos7) (hd1,msdos8) ....grub rescue&gt;ls (hd1,msdos7).... /boot //则(hd1,msdos7)为启动盘grub rescue&gt;set prefix=(hd1,msdos7)/boot/grubgrub rescue&gt;set root=(hd1,msdos7)grub rescue&gt;insmod normalgrub rescue&gt;normalgrub&gt;insmod linuxgrub&gt; linux /boot/vmlinuz-3.13.0-29-generic root=/dev/sda1grub&gt; initrd /boot/initrd.img-3.13.0-29-genericgrub&gt; boot 自动进行修复学习地址123sudo add-apt-repository ppa:yannubuntu/boot-repairsudo apt-get updatesudo apt-get install -y boot-repair &amp;&amp; boot-repair 重启电脑无法选择window系统 linux系统下使用apt下载os-prober 12345678apt install os-probersudo os-prober``` &gt; 重启电脑后发现无法自动进入系统，出现error not find device linux系统使用下面指令,[学习地址](https://askubuntu.com/questions/143667/boot-error-no-such-device-grub-rescue &apos;1&apos;) grub-install /dev/sda -- 硬盘 grub-install /dev/sdb -- 机器硬盘 update-grub `","categories":[{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/categories/linux/"}],"tags":[{"name":"linux mint","slug":"linux-mint","permalink":"https://chenadminchen.github.io/tags/linux-mint/"}]},{"title":"mysql transaction","slug":"mysql-transaction","date":"2018-05-03T01:50:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/05/03/mysql-transaction/","link":"","permalink":"https://chenadminchen.github.io/2018/05/03/mysql-transaction/","excerpt":"","text":"mysql四种隔离级别read committed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读) read uncommitted&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;允许脏读，也就是可能读取到其他会话中未提交事务修改的数据 book结构12345create table book( id int(11), name varchar(11)); 脏读&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。在read uncommitted可脏话 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#session A -&gt; read uncommittedstart transaction;set session transaction isolation level read uncommitted;insert into book(id, name) values(3,'javaScript');mysql&gt; select * from book+------+------------+| id | name |+------+------------+| 1 | java || 2 | python || 3 | javaScript |+------+------------+3 rows in set (0.00 sec)commit;#session B -&gt; read uncommittedstart transaction;set session transaction isolation level read uncommitted;#before session A commitmysql&gt; select * from book+------+------------+| id | name |+------+------------+| 1 | java || 2 | python || 3 | javaScript |+------+------------+3 rows in set (0.00 sec)#session C -&gt; repeatable read#before session A commitmysql&gt; select * from book;+------+--------+| id | name |+------+--------+| 1 | java || 2 | python |+------+--------+2 rows in set (0.00 sec)#after session A commitmysql&gt; select * from book+------+------------+| id | name |+------+------------+| 1 | java || 2 | python || 3 | javaScript |+------+------------+3 rows in set (0.00 sec) 不可重复读&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 repeatable read&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可重复读。在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读 serializable&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞 操作当前会话的隔离级别隔离级别 | 脏读（Dirty Read） | 不可重复读（NonRepeatable Read） | 幻读（Phantom Read） | - | - | - | - | 未提交读（Read uncommitted） | 可能 | 可能 | 可能 已提交读（Read committed） | 不可能 | 可能 | 可能 可重复读（Repeatable read） | 不可能 | 不可能 | 可能 可串行化（Serializable ） | 不可能 | 不可能 | 不可能 12345#查看当前会话的隔离级别select @@session.tx_isolation;#修改当前会话的隔离级别set [session / global] transaction isolation level [read committed / read uncommitted / repeatable read /serializable] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认的行为（不带session和global）是为下一个（未开始）事务设置隔离级别。如果你使用GLOBAL关键字，语句在全局对从那点开始创建的所有新连接（除了不存在的连接）设置默认事务级别。你需要SUPER权限来做这个。使用SESSION 关键字为将来在当前连接上执行的事务设置默认事务级别。 任何客户端都能自由改变会话隔离级别（甚至在事务的中间），或者为下一个事务设置隔离级别。 数据导入出错&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当A表的数据由B表的数据插入时用触发器生成时，若向A导入数据时可能会出现错： 触发器可能会导致主键重复的错误，原因是A表中的数据由此触发器插入，但数据导入脚本也导入了已有数据，导致冲突。 因此，在触发器中增加对用户自定义变量 @disable_triggers 的检查，此变量为null时才执行动作。当需要禁止触发器动作时，设置此变量为1即可。 然后修改数据导入脚本，在前、后分别增加 禁止触发器 和 恢复触发器 的设置。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"transaction","slug":"transaction","permalink":"https://chenadminchen.github.io/tags/transaction/"}]},{"title":"message queue","slug":"message-queue","date":"2018-04-26T02:33:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/04/26/message-queue/","link":"","permalink":"https://chenadminchen.github.io/2018/04/26/message-queue/","excerpt":"","text":"Jms基本概念&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JMS(JAVA Message Service)是java的消息服务，JMS的客户端之间可以通过JMS服务进行异步的消息传输 消息模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Point-to-Point(P2P)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Publish/Subscribe(Pub/Sub)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即点对点和发布订阅模型 P2P&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按官网文档的要求，可以直接使用如下指令（本人将所有的虚拟环境创建在python35文件夹的venv内） 1D:\\Users\\Python\\Python35\\venv&gt; python -m venv py35","categories":[],"tags":[{"name":"message queue","slug":"message-queue","permalink":"https://chenadminchen.github.io/tags/message-queue/"}]},{"title":"mysql SQL (二)","slug":"mysql-service-SQL","date":"2018-04-26T01:54:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/04/26/mysql-service-SQL/","link":"","permalink":"https://chenadminchen.github.io/2018/04/26/mysql-service-SQL/","excerpt":"","text":"mysql lock&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每张表有锁定时间超时的设置，下面是将超时时间设置为600 123SHOW VARIABLES LIKE '%innodb_lock_wait%';SET innodb_lock_wait_timeout=600;","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"SQL","slug":"SQL","permalink":"https://chenadminchen.github.io/tags/SQL/"}]},{"title":"react-native error","slug":"react-native-error","date":"2018-04-26T01:19:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/04/26/react-native-error/","link":"","permalink":"https://chenadminchen.github.io/2018/04/26/react-native-error/","excerpt":"","text":"react-native-charts-wrapper&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该组件用于曲线，其github地址，其react-native用0.54.0版本时，出现如下错误信息，解决方法 1234567#error(Android) RN 0.54 Exception \"local reference table overflow (max=512)\" #229#solve #在MPAndroidChartPackage.java/ createViewManagers()中添加如下内容：ReadableNativeArray.setUseNativeAccessor(true);ReadableNativeMap.setUseNativeAccessor(true); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从react-native的源码可以看出ReadableNativeArray、ReadableNativeMap中的setUseNativeAccessor方法为static function，因此可在react-native-charts-wrapper源码加载LineChart数据之前的任何一个地方加载该方法，其问题就解决。 1234https://github.com/facebook/react-native/blob/master/ReactAndroid/src/main/java/com/facebook/react/bridge/ReadableNativeMap.javahttps://github.com/facebook/react-native/blob/master/ReactAndroid/src/main/java/com/facebook/react/bridge/ReadableNativeArray.java","categories":[{"name":"react-native","slug":"react-native","permalink":"https://chenadminchen.github.io/categories/react-native/"}],"tags":[{"name":"react-native error","slug":"react-native-error","permalink":"https://chenadminchen.github.io/tags/react-native-error/"}]},{"title":"java classload","slug":"java-class-load","date":"2018-04-18T01:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/04/18/java-class-load/","link":"","permalink":"https://chenadminchen.github.io/2018/04/18/java-class-load/","excerpt":"","text":"介绍类加载器(classload)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理解类加载器(https://blog.csdn.net/javazejian/article/details/73413292)[&#39;学习地址&#39;]","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"classload","slug":"classload","permalink":"https://chenadminchen.github.io/tags/classload/"}]},{"title":"java class (二)","slug":"java-class-2","date":"2018-04-18T01:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/04/18/java-class-2/","link":"","permalink":"https://chenadminchen.github.io/2018/04/18/java-class-2/","excerpt":"","text":"介绍class中数据类型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该文章引用于 https://blog.csdn.net/zhangjg_blog/article/details/21487287,若 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class文件中的信息是一项一项排列的， 每项数据都有它的固定长度， 有的占一个字节， 有的占两个字节， 还有的占四个字节或8个字节， 数据项的不同长度分别用u1, u2, u4, u8表示， 分别表示一种数据项在class文件中占据一个字节， 两个字节， 4个字节和8个字节。 可以把u1, u2, u3, u4看做class文件数据项的“类型” 。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class文件中存在以下数据项(该图表参考自《深入Java虚拟机》)： 类型 名称 数量 名称 u4 magic 1 魔数 u2 minor_version 1 此版本号 u2 major_version 1 主版本号 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count 介绍java class 中的魔数(magic)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在很多文件中都存在魔数,魔数是告诉调用者,该文件是属于那一类型,是否有用,在class文件中魔数放在第一位,其在class文件中的魔数占用了4个字节,网上说其class文件存在固定值 ‘0xCAFEBABE’,将class文件以二进制流的形式打开文件，将会看到对应的魔数。 介绍java class 常量池中的数据项的类型 常量池中数据项类型 类型标志 类型描述 CONSTANT_Utf8 1 UTF-8编码的Unicode字符串 CONSTANT_Integer 3 int类型字面值 CONSTANT_Float 4 float类型字面值 CONSTANT_Long 5 long类型字面值 CONSTANT_Double 6 double类型字面值 CONSTANT_Class 7 对一个类或接口的符号引用 CONSTANT_String 8 String类型字面值 CONSTANT_Fieldref 9 对一个字段的符号引用 CONSTANT_Methodref 10 对一个类中声明的方法的符号引用 CONSTANT_InterfaceMethodref 11 对一个接口中声明的方法的符号引用 CONSTANT_NameAndType 12 对一个字段或方法的部分符号引用 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个数据项叫做一个XXX_info项， 比如， 一个常量池中一个CONSTANT_Utf8类型的项， 就是一个CONSTANT_Utf8_info 。除此之外， 每个info项中都有一个标志值（tag）， 这个标志值表明了这个常量池中的info项的类型是什么， 从上面的表格中可以看出， 一个CONSTANT_Utf8_info中的tag值为1， 而一个CONSTANT_Fieldref_info中的tag值为9 。 常量池中存放的符号引用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java程序是动态链接的， 在动态链接的实现中， 常量池扮演者举足轻重的角色。 除了存放一些字面量之外， 常量池中还存放着以下几种符号引用： （1） 类和接口的全限定名 （2） 字段的名称和描述符 （3） 方法的名称和描述符 类和接口的全限定名：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在常量池中， 一个类型的名字并不是我们在源文件中看到的那样， 也不是我们在源文件中使用的包名加类名的形式。 源文件中的全限定名和class文件中的全限定名不是相同的概念。 源文件中的全新定名是包名加类名， 包名的各个部分之间，包名和类名之间， 使用点号分割。 如Object类， 在源文件中的全限定名是java.lang.Object 。 而class文件中的全限定名是将点号替换成“/” 。 例如， Object类在class文件中的全限定名是 java/lang/Object 。 如果读者之前没有接触过class文件格式， 是class文件格式的初学者， 在这里不必知道全限定名在class文件中是如何使用的， 只需要知道， 源文件中一个类的名字， 在class文件中是用全限定名表述的。 字段的名称和描述符 基本数据类型和void类型 类型的对应字符 byte B char C double D float F int I long J short S boolean Z void V 类和接口，枚举描述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本类型和void在描述符中都有一个大写字符和他们对应， 那么引用类型（类和接口，枚举）在描述符中是如何对应的呢？ 引用类型的对应字符串（注意， 引用类型在描述符中使用一个字符串做对应） ， 这个字符串的格式是： 123456“L” + 类型的全限定名 + “;”#55 = NameAndType #74:#75 // getClass:()Ljava/lang/Class;#74 = Utf8 getClass#75 = Utf8 ()Ljava/lang/Class; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这三个部分之间没有空格， 是紧密排列的。 如Object在描述符中的对应字符串是： Ljava/lang/Object; ； ArrayList在描述符中的对应字符串是： Ljava/lang/ArrayList; ； 自定义类型com.examples.Person在描述符中的对应字符串是： Lcom/examples/Person; 。 数组类型的描述1若干个“[” + 数组中元素类型的对应字符串 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;int[]类型的对应字符串是： [I 。 int[][]类型的对应字符串是： [[I 。 Object[]类型的对应字符串是： [Ljava/lang/Object; 。 Object[][][]类型的对应字符串是： [[[Ljava/lang/Object; 。 方法描述12(参数1类型 参数2类型 参数3类型 ...)返回值类型 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面举例说明（此表格来源于《深入Java虚拟机》） 方法描述符 | 方法声明()I | int getSize()()Ljava/lang/String; | String toString()([Ljava/lang/String;)V | void main(String[] args)()V | void wait()(JI)V | void wait(long timeout, int nanos)(ZILjava/lang/String;II)Z | boolean regionMatches(boolean ignoreCase, int toOffset, String other, int ooffset, int len)([BII)I | int read(byte[] b, int off, int len )()[[Ljava/lang/Object; | Object[][] getObjectArray() 特殊方法的方法名首先要明确一下， 这里的特殊方法是指的类的构造方法和类型初始化方法。 构造方法就不用多说了， 至于类型的初始化方法， 对应到源码中就是静态初始化块。 也就是说， 静态初始化块， 在class文件中是以一个方法表述的， 这个方法同样有方法描述符和方法名。 类的构造方法的方法名使用字符串 表示， 而静态初始化方法的方法名使用字符串 表示。 除了这两种特殊的方法外， 其他普通方法的方法名， 和源文件中的方法名相同。 class文件中的访问标志信息 标志名 标志值 标志含义 针对的对像 ACC_PUBLIC 0x0001 public类型 所有类型 ACC_FINAL 0x0010 final类型 类 ACC_SUPER 0x0020 使用新的invokespecial语义 类和接口 ACC_INTERFACE 0x0200 接口类型 接口 ACC_ABSTRACT 0x0400 抽象类型 类和接口 ACC_SYNTHETIC 0x1000 该类不由用户代码生成 所有类型 ACC_ANNOTATION 0x2000 注解类型 注解 ACC_ENUM 0x4000 枚举类型 枚举 class文件字段的访问标志信息（flag） 标志名 标志值 标志含义 设定者 ACC_PUBLIC 0x0001 字段被设为public 类和接口 ACC_PRIVATE 0x0002 字段被设为private 类 ACC_PROTECTED 0x0004 字段被设为protected 类 ACC_STATIC 0x0008 字段被设为static 类和接口 ACC_FINAL 0x0010 字段被设为final 类和接口 ACC_VOLATILE 0x0040 字段被设为volatile 类 ACC_TRANSIENT 0x0080 字段被设为transient 类 描述的是方法的访问标志信息 标志名 标志值 标志含义 设定者 ACC_PUBLIC 0x0001 方法设为public 类和接口 ACC_PRIVATE 0x0002 方法设为private 类 ACC_PROTECTED 0x0004 方法设为protected 类 ACC_STATIC 0x0008 方法设为static 类 ACC_FINAL 0x0010 方法设为final 类 ACC_SYNCHRONIZED 0x0020 方法设为sychronized 类 ACC_NATIVE 0x0100 方法设为native 类 ACC_ABSTRACT 0x0400 方法设为abstract 类和接口 ACC_STRICT 0x0800 方法设为strictFP 类和接口的方法","categories":[],"tags":[{"name":"class","slug":"class","permalink":"https://chenadminchen.github.io/tags/class/"},{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"}]},{"title":"java class (一)","slug":"java-class-1","date":"2018-04-17T09:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/04/17/java-class-1/","link":"","permalink":"https://chenadminchen.github.io/2018/04/17/java-class-1/","excerpt":"","text":"java 类&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在创建一个普通的实体类，并且该类带有main方法，如下代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Person &#123; String name; int age; String describe; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getDescribe() &#123; return describe; &#125; public void setDescribe(String describe) &#123; this.describe = describe; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Person person = (Person) o; if (age != person.age) return false; if (name != null ? !name.equals(person.name) : person.name != null) return false; return describe != null ? describe.equals(person.describe) : person.describe == null; &#125; @Override public int hashCode() &#123; int result = name != null ? name.hashCode() : 0; result = 31 * result + age; result = 31 * result + (describe != null ? describe.hashCode() : 0); return result; &#125; @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age=\" + age + \", describe='\" + describe + '\\'' + '&#125;'; &#125; public static void main(String[] args) &#123; System.out.println(\"测试\"); &#125;&#125; javac编译&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入到当前目录，对Person.java进行编译，其 ‘javac className.java’ 12javac Person.java #其会在当前目标下生成Person.class java 执行&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入到当前目录，执行Person.class,其 ‘java className’ 12java Person 查看编译过后生成的class文件中的常量池&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入到当前目录，执行 ‘javap -verbose className.class’,可以看到编译过后的常量池 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377javap -verbose Person.class#结果如下Classfile /E:/Users/java/Person.class Last modified 2018-4-18; size 1726 bytes MD5 checksum 51074296dee03987f028c680cf1b10f7 Compiled from \"Person.java\"public class Person minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #21.#51 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Fieldref #6.#52 // Person.name:Ljava/lang/String; #3 = Fieldref #6.#53 // Person.age:I #4 = Fieldref #6.#54 // Person.describe:Ljava/lang/String; #5 = Methodref #21.#55 // java/lang/Object.getClass:()Ljava/lang/Class; #6 = Class #56 // Person #7 = Methodref #57.#58 // java/lang/String.equals:(Ljava/lang/Object;)Z #8 = Methodref #57.#59 // java/lang/String.hashCode:()I #9 = Class #60 // java/lang/StringBuilder #10 = Methodref #9.#51 // java/lang/StringBuilder.\"&lt;init&gt;\":()V #11 = String #61 // Person&#123;name=' #12 = Methodref #9.#62 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #13 = Methodref #9.#63 // java/lang/StringBuilder.append:(C)Ljava/lang/StringBuilder; #14 = String #64 // , age= #15 = Methodref #9.#65 // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; #16 = String #66 // , describe=' #17 = Methodref #9.#67 // java/lang/StringBuilder.toString:()Ljava/lang/String; #18 = Fieldref #68.#69 // java/lang/System.out:Ljava/io/PrintStream; #19 = String #70 // 娴嬭瘯 #20 = Methodref #71.#72 // java/io/PrintStream.println:(Ljava/lang/String;)V #21 = Class #73 // java/lang/Object #22 = Utf8 name #23 = Utf8 Ljava/lang/String; #24 = Utf8 age #25 = Utf8 I #26 = Utf8 describe #27 = Utf8 &lt;init&gt; #28 = Utf8 ()V #29 = Utf8 Code #30 = Utf8 LineNumberTable #31 = Utf8 getName #32 = Utf8 ()Ljava/lang/String; #33 = Utf8 setName #34 = Utf8 (Ljava/lang/String;)V #35 = Utf8 getAge #36 = Utf8 ()I #37 = Utf8 setAge #38 = Utf8 (I)V #39 = Utf8 getDescribe #40 = Utf8 setDescribe #41 = Utf8 equals #42 = Utf8 (Ljava/lang/Object;)Z #43 = Utf8 StackMapTable #44 = Class #56 // Person #45 = Utf8 hashCode #46 = Utf8 toString #47 = Utf8 main #48 = Utf8 ([Ljava/lang/String;)V #49 = Utf8 SourceFile #50 = Utf8 Person.java #51 = NameAndType #27:#28 // \"&lt;init&gt;\":()V #52 = NameAndType #22:#23 // name:Ljava/lang/String; #53 = NameAndType #24:#25 // age:I #54 = NameAndType #26:#23 // describe:Ljava/lang/String; #55 = NameAndType #74:#75 // getClass:()Ljava/lang/Class; #56 = Utf8 Person #57 = Class #76 // java/lang/String #58 = NameAndType #41:#42 // equals:(Ljava/lang/Object;)Z #59 = NameAndType #45:#36 // hashCode:()I #60 = Utf8 java/lang/StringBuilder #61 = Utf8 Person&#123;name=' #62 = NameAndType #77:#78 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #63 = NameAndType #77:#79 // append:(C)Ljava/lang/StringBuilder; #64 = Utf8 , age= #65 = NameAndType #77:#80 // append:(I)Ljava/lang/StringBuilder; #66 = Utf8 , describe=' #67 = NameAndType #46:#32 // toString:()Ljava/lang/String; #68 = Class #81 // java/lang/System #69 = NameAndType #82:#83 // out:Ljava/io/PrintStream; #70 = Utf8 娴嬭瘯 #71 = Class #84 // java/io/PrintStream #72 = NameAndType #85:#34 // println:(Ljava/lang/String;)V #73 = Utf8 java/lang/Object #74 = Utf8 getClass #75 = Utf8 ()Ljava/lang/Class; #76 = Utf8 java/lang/String #77 = Utf8 append #78 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #79 = Utf8 (C)Ljava/lang/StringBuilder; #80 = Utf8 (I)Ljava/lang/StringBuilder; #81 = Utf8 java/lang/System #82 = Utf8 out #83 = Utf8 Ljava/io/PrintStream; #84 = Utf8 java/io/PrintStream #85 = Utf8 println&#123; java.lang.String name; descriptor: Ljava/lang/String; flags: int age; descriptor: I flags: java.lang.String describe; descriptor: Ljava/lang/String; flags: public Person(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 1: 0 public java.lang.String getName(); descriptor: ()Ljava/lang/String; flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field name:Ljava/lang/String; 4: areturn LineNumberTable: line 7: 0 public void setName(java.lang.String); descriptor: (Ljava/lang/String;)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #2 // Field name:Ljava/lang/String; 5: return LineNumberTable: line 11: 0 line 12: 5 public int getAge(); descriptor: ()I flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #3 // Field age:I 4: ireturn LineNumberTable: line 15: 0 public void setAge(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #3 // Field age:I 5: return LineNumberTable: line 19: 0 line 20: 5 public java.lang.String getDescribe(); descriptor: ()Ljava/lang/String; flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #4 // Field describe:Ljava/lang/String; 4: areturn LineNumberTable: line 23: 0 public void setDescribe(java.lang.String); descriptor: (Ljava/lang/String;)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #4 // Field describe:Ljava/lang/String; 5: return LineNumberTable: line 27: 0 line 28: 5 public boolean equals(java.lang.Object); descriptor: (Ljava/lang/Object;)Z flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=2 0: aload_0 1: aload_1 2: if_acmpne 7 5: iconst_1 6: ireturn 7: aload_1 8: ifnull 22 11: aload_0 12: invokevirtual #5 // Method java/lang/Object.getClass:()Ljava/lang/Class; 15: aload_1 16: invokevirtual #5 // Method java/lang/Object.getClass:()Ljava/lang/Class; 19: if_acmpeq 24 22: iconst_0 23: ireturn 24: aload_1 25: checkcast #6 // class Person 28: astore_2 29: aload_0 30: getfield #3 // Field age:I 33: aload_2 34: getfield #3 // Field age:I 37: if_icmpeq 42 40: iconst_0 41: ireturn 42: aload_0 43: getfield #2 // Field name:Ljava/lang/String; 46: ifnull 66 49: aload_0 50: getfield #2 // Field name:Ljava/lang/String; 53: aload_2 54: getfield #2 // Field name:Ljava/lang/String; 57: invokevirtual #7 // Method java/lang/String.equals:(Ljava/lang/Object;)Z 60: ifne 75 63: goto 73 66: aload_2 67: getfield #2 // Field name:Ljava/lang/String; 70: ifnull 75 73: iconst_0 74: ireturn 75: aload_0 76: getfield #4 // Field describe:Ljava/lang/String; 79: ifnull 96 82: aload_0 83: getfield #4 // Field describe:Ljava/lang/String; 86: aload_2 87: getfield #4 // Field describe:Ljava/lang/String; 90: invokevirtual #7 // Method java/lang/String.equals:(Ljava/lang/Object;)Z 93: goto 108 96: aload_2 97: getfield #4 // Field describe:Ljava/lang/String; 100: ifnonnull 107 103: iconst_1 104: goto 108 107: iconst_0 108: ireturn LineNumberTable: line 32: 0 line 33: 7 line 35: 24 line 37: 29 line 38: 42 line 39: 75 StackMapTable: number_of_entries = 10 frame_type = 7 /* same */ frame_type = 14 /* same */ frame_type = 1 /* same */ frame_type = 252 /* append */ offset_delta = 17 locals = [ class Person ] frame_type = 23 /* same */ frame_type = 6 /* same */ frame_type = 1 /* same */ frame_type = 20 /* same */ frame_type = 10 /* same */ frame_type = 64 /* same_locals_1_stack_item */ stack = [ int ] public int hashCode(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=1 0: aload_0 1: getfield #2 // Field name:Ljava/lang/String; 4: ifnull 17 7: aload_0 8: getfield #2 // Field name:Ljava/lang/String; 11: invokevirtual #8 // Method java/lang/String.hashCode:()I 14: goto 18 17: iconst_0 18: istore_1 19: bipush 31 21: iload_1 22: imul 23: aload_0 24: getfield #3 // Field age:I 27: iadd 28: istore_1 29: bipush 31 31: iload_1 32: imul 33: aload_0 34: getfield #4 // Field describe:Ljava/lang/String; 37: ifnull 50 40: aload_0 41: getfield #4 // Field describe:Ljava/lang/String; 44: invokevirtual #8 // Method java/lang/String.hashCode:()I 47: goto 51 50: iconst_0 51: iadd 52: istore_1 53: iload_1 54: ireturn LineNumberTable: line 44: 0 line 45: 19 line 46: 29 line 47: 53 StackMapTable: number_of_entries = 4 frame_type = 17 /* same */ frame_type = 64 /* same_locals_1_stack_item */ stack = [ int ] frame_type = 255 /* full_frame */ offset_delta = 31 locals = [ class Person, int ] stack = [ int ] frame_type = 255 /* full_frame */ offset_delta = 0 locals = [ class Person, int ] stack = [ int, int ] public java.lang.String toString(); descriptor: ()Ljava/lang/String; flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: new #9 // class java/lang/StringBuilder 3: dup 4: invokespecial #10 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 7: ldc #11 // String Person&#123;name=' 9: invokevirtual #12 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 12: aload_0 13: getfield #2 // Field name:Ljava/lang/String; 16: invokevirtual #12 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: bipush 39 21: invokevirtual #13 // Method java/lang/StringBuilder.append:(C)Ljava/lang/StringBuilder; 24: ldc #14 // String , age= 26: invokevirtual #12 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 29: aload_0 30: getfield #3 // Field age:I 33: invokevirtual #15 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 36: ldc #16 // String , describe=' 38: invokevirtual #12 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 41: aload_0 42: getfield #4 // Field describe:Ljava/lang/String; 45: invokevirtual #12 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 48: bipush 39 50: invokevirtual #13 // Method java/lang/StringBuilder.append:(C)Ljava/lang/StringBuilder; 53: bipush 125 55: invokevirtual #13 // Method java/lang/StringBuilder.append:(C)Ljava/lang/StringBuilder; 58: invokevirtual #17 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 61: areturn LineNumberTable: line 52: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: getstatic #18 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #19 // String 娴嬭瘯 5: invokevirtual #20 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 60: 0 line 61: 8&#125;SourceFile: \"Person.java\" &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;查看编译过后class文件,从上面打印能够显示的看到的存在常量池中的变量存在85项,其实它存在86项,不要忘记了第0个常量,因为第0个常量被用来表示class中的数据项不引用任何常量池中的常量.","categories":[],"tags":[{"name":"class","slug":"class","permalink":"https://chenadminchen.github.io/tags/class/"},{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"}]},{"title":"servicemix long distance debug","slug":"servicemix-long-distance-debug","date":"2018-04-17T02:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/04/17/servicemix-long-distance-debug/","link":"","permalink":"https://chenadminchen.github.io/2018/04/17/servicemix-long-distance-debug/","excerpt":"","text":"servicemix设置命令别名&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ServiceMix是一个建立在JBI (JSR 208)语法规则和APIs上的开源ESB(Enterprise Service Bus:企业服务总线)。 它包括一个完整的JBI容器，其主要是由标准化信息服务和路由器，JBI管理MBeans，JBI配置单元和Ant任务（安装组 件和管理容器）组成。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;版本 ：Apache ServiceMix 7.0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;调试工具：IntelliJ IDEA 2017.1.4 x64 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;servicemix控制台设置:找到本地安装的servicemix文件夹，找到bin目录，cmd执行命令servicemix.bat debug即可，可以看到端口号 5005 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样，servicemix这里就设置好了，这个端口号是可以在servicemix.mix可以设置的，打开bin目录下servicemix.bat文件 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置好了，只要servicemix启动之后，运行刚刚设置的Remote，就可以远程调试了","categories":[],"tags":[{"name":"servicemix","slug":"servicemix","permalink":"https://chenadminchen.github.io/tags/servicemix/"},{"name":"debug","slug":"debug","permalink":"https://chenadminchen.github.io/tags/debug/"}]},{"title":"servicemix set alias","slug":"servicemix-set-alias","date":"2018-04-17T01:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/04/17/servicemix-set-alias/","link":"","permalink":"https://chenadminchen.github.io/2018/04/17/servicemix-set-alias/","excerpt":"","text":"servicemix设置命令别名&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;servicemix服务器使用了OSGI协议，而OSGI的目的是模块化，就是为了将一个大的应用分解成较小的模块，这些模块物理上就是一个个的jar包，也就是OSGI bundle。OSGI规范就是指导怎么令这些bundle能更好的有高内聚性、有松藕性，能更好地被复用。至于被神化的“动态性”、“热插拔”的特性，则是OSGI规范带来的一种可能，并不是一定会有的。因为OSGI的特性，在servicemix中某个应用程序所依赖的bundle过多时，则需要快速查找到某一类型的bundle，在servicemix中可以用如下命令 123#查找与mybatis相关的bundlela | grep mybatis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结果如下图: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;若每次查找mybatis相关的bundle时，都需要输入该指令，则会相对复杂，好在servicemix可以自定义指令，若想定义 ‘my’ 指令用于代替la | grep mybatis，其操作如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在etc/shell.init.script文件中配置如下指令: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;重启servicemix后使用指令 my 可得如下图:","categories":[],"tags":[{"name":"servicemix","slug":"servicemix","permalink":"https://chenadminchen.github.io/tags/servicemix/"},{"name":"alias","slug":"alias","permalink":"https://chenadminchen.github.io/tags/alias/"}]},{"title":"mysql information-schema","slug":"mysql-information-schema","date":"2018-03-30T08:58:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/30/mysql-information-schema/","link":"","permalink":"https://chenadminchen.github.io/2018/03/30/mysql-information-schema/","excerpt":"","text":"information-schema 介绍&nbsp;&nbsp;&nbsp;&nbsp;information_schema数据库是MySQL自带的，它提供了访问数据库元数据的方式。什么是元数据呢？元数据是关于数据的数据，如数据库名或表名，列的数据类型，或访问权限等。有些时候用于表述该信息的其他术语包括“数据词典”和“系统目录”。在 MySQL中，把 information_schema 看作是一个数据库，确切说是信息数据库。其中保存着关于MySQL服务器所维护的所有其他数据库的信息。如数据库名，数据库的表，表栏的数据类型与访问权限等。在INFORMATION_SCHEMA中，有数个只读表。它们实际上是视图，而不是基本表，因此，你将无法看到与之相关的任何文件。 information_schema数据库表说明SCHEMATA表：提供了当前mysql实例中所有数据库的信息。是show databases的结果取之此表。 TABLES表：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。是show tables from schemaname的结果取之此表。 COLUMNS表：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。是show columns from schemaname.tablename的结果取之此表。 STATISTICS表：提供了关于表索引的信息。是show index from schemaname.tablename的结果取之此表。 USER_PRIVILEGES（用户权限）表：给出了关于全程权限的信息。该信息源自mysql.user授权表。是非标准表。 SCHEMA_PRIVILEGES（方案权限）表：给出了关于方案（数据库）权限的信息。该信息来自mysql.db授权表。是非标准表。 TABLE_PRIVILEGES（表权限）表：给出了关于表权限的信息。该信息源自mysql.tables_priv授权表。是非标准表。 COLUMN_PRIVILEGES（列权限）表：给出了关于列权限的信息。该信息源自mysql.columns_priv授权表。是非标准表。 CHARACTER_SETS（字符集）表：提供了mysql实例可用字符集的信息。是SHOW CHARACTER SET结果集取之此表。 COLLATIONS表：提供了关于各字符集的对照信息。 COLLATION_CHARACTER_SET_APPLICABILITY表：指明了可用于校对的字符集。这些列等效于SHOW COLLATION的前两个显示字段。 TABLE_CONSTRAINTS表：描述了存在约束的表。以及表的约束类型。 KEY_COLUMN_USAGE表：描述了具有约束的键列。 ROUTINES表：提供了关于存储子程序（存储程序和函数）的信息。此时，ROUTINES表不包含自定义函数（UDF）。名为“mysql.proc name”的列指明了对应于INFORMATION_SCHEMA.ROUTINES表的mysql.proc表列。 VIEWS表：给出了关于数据库中的视图的信息。需要有show views权限，否则无法查看视图信息。 TRIGGERS表：提供了关于触发程序的信息。必须有super权限才能查看该表。 information_schema 表内容+—————————————+| Tables_in_information_schema |+—————————————+| CHARACTER_SETS || COLLATIONS || COLLATION_CHARACTER_SET_APPLICABILITY || COLUMNS || COLUMN_PRIVILEGES || ENGINES || EVENTS || FILES || GLOBAL_STATUS || GLOBAL_VARIABLES || KEY_COLUMN_USAGE || PARAMETERS || PARTITIONS || PLUGINS || PROCESSLIST || PROFILING || REFERENTIAL_CONSTRAINTS || ROUTINES || SCHEMATA || SCHEMA_PRIVILEGES || SESSION_STATUS || SESSION_VARIABLES || STATISTICS || TABLES || TABLESPACES || TABLE_CONSTRAINTS || TABLE_PRIVILEGES || TRIGGERS || USER_PRIVILEGES || VIEWS || INNODB_CMP_RESET || INNODB_TRX || INNODB_CMPMEM_RESET || INNODB_LOCK_WAITS || INNODB_CMPMEM || INNODB_CMP || INNODB_LOCKS | 使用information-schema 中的字段产生可执行的sql语句123456789101112131415161718SELECT * FROM tigase.user_jid;show databases;use information_schema;show tables;desc columns;-- ALTER TABLE `tigase`.`broadcast_msgs` CHANGE COLUMN `msg` `msg` VARCHAR(4096) CHARACTER SET &apos;utf8&apos; NOT NULL ;-- ALTER TABLE `tigase`.`broadcast_msgs_recipients` CHANGE COLUMN `msg_id` `msg_id` VARCHAR(128) CHARACTER SET &apos;utf8&apos; NOT NULL ;-- ALTER TABLE `tigase`.`broadcast_msgs` CHANGE COLUMN `id` `id` VARCHAR(128) CHARACTER SET &apos;utf8&apos; NOT NULL ;select table_name, column_name,COLUMN_DEFAULT, COLLATION_NAME,COLUMN_TYPE from COLUMNS where table_schema=&apos;tigase&apos; and data_type=&apos;varchar&apos; and collation_name = &apos;latin1_swedish_ci&apos;;select concat(&apos;alter table &apos;, &apos;\\`tigase\\`.\\`&apos;,table_name, &apos;\\` change column \\`&apos;, column_name, &apos;\\` \\`&apos;, column_name, &apos;\\` &apos;,COLUMN_TYPE,&apos; CHARACTER SET \\&apos;utf8\\&apos; NOT NULL&apos; ) from COLUMNS where table_schema=&apos;tigase&apos; and data_type=&apos;varchar&apos; and collation_name = &apos;latin1_swedish_ci&apos;;","categories":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"information-schema","slug":"information-schema","permalink":"https://chenadminchen.github.io/tags/information-schema/"}]},{"title":"react-native install","slug":"react-native","date":"2018-03-30T06:03:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/30/react-native/","link":"","permalink":"https://chenadminchen.github.io/2018/03/30/react-native/","excerpt":"","text":"react-native介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用React Native，你可以使用标准的平台组件，例如iOS的UITabBar或安卓的Drawer。 这使你的app获得平台一致的视觉效果和体验，并且获得最佳的性能和流畅性。 使用对应的React component，就可以轻松地把这些原生组件整合到你的React Native应用中 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Javascript代码和原生平台之间的所有操作都是异步执行的，并且原生模块还可以根据需要创建新的线程。这意味着你可以在主线程解码图片，然后在后台将它保存到磁盘，或者在不阻塞UI的情况下计算文字大小和界面布局等等。所以React Native开发的app天然具备流畅和反应灵敏的优势。Javascript和原生代码之间的通讯是完全可序列化的，这使得我们可以借助Chrome开发者工具去调试应用，而不论应用运行在模拟器还是真机上。 react-native安装&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用npm安装环境，但这前提条件是配置好了SDK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在visual studio code中编辑代码时，可以下载Flow Language Support 1234567891011121314151617181920#下载服务器npm install global react-native#安装react-native-cli，用于创建react-native的项目npm install -g yarn react-native-cli#安装yarn，用于管理组件npm install yarn#创建项目react-native init AwesomeProject#进入项目cd AwesomeProject#运行安装react-native run-android#下载其他需要的包时，可使用yarn 指令","categories":[],"tags":[{"name":"install","slug":"install","permalink":"https://chenadminchen.github.io/tags/install/"},{"name":"react-native","slug":"react-native","permalink":"https://chenadminchen.github.io/tags/react-native/"}]},{"title":"flutter","slug":"dart-array-x-y-z","date":"2018-03-27T06:36:45.000Z","updated":"2019-08-31T06:22:26.359Z","comments":true,"path":"2018/03/27/dart-array-x-y-z/","link":"","permalink":"https://chenadminchen.github.io/2018/03/27/dart-array-x-y-z/","excerpt":"","text":"dart one array divide into three group1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import 'dart:async';import 'package:async/async.dart';import 'package:rxdart/rxdart.dart';import 'package:test_api/test_api.dart';import 'package:training/models/storing_data.dart';main() &#123; group('array_x_y_z', () &#123; test('array_x_y_z_1', () &#123; List list = List(); List array = createArray(101); for (int i = 0; i &lt; (array.length) / 3; i++) &#123; int x = array[i]; int y = array[i + 33]; int z = array[i + 33 + 33]; list.add(&#123;'x': x, 'y': y, 'z': z&#125;); &#125; print(list.length); &#125;); test('array_x_y_z_2', () &#123; List list = createArray(101); List result = cal(list, 5); list.map((f) &#123;&#125;); assert(result.length == (list.length / 5).floor()); assert(result[0].length == 5); assert(result[0][0] == list[0]); assert(result[10][4] == list[result.length * 4 + 10]); &#125;); // test(\"array_x_y_z_3\", () &#123; // var array1 = array.getRange(0, 32); // var array2 = array.getRange(33, 65); // var array3 = array.getRange(66, 98); &#125;); test(\"array_x_y_z_3\", () async &#123; var firstCompleter = Completer(); List array = createArray(101); // // 5 StreamZip([ Stream.fromIterable(array.getRange(0, 50)), Stream.fromIterable(array.getRange(50, 100)), ]) .toList() .then(print) .whenComplete(()&#123; return firstCompleter.complete(); &#125;) ; await firstCompleter.future; &#125;, timeout: Timeout(Duration(seconds: 20)));&#125;List createArray(int size) &#123; return List&lt;int&gt;.generate(size, (int index) =&gt; index);&#125;List cal(List array, int size) &#123; // List&lt;List&gt; list = List(); var length = (array.length / size).floor(); return List&lt;List&gt;.generate(length, (index) =&gt; List&lt;int&gt;.generate(size, (c) =&gt; array[length * c + index])); // for (int j = 0; j &lt; length; j++) &#123; // var result = []; // for (int i = 0; i &lt; size; ++i) &#123; // result.add(array[length * i + j]); // &#125; // list.add(result); // &#125; // return list;&#125;Future future() async &#123; return await Future.delayed(Duration(seconds: 1), () &#123; return 1; &#125;);&#125;","categories":[],"tags":[{"name":"flutter","slug":"flutter","permalink":"https://chenadminchen.github.io/tags/flutter/"},{"name":"image","slug":"image","permalink":"https://chenadminchen.github.io/tags/image/"},{"name":"install","slug":"install","permalink":"https://chenadminchen.github.io/tags/install/"}]},{"title":"flutter","slug":"flutter","date":"2018-03-27T06:36:45.000Z","updated":"2019-11-07T11:47:47.461Z","comments":true,"path":"2018/03/27/flutter/","link":"","permalink":"https://chenadminchen.github.io/2018/03/27/flutter/","excerpt":"","text":"flutter介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flutter 是一个跨平台（Android 和 iOS）的移动开发框架，使用的是 Dart 语言。和 React Native 不同的是，Flutter 框架并不是一个严格意义上的原生应用开发框架。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Flutter 的目标是用来创建高性能、高稳定性、高帧率、低延迟的 Android 和 iOS 应用。并且开发出来的应用在不同的平台用起来跟原生应用具有一样的体验。不同的平台的原生体验应该得到保留，让该应用看起来同整个系统更加协调。不同平台的滚动操作、字体、图标 等特殊的特性 应该和该平台上的其他应用保持一致，让用户感觉就像操作原生应用一样。比如，返回图标 Android 和 iOS 是不一样的；滚动内容滚动到底的反馈也是不一样的。 安装flutter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用Git下载服务，并且配置好环境变量,便可使用flutter，但这前提条件是配置好了SDK 123456789101112#下载服务器git clone -b beta https://github.com/flutter/flutter.git#配置好环境变量path = D:\\flutter\\bin;#确定是否有硬件连接电脑flutter devices#进入某个项目下 运行安装flutter run flutter mirror configsudo nano /etc/profile12export PUB_HOSTED_URL=https://pub.flutter-io.cnexport FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cn source /etc/profile flutter change channel12# show channel options flutter channel flutter change version12345678# show version optionsflutter version# upgrade version flutter version 1.5.4# upgrade versionflutter upgrade flutter image&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;flutter中图片的加载分为从网络上获得，或者本地加载图片 flutter Image.assets&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Images.assets用于加载本地图片，项目结构如下图， 基本步骤如下： 1234567891011# 在pubspec.yaml中添加图片地址flutter: uses-material-design: true # 图片地址 assets: - assets/images/search.png# 引入图片： new Image.assets('assets/images/search.png', width:200.0, height:200.0)","categories":[],"tags":[{"name":"flutter","slug":"flutter","permalink":"https://chenadminchen.github.io/tags/flutter/"},{"name":"image","slug":"image","permalink":"https://chenadminchen.github.io/tags/image/"},{"name":"install","slug":"install","permalink":"https://chenadminchen.github.io/tags/install/"}]},{"title":"javaScript （二）","slug":"javaScript-2","date":"2018-03-15T08:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/15/javaScript-2/","link":"","permalink":"https://chenadminchen.github.io/2018/03/15/javaScript-2/","excerpt":"","text":"variable undefined&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当变量声明未初始化时，则属于undefined,若变量为number类型时属于NaN,并且undefined为false. 123456789var a;console.info(a); //a is undefinedvar c = a + 2;console.info(c); //c is NaNif (a === false)&#123; console.info('undefined equal to false ');&#125; const variable&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;const为常量，因此对于常量值时不可修改内容，但对于对象时，该对象将不再受到保护。 123456789const value = 9;value = 7; //is error ,value is const ,not be updatedconst my_object = &#123;'key': 'test'&#125;;my_object.key = 'object';console.info(my_object); //&#123;'key': 'object'&#125; 字符类型转为数字类型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;除了使用parseInt()、parseFloat()进行转换时，可用(+’ ‘)进行转换。 123'1.1' + '1.1'; // '1.11.1'(+'1.1') + (+'1.1'); // 2.2 数组中的删除与赋值为undefined的区别&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当用delete删除数组中的某个元素后，in判断当前元素是否存在于数组中,返回一个false,但如果直接赋值undefined，再判断时，则返回true 12345678var trees = ['test', 'test1', 'test2', 'test3'];delete trees[3];console.info(3 in trees); //falsetrees[2] = undefined;console.info(2 in trees); // true sort()排序&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sort()方法是按照字典顺序对元素进行排序，因此它假定元素都是字符串类型，并对其进行比较时，都是字符串类型的比较，对数字进行sort()时，可能会出现错误。 12345678910111213141516171819202122232425# 对字符串进行比较var names = [\"David\",\"Mike\",\"Cynthia\",\"Clayton\",\"Bryan\",\"Raymond\"];names.sort();print(names); // Bryan,Clayton,Cynthia,David,Mike,Raymond# 对数字进行对比,其无法得到正确的答案var nums = [3,2,100,4,200]nums.sort()print(nums) //100,2,200,3,4# 改进function compare(num1, num2)&#123; return num1-num2;&#125;var nums = [3,1,2,100,4,2900,2];nums.sort(compare);print(nums); //[1, 2, 2, 3, 4, 100, 2900]","categories":[],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"variable","slug":"variable","permalink":"https://chenadminchen.github.io/tags/variable/"}]},{"title":"React Native State","slug":"React-native-state","date":"2018-03-14T05:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/03/14/React-native-state/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/React-native-state/","excerpt":"","text":"React Native state定义&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;State必须能代表一个组件UI呈现的完整状态集，即组件的任何UI改变，都可以从State的变化中反映出来；同时，State还必须是代表一个组件UI呈现的最小状态集，即State中的所有状态都是用于反映组件UI的变化，没有任何多余的状态，也不需要通过其他状态计算而来的中间状态。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;组件中用到的一个变量是不是应该作为组件State，可以通过下面的4条依据进行判断： &lt;li这个变量是否是通过Props从父组件中获取？如果是，那么它不是一个状态。 这个变量是否在组件的整个生命周期中都保持不变？如果是，那么它不是一个状态。 这个变量是否可以通过其他状态（State）或者属性(Props)计算得到？如果是，那么它不是一个状态。 这个变量是否在组件的render方法中使用？如果不是，那么它不是一个状态。这种情况下，这个变量更适合定义为组件的一个普通属性，例如组件中用到的定时器，就应该直接定义为this.timer，this.state.timer。 请务必牢记，并不是组件中用到的所有变量都是组件的状态！当存在多个组件共同依赖一个状态时，一般的做法是状态上移，将这个状态放到这几个组件的公共父组件中 React Native 声明及修改123456789101112131415#声明class react extends React.component&#123; consurctor(props)&#123; super(props); this.state = &#123; title: \"测试\", content: \"测试中的内容\" &#125;; &#125;&#125;#修改时，可以部分修改this.setState(&#123; title: \"改变title\",&#125;); State 的更新是一个浅合并（Shallow Merge）的过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当调用setState修改组件状态时，只需要传入发生改变的State，而不是组件完整的State，因为组件State的更新是一个浅合并（Shallow Merge）的过程 State的更新是异步的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;调用setState，组件的state并不会立即改变，setState只是把要修改的状态放入一个队列中，React会优化真正的执行时机，并且React会出于性能原因，可能会将多次setState的状态修改合并成一次状态修改。所以不要依赖当前的State，计算下个State。当真正执行状态修改时，依赖的this.state并不能保证是最新的State，因为React会把多次State的修改合并成一次，这时，this.state将还是这几次State修改前的State。另外需要注意的事，同样不能依赖当前的Props计算下个状态，因为Props一般也是从父组件的State中获取，依然无法确定在组件状态更新时的值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举个例子，对于一个电商类应用，在我们的购物车中，当我们点击一次购买数量按钮，购买的数量就会加1，如果我们连续点击了两次按钮，就会连续调用两次this.setState({number: this.state.number + 1})，在React合并多次修改为一次的情况下，相当于等价执行了如下代码： 1234Object.assign( &#123;number: this.state.number + 1&#125;, &#123;number: this.state.number + 1&#125;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;后面的操作覆盖掉了前面的操作，最终购买的数量只增加了1个。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以使用另一个接收一个函数作为参数的setState，这个函数有两个参数，第一个是当前最新状态（本次组件状态修改后的状态）的前一个状态preState（本次组件状态修改前的状态），第二个参数是当前最新的属性props。如下所示： 1234// 正确this.setState((preState, props) =&gt; &#123; counter: preState.number + 1;&#125;)","categories":[],"tags":[{"name":"React Native","slug":"React-Native","permalink":"https://chenadminchen.github.io/tags/React-Native/"},{"name":"State","slug":"State","permalink":"https://chenadminchen.github.io/tags/State/"}]},{"title":"maven","slug":"maven","date":"2018-03-14T03:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/14/maven/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/maven/","excerpt":"","text":"maven指令1234567891011# 这个命令是在install时跳过test的类与javadoc的语句在run中设置-Dmaven.test.skip -Dmaven.javadoc.skip install#查看maven版本信息mvn -v test：测试 package：打包 compile:编译 clear:清除targer install:下载所需要的jar到本地仓库 maven环境变量名M2_HOME与MAVEN_HOME的区别&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;M2_HOME的地址&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MAVEN_HOME的地址","categories":[],"tags":[{"name":"maven","slug":"maven","permalink":"https://chenadminchen.github.io/tags/maven/"}]},{"title":"spring mvc error","slug":"spring-mvc-error","date":"2018-03-14T02:50:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/14/spring-mvc-error/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/spring-mvc-error/","excerpt":"","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1).java.lang.ClassNotFoundException:org.springframework.web.servlet.DispatcherServlet当tomact用maven导包后，需要在生成war后到资源里去查看WEB-INF中的lib中有没有包 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2).java.lang.NoClassDefFoundError: javax/servlet/jsp/jstl/core/Config当出现错误时：证明你在使用jsp页面时，并没有导入jsp相关的包 123456789101112131415161718192021222324252627&lt;!-- jsp标准标签库 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;1.6.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;","categories":[],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"https://chenadminchen.github.io/tags/spring-mvc/"},{"name":"error","slug":"error","permalink":"https://chenadminchen.github.io/tags/error/"}]},{"title":"spring mvc image uploading","slug":"spring-mvc-image-uploading","date":"2018-03-14T02:50:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/14/spring-mvc-image-uploading/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/spring-mvc-image-uploading/","excerpt":"","text":"upload.jsp123456789101112131415161718&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"pageEncoding=\"UTF-8\"%&gt;&lt;%@ taglib uri=\"http://www.springframework.org/tags/form\" prefix=\"form\" %&gt; &lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt; &lt;title&gt;Insert title here&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form action=\"addAction\" method=\"post\" enctype=\"multipart/form-data\"&gt; &lt;input type=\"text\" name=\"photoid\"/&gt; &lt;input type=\"file\" name=\"filename\"/&gt; &lt;input type=\"submit\" value=\"提交\"/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; java处理代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 新闻图片上传处理get请求 添加上传页面 @RequestMapping(value = \"/AddPicture\", method = &#123; RequestMethod.GET &#125;) public String addPicture(Model model) &#123; List&lt;TypeNews&gt; typeNews = userService.QueryTypeNews(); NewsPhoto newsPhoto = new NewsPhoto(); model.addAttribute(\"NewsPhoto\", newsPhoto); model.addAttribute(\"TypeNews\", typeNews); return \"back/sub/uploadPicture.jsp\"; &#125; // 新闻图片上传处理post请求 添加上传页面 @RequestMapping(value = \"/AddPicture\", method = &#123; RequestMethod.POST &#125;) public String addPicture(Model model, NewsPhoto newsPhoto, @RequestParam(value = \"Newsphotos\") MultipartFile file) &#123; Resource res = new ServletContextResource(context, \"/yfrxhPicture\"); //获得项目路径 File picRootFile = null; try &#123; picRootFile = res.getFile(); //查询项目中的文件名称 &#125; catch (IOException e1) &#123; return \"back/fail/fail_addPhotoNews.jsp\"; &#125; if (!picRootFile.exists()) &#123; picRootFile.mkdirs(); &#125; try &#123; InputStream inStream = file.getInputStream(); // 以流的形式获得图片 // 虚拟文件路径 Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd\"); String picFolderPath = sdf.format(date); // 以日期为文件夹 File picFolderFile = new File(picRootFile, picFolderPath); if (!picFolderFile.exists()) &#123; picFolderFile.mkdirs(); &#125; // pic 图片名字 String picName = date.getTime() + \".jpg\"; File picFile = new File(picFolderFile, picName); FileOutputStream fs = new FileOutputStream(picFile); byte[] buffer = new byte[1024 * 1024]; int bytesum = 0; int byteread = 0; while ((byteread = inStream.read(buffer)) != -1) &#123; bytesum += byteread; fs.write(buffer, 0, byteread); fs.flush(); &#125; String path=\"/yfrxh/img/\"+picFolderPath+\"/\"+picName; //该路径在spring-mvg.xml中存在映射 newsPhoto.setNewsPhoto(path); fs.close(); inStream.close(); &#125; catch (Exception e) &#123; return \"back/fail/fail_addPhotoNews.jsp\"; &#125; int data=userService.insertNewsPhoto(newsPhoto); if(data&gt;0)&#123; return \"redirect:/newsController/TypePhoto?nId=\"+newsPhoto.getTid(); &#125; return \"back/fail/fail_addPhotoNews.jsp\"; &#125; xml配置1234567891011121314&lt;mvc:resources location=\"/yfrxhPicture/\" mapping=\"/img/**\"/&gt; //静态资源的映射 若在spring mvc 中访问静态资源时，则需要配置 &lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt; &lt;property name=\"maxUploadSize\"&gt; &lt;value&gt;10485760000&lt;/value&gt; &lt;/property&gt; &lt;property name=\"maxInMemorySize\"&gt; &lt;value&gt;40960&lt;/value&gt; &lt;/property&gt; &lt;property name=\"defaultEncoding\"&gt; &lt;value&gt;UTF-8&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;","categories":[],"tags":[{"name":"spring mvc","slug":"spring-mvc","permalink":"https://chenadminchen.github.io/tags/spring-mvc/"},{"name":"imgae uploading","slug":"imgae-uploading","permalink":"https://chenadminchen.github.io/tags/imgae-uploading/"}]},{"title":"get from value","slug":"from-get-value","date":"2018-03-14T02:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/03/14/from-get-value/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/from-get-value/","excerpt":"","text":"代码如下123456789101112131415当前台需要向后台提交多条数据时，一般采用from表单中的name属性提交 （1）$(\"#id\").serialize();获得数据的格式：naem=xiaoming&amp;sex=1 键值对之间用&amp;连接 （2）$(\"#id\").serializeArray();获得返回的是Json对象的数量 格式：[objcet object],[objcet object] $.each(data,function(key,field))&#123; alert(key); //为index alert(field.name); //键值 alert(field.value); //为内容值 &#125; （3）var content= $(\"#id\").serializeArray().reduce(function(m,o)&#123;m[o.name] = o.value; return m;&#125;, &#123;&#125;);获得数据的格式：content[[objcet object]],content[[objcet object]]","categories":[],"tags":[{"name":"web","slug":"web","permalink":"https://chenadminchen.github.io/tags/web/"},{"name":"from","slug":"from","permalink":"https://chenadminchen.github.io/tags/from/"},{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"}]},{"title":"web pagin","slug":"web-paging","date":"2018-03-14T02:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/14/web-paging/","link":"","permalink":"https://chenadminchen.github.io/2018/03/14/web-paging/","excerpt":"","text":"代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128&lt;%@ page language=\"java\" import=\"java.util.*\" pageEncoding=\"UTF-8\"%&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;div&gt; &lt;font style=\"float: left;margin-left: 20px;\"&gt;共$&#123;personNum&#125;条&amp;nbsp;&amp;nbsp;&amp;nbsp;第$&#123;currentPage&#125;页/共$&#123;pageTimes&#125;页&lt;/font&gt; &lt;div id=\"div\" style=\"float: left;margin-left: 500px;\"&gt; &lt;c:if test=\"$&#123;paging=='search'&#125;\"&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"current\"&gt;首页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage!=1&#125;\"&gt; &lt;a href=\"LinkMessage?page=1&amp;mName=$&#123;Na&#125;\"&gt;首页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"disabled\"&gt;上一页 &lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage !=1&#125;\"&gt; &lt;a href=\"LinkMessage?page=$&#123;currentPage-1&#125;&amp;mName=$&#123;Na&#125;\"&gt;上一页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"current\"&gt;1&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage!=1&#125;\"&gt; &lt;a href=\"LinkMessage?page=1&amp;mName=$&#123;Na&#125;\"&gt;1&lt;/a&gt; &lt;/c:if&gt; &lt;% int pageTimes=(Integer)request.getAttribute(\"pageTimes\"); for(int i=1;i&lt;pageTimes;i++)&#123; request.setAttribute(\"page\", i+1); %&gt; &lt;c:if test=\"$&#123;currentPage == page&#125;\"&gt; &lt;span class=\"current\"&gt;&lt;%= i+1 %&gt;&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != page&#125;\"&gt; &lt;a href=\"LinkMessage?page=&lt;%= i+1 %&gt;&amp;mName=$&#123;Na&#125;\"&gt;&lt;%= i+1 %&gt;&lt;/a&gt; &lt;/c:if&gt; &lt;% &#125; %&gt; &lt;c:if test=\"$&#123;currentPage == pageTimes&#125;\"&gt; &lt;span class=\"disabled\"&gt;下一页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != pageTimes&#125;\"&gt; &lt;a href=\"LinkMessage?page=$&#123;currentPage+1&#125;&amp;mName=$&#123;Na&#125;\"&gt;下一页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage == pageTimes&#125;\"&gt; &lt;span class=\"disabled\"&gt;尾页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != pageTimes&#125;\"&gt; &lt;a href=\"LinkMessage?page=$&#123;pageTimes&#125;&amp;mName=$&#123;Na&#125;\"&gt;尾页&lt;/a&gt; &lt;/c:if&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;paging=='paging'&#125;\"&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"current\"&gt;首页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage!=1&#125;\"&gt; &lt;a href=\"Message?page=1\"&gt;首页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"disabled\"&gt;上一页 &lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage !=1&#125;\"&gt; &lt;a href=\"Message?page=$&#123;currentPage-1&#125;\"&gt;上一页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage==1&#125;\"&gt; &lt;span class=\"current\"&gt;1&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage!=1&#125;\"&gt; &lt;a href=\"Message?page=1\"&gt;1&lt;/a&gt; &lt;/c:if&gt; &lt;% int pageTimes=(Integer)request.getAttribute(\"pageTimes\"); for(int i=1;i&lt;pageTimes;i++)&#123; request.setAttribute(\"page\", i+1); %&gt; &lt;c:if test=\"$&#123;currentPage == page&#125;\"&gt; &lt;span class=\"current\"&gt;&lt;%= i+1 %&gt;&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != page&#125;\"&gt; &lt;a href=\"Message?page=&lt;%= i+1 %&gt;\"&gt;&lt;%= i+1 %&gt;&lt;/a&gt; &lt;/c:if&gt; &lt;% &#125; %&gt; &lt;c:if test=\"$&#123;currentPage == pageTimes&#125;\"&gt; &lt;span class=\"disabled\"&gt;下一页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != pageTimes&#125;\"&gt; &lt;a href=\"Message?page=$&#123;currentPage+1&#125;\"&gt;下一页&lt;/a&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage == pageTimes&#125;\"&gt; &lt;span class=\"disabled\"&gt;尾页&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test=\"$&#123;currentPage != pageTimes&#125;\"&gt; &lt;a href=\"Message?page=$&#123;pageTimes&#125;\"&gt;尾页&lt;/a&gt; &lt;/c:if&gt; &lt;/c:if&gt; &lt;/div&gt;&lt;/div&gt;分页的action写法// 获得新闻类型 @RequestMapping(\"/GetTypeNewsInfo\") public String getTypeNews(Model model, @RequestParam(value = \"nId\") Integer nId, String page) &#123; int pageSize = 10; List&lt;News&gt; news = userService.getTypeNews(nId); // 查到的总用户数 model.addAttribute(\"personNum\", news.size()); // 总页数 int pageTimes; if (news.size() == 0) &#123; pageTimes = 1; &#125; else if (news.size() % pageSize == 0) &#123; pageTimes = news.size() / pageSize; &#125; else &#123; pageTimes = news.size() / pageSize + 1; &#125; model.addAttribute(\"pageTimes\", pageTimes); // 页面初始的时候page没值 if (null == page) &#123; page = \"1\"; &#125; // 每页总第几条记录开始 int startRow = (Integer.parseInt(page) - 1) * pageSize; news = this.userService.getTypeNewsPage(nId, startRow, pageSize); model.addAttribute(\"currentPage\", Integer.parseInt(page)); model.addAttribute(\"paging\", \"paging\"); model.addAttribute(\"nId\", nId); model.addAttribute(\"News\", news); return \"back/sub/ByIdNews.jsp\"; &#125;","categories":[],"tags":[{"name":"web","slug":"web","permalink":"https://chenadminchen.github.io/tags/web/"},{"name":"paging","slug":"paging","permalink":"https://chenadminchen.github.io/tags/paging/"},{"name":"jsp","slug":"jsp","permalink":"https://chenadminchen.github.io/tags/jsp/"}]},{"title":"react-native-install-app","slug":"react-native-install-app","date":"2018-03-12T07:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/03/12/react-native-install-app/","link":"","permalink":"https://chenadminchen.github.io/2018/03/12/react-native-install-app/","excerpt":"","text":"recat-native create projectnode.js install&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下载node.js安装包,下载地址 yarn install&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用node下载yarn 1npm install yarn install SDK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SDK的下载地址&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;配置adb服务,下载地址,其学习地址 12#查看当前电脑连接的手机设备adb devices react-native install12345678910#安装react-native-cli包,获得react-native指令yarn global add react-native-cli#创建项目react-native init AwesomeProjectcd AwesomeProject#将安装app到客户端react-native run-android","categories":[],"tags":[{"name":"react-native","slug":"react-native","permalink":"https://chenadminchen.github.io/tags/react-native/"},{"name":"android studio","slug":"android-studio","permalink":"https://chenadminchen.github.io/tags/android-studio/"}]},{"title":"oauth2","slug":"oauth2","date":"2018-02-28T09:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/02/28/oauth2/","link":"","permalink":"https://chenadminchen.github.io/2018/02/28/oauth2/","excerpt":"","text":"oauth2 four rolesresource user&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;能够对受保护的资源进行授权的实体。当resource owner是人的时候，它是指终端用户 resource server&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;持有受保护的资源的服务器，使用access tokens能够接收和响应对受保护资源的请求 client&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在resource owner的行为和授权下，请求受保护资源的应用。“client”没有特指任何实现特性（比如，无论应用执行在服务器，桌面或者其他设备上） authorization server&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当成功认证了resource owner并且获得授权后，分发access tokens给client的服务器。","categories":[],"tags":[{"name":"未写完","slug":"未写完","permalink":"https://chenadminchen.github.io/tags/未写完/"},{"name":"oauth2","slug":"oauth2","permalink":"https://chenadminchen.github.io/tags/oauth2/"}]},{"title":"cas server set up","slug":"cas-server-set-up","date":"2018-02-28T04:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/02/28/cas-server-set-up/","link":"","permalink":"https://chenadminchen.github.io/2018/02/28/cas-server-set-up/","excerpt":"","text":"cas的学习下载基于5.2x版本的cas服务器&nbsp;&nbsp;&nbsp;&nbsp;下载地址 cas.properties文件配置&nbsp;&nbsp;&nbsp;&nbsp;在项目的cas-overlay-template\\etc\\cas\\config文件下需要配置cas.properties内相关的配置内容。&nbsp;&nbsp;&nbsp;&nbsp;以下是相关配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#server configcas.server.name: https://localhostcas.server.prefix: https://localhost/cas#logger，可在log4j2.xml中设置logger leverlogging.config: file:/etc/cas/config/log4j2.xml#adminPagesSecuritycas.adminPagesSecurity.ip=127\\.0\\.0\\.1cas.adminPagesSecurity.adminRoles[0]=ROLE_ADMINcas.adminPagesSecurity.actuatorEndpointsEnabled=true#openid connect Authenticationcas.authn.oidc.issuer=https://localhost/cas/oidccas.authn.oidc.jwksFile=file:/etc/cas/keystore.jwkscas.authn.oidc.dynamicClientRegistrationMode=OPENcas.authn.oidc.scopes=openid,profile,email,address,phone,offline_accesscas.authn.oidc.claims=sub,name,preferred_username,family_name,given_name,middle_name,given_name,profile,picture,nickname,website,zoneinfo,locale,updated_at,birthdate,email,email_verified,phone_number,phone_number_verified,addresscas.authn.oidc.claimsMap.given_name=emailcas.authn.oidc.claimsMap.phone_number=phone#accept.authn.users=casuser::Mellon,ROLE_ADMIN#用户名：casuser#密码：Mellon#取消有静态登录的警告cas.authn.accept.users=#service注册所在目录# json service registrycas.serviceRegistry.watcherEnabled=truecas.serviceRegistry.config.location=file:/etc/cas/servicescas.serviceRegistry.initFromJson=true# json service registry#cas.service-registry.init-from-json=true#cas.service-registry.json.location=file:/etc/cas/services# mysql databasecas.serviceRegistry.jpa.ddlAuto=create-dropcas.serviceRegistry.jpa.user=rootcas.serviceRegistry.jpa.password=xxxcas.serviceRegistry.jpa.driverClass=com.mysql.jdbc.Drivercas.serviceRegistry.jpa.url=jdbc:mysql://127.0.0.1:3306/cas?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useTimezone=true&amp;amp;serverTimezone=GMT%2B8:00&amp;amp;zeroDateTimeBehavior=roundcas.serviceRegistry.jpa.dialect=org.hibernate.dialect.HSQLDialectcas.serviceRegistry.jpa.autocommit=true# login databases configurecas.authn.jdbc.query[0].user=rootcas.authn.jdbc.query[0].password=xxxcas.authn.jdbc.query[0].driverClass=com.mysql.jdbc.Drivercas.authn.jdbc.query[0].url=jdbc:mysql://127.0.0.1:3306/yfaf?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useTimezone=true&amp;amp;serverTimezone=GMT%2B8:00&amp;amp;zeroDateTimeBehavior=roundcas.authn.jdbc.query[0].dialect=org.hibernate.dialect.MySQL5Dialect#login certificationcas.authn.jdbc.query[0].sql=SELECT LOWER(password) as password, deleted, account, name, nickname, date, phone, email, sex as gender, im_user_id as im, safety_id as safe_aid, com_id as company FROM user WHERE account=?cas.authn.jdbc.query[0].fieldPassword=passwordcas.authn.jdbc.query[0].passwordEncoder.type=DEFAULTcas.authn.jdbc.query[0].passwordEncoder.encodingAlgorithm=MD5cas.authn.jdbc.query[0].passwordEncoder.characterEncoding=UTF-8#ticket configurecas.ticket.registry.inMemory.cache=falsecas.ticket.registry.jpa.ddlAuto=create-dropcas.ticket.registry.jpa.user=rootcas.ticket.registry.jpa.password=as1996cas.ticket.registry.jpa.driverClass=com.mysql.jdbc.Drivercas.ticket.registry.jpa.url=jdbc:mysql://chen-PC:3306/cas?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useTimezone=true&amp;amp;serverTimezone=GMT%2B8:00&amp;amp;zeroDateTimeBehavior=round#用作https://localhost/cas/status/attrresolution页面查询cas.authn.attributeRepository.jdbc[0].user=rootcas.authn.attributeRepository.jdbc[0].password=as1996cas.authn.attributeRepository.jdbc[0].driverClass=com.mysql.jdbc.Drivercas.authn.attributeRepository.jdbc[0].url=jdbc:mysql://chen-PC:3306/yfaf?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useTimezone=true&amp;amp;serverTimezone=GMT%2B8:00&amp;amp;zeroDateTimeBehavior=roundcas.authn.attributeRepository.jdbc[0].singleRow=truecas.authn.attributeRepository.jdbc[0].requireAllAttributes=truecas.authn.attributeRepository.jdbc[0].sql=SELECT account, name, nickname, date, phone, email, sex as gender, im_user_id as im, safety_id as safe_aid, com_id as company FROM user WHERE account=&#123;0&#125;cas.authn.attributeRepository.jdbc[0].username=account#用作oidc查询映射cas.authn.attributeRepository.defaultAttributesToRelease=name,account#,nickname,date,phone,email,gender,im,safe_aid,company#将cas页面中查看 sso session/ register service page cas.monitor.endpoints.enabled=true cas.monitor.endpoints.sensitive=falsecas.monitor.endpoints.dashboard.enabled=truecas.monitor.endpoints.dashboard.sensitive=falsecas.monitor.endpoints.status.enabled=true cas.monitor.endpoints.status.sensitive=false#开启 jwt tokencas.authn.token.crypto.encryptionEnabled=truecas.authn.token.crypto.signingEnabled=true#jwt key,若key，未设置，则在启动时会自动生成下面的keycas.authn.token.crypto.encryption.key=xPZkj_A8RXlQfvD8EwmT7mU2TseRrcWHjM8q3R1AGikcas.authn.token.crypto.signing.key=PKH_BNwqiUDkMey108ix1fTWktUGXkALNBqoyE1NBT_RABe1WPY42FAqJOwCltLAa6duzvANst-Kxx7lYctrrgcas.tgc.crypto.encryption.key=kJbeEjRlDRQCixHWwn2WpjiXAwXzan8h_o-jCv89k90cas.tgc.crypto.signing.key=pR0GCaP_10pxitFBh2I2KNEGrDF9vb6HodyyV2u5u-3DkQiXd6GcSACeDfWxVsfS345ao99cIvF8ox4y_kjdSwcas.webflow.crypto.signing.key=TnK9AvAkwAbvFLIIZgtoT1K3YiGBWoebDIWC_8bozIfT2XKFGxQxochwa-d4Q_2WRwYwDv4Kw_d930MwywZHegcas.webflow.crypto.encryption.key=9fuRE_lJHtFmCVJUi8K3xQ 注册服务service.json 123456789101112131415161718192021222324252627282930313233343536373839404142&#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexRegisteredService&quot;, &quot;serviceId&quot; : &quot;^https?://.*&quot;, //所注册的服务地址 &quot;name&quot; : &quot;CAS Spring Secured App&quot;, &quot;description&quot;: &quot;This is a Spring App that usses the CAS Server for it&apos;s authentication&quot;, &quot;id&quot; : 19991, &quot;evaluationOrder&quot; : 1, &quot;proxyPolicy&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegexMatchingRegisteredServiceProxyPolicy&quot;, &quot;pattern&quot; : &quot;^https?://.*&quot; &#125;, //设置 生成 jwt时所要的key，该key来自于生成的cer中，则必需使用与cas服务器中相同的证书，可以不设置 &quot;publicKey&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.RegisteredServicePublicKeyImpl&quot;, &quot;location&quot; : &quot;file:/etc/cas/chen.cer&quot;, &quot;algorithm&quot; : &quot;RSA&quot; //证书生成时所使用的加密方式 &#125;， //使用jwt时才使用 &quot;properties&quot; : &#123; &quot;@class&quot; : &quot;java.util.HashMap&quot;, &quot;jwtAsServiceTicket&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.DefaultRegisteredServiceProperty&quot;, &quot;values&quot; : [ &quot;java.util.HashSet&quot;, [ &quot;true&quot; ] ] &#125;, // 可以不设置，若不设置，则在service启动时service 生成 &quot;jwtAsServiceTicketSigningKey&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.DefaultRegisteredServiceProperty&quot;, &quot;values&quot; : [ &quot;java.util.HashSet&quot;, [ &quot;ONOqVlFFievk5lo2Yz84S8J41DTrAJDbt4MnB2ZpniKAlzHitlL12xJ1VYxB8GpB&quot; ] ] //key一定为64字节，在jwtAsServiceTicketEncryptionKey加密才使用该加密 &#125;, // 可以不设置，若不设置，则在service启动时service 生成 &quot;jwtAsServiceTicketEncryptionKey&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.DefaultRegisteredServiceProperty&quot;, &quot;values&quot; : [ &quot;java.util.HashSet&quot;, [ &quot;afkeykeykeykyekyefdafsadfsdafdafdafsadfsafa&quot; ] ] //key一定为256位 ，先使用该key 加密 &#125; &#125;, //设置返回值的内类 &quot;attributeReleasePolicy&quot; : &#123; &quot;@class&quot; : &quot;org.apereo.cas.services.ReturnAllowedAttributeReleasePolicy&quot;, &quot;authorizedToReleaseCredentialPassword&quot; : true &#125; &#125; 配置pom.xml&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在cas-overlay-template项目下存在一个pom.xml文件，需要添加依赖包后，才会开启相应的功能，否则只存在一部分基础功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd \"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-overlay&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-webapp$&#123;app.server&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-jdbc-drivers&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;5.2.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-jdbc-authentication&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; #此处也需要添加,无法打包时可删除 &lt;!--&lt;dependency&gt; &lt;groupId&gt;org.jasig.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-jpa-ticket-registry&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-oidc&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-core-authentication&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-json-service-registry&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--jwt--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-token-tickets&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-json-service-registry&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--rest--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-rest&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apereo.cas&lt;/groupId&gt; &lt;artifactId&gt;cas-server-support-rest-tokens&lt;/artifactId&gt; &lt;version&gt;$&#123;cas.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; SSL认证生成私钥&nbsp;&nbsp;&nbsp;&nbsp;利用jdk自身的keytool生成相应的数字一个证书,生成证书到D:\\localhost.keystore 123456789101112131415161718192021222324252627282930313233#使用JDK的keytool命令，生成证书（包含证书/公钥/私钥）到D:\\localhost.keystore：#-ext san（subjectAltName）: 备用域名,在新的规范内代替cn，可映射到多个域名，也可指向ip,在chrome中需要设置 #您的名字与姓氏是（cn）:特殊的设置项，与域名相同D:&gt;keytool -genkey -keystore \"D:\\localhost.keystore\" -alias localhost -keyalg RSA -storepass changeit -ext san=dns:cas.example.org,ip:127.0.01输入密钥库口令:再次输入新口令:您的名字与姓氏是什么? [Unknown]: localhost您的组织单位名称是什么? [Unknown]: sishuok.com您的组织名称是什么? [Unknown]: sishuok.com您所在的城市或区域名称是什么? [Unknown]: beijing您所在的省/市/自治区名称是什么? [Unknown]: beijing该单位的双字母国家/地区代码是什么? [Unknown]: cnCN=localhost, OU=sishuok.com, O=sishuok.com, L=beijing, ST=beijing, C=cn是否正确? [否]: y输入 &lt;localhost&gt; 的密钥口令 (如果和密钥库口令相同, 按回车):再次输入新口令:#通过如上步骤，生成证书到D:\\ localhost.keystore； 生成公钥&nbsp;&nbsp;&nbsp;&nbsp;首先使用localhost.keystore导出数字证书（公钥）到D:\\localhost.cer 1234#-alias 与生成时的名字要相同D:&gt;keytool -export -alias localhost -file D:\\localhost.cer -keystore D:\\localhost.keystore 将其配置到jdk内&nbsp;&nbsp;&nbsp;&nbsp;因为CAS client需要使用该证书进行验证，需要将证书导入到JDK中 12345#需要进入jdk安装路径的security文件内D:&gt; cd D:\\jdk1.7.0_21\\jre\\lib\\securitykeytool -import -alias localhost -file D:\\localhost.cer -noprompt -trustcacerts -storetype jks -keystore cacerts -storepass changeit#若导入出现错误时,可将security目录下的cacerts删掉,再次导入 打包运行&nbsp;&nbsp;&nbsp;&nbsp;打包成功后会,项目内会出现target文件内存在cas.war的包 12345678910111213141516#将etc目录下的所有文件都复制到项目所在的根目下面build.cmd copy#自动生成证书build.cmd gencert#cmd进入项目文件下按github上面的指令进行打包D:&gt;build.cmd package -U # -U是清除后打包#打包后，再运行build.cmd run#直接运行war,需要进入到cas.war所在的目录下java -jar cas.war#可查看build.cmd/build.sh下自己写入启动方法 下面的步骤不需要使用将cas.war放入tomact容器&nbsp;&nbsp;&nbsp;&nbsp;将cas.war放入D:\\apache-tomcat-8.0.30\\webapps内 与tomact同级创建ect文件&nbsp;&nbsp;&nbsp;&nbsp;将项目中的ect文件全部复制到与tomact同级的磁盘存储,在该文件下只改变cas.properties内的内容时,不需要将项目重新打包,只需要将tomact重启就可生效配置文件 配置tomact的,认证SSL ,其中这一步可不执行,跳转到&nbsp;&nbsp;&nbsp;&nbsp;配置D:\\apache-tomcat-8.0.30\\conf下的server.xml文件,将下面的内容添加进出,认证SSL,其keystoreFile所指向的地方:为私钥存放的地方 12345&lt;Connector port=\"8443\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" maxThreads=\"150\" SSLEnabled=\"true\" scheme=\"https\" secure=\"true\" clientAuth=\"false\" sslProtocol=\"TLS\" keystoreFile=\"D:\\localhost.keystore\" keystorePass=\"123456\" /&gt; &nbsp;&nbsp;&nbsp;&nbsp;将其内容配置好后,启动tomcat,访问地址:https://127.0.0.1:8443/cas/login 若需要查看client可前往githut https://github.com/ChenAdminChen/java.git project: cas-client cas-client-test","categories":[],"tags":[{"name":"cas","slug":"cas","permalink":"https://chenadminchen.github.io/tags/cas/"},{"name":"openid","slug":"openid","permalink":"https://chenadminchen.github.io/tags/openid/"},{"name":"单点登录","slug":"单点登录","permalink":"https://chenadminchen.github.io/tags/单点登录/"}]},{"title":"karaf database driver","slug":"karaf-database","date":"2018-01-29T08:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/01/29/karaf-database/","link":"","permalink":"https://chenadminchen.github.io/2018/01/29/karaf-database/","excerpt":"","text":"下载servicemix所需要的包&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;database的数据源学习地址&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从官网下载最新的karaf容器，配置mysql数据源，基本操作如下： 123456feature:repo-add mvn:org.ops4j.pax.jdbc/pax-jdbc-features/0.8.0/xml/featuresfeature:install transaction jndi pax-jdbc-h2 pax-jdbc-pool-dbcp2 pax-jdbc-config #pax-jdbc-h2 是指你想连接那个数据库时，则下载相应的pax-jdbc-xxservice:list DataSourceFactory # 用于查看该容器里配置的数据源","categories":[],"tags":[{"name":"karaf","slug":"karaf","permalink":"https://chenadminchen.github.io/tags/karaf/"},{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"}]},{"title":"python venv","slug":"python-venv","date":"2018-01-26T07:33:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/01/26/python-venv/","link":"","permalink":"https://chenadminchen.github.io/2018/01/26/python-venv/","excerpt":"","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于python，创建一个virtual environments,用于存入特定项目所需要的包，方便快速搭建一个指定的python环境 venv&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;python中自带一个venv，可以创建虚拟环境学习地址 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按官网文档的要求，可以直接使用如下指令（本人将所有的虚拟环境创建在python35文件夹的venv内） 1D:\\Users\\Python\\Python35\\venv&gt; python -m venv py35 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按上面的指令进行创建时，可能会出现如下错误若出来如上的错误时，可以将–without-pip命令添加进去，若并未出来如下错误，则说明成功 1D:\\Users\\Python\\Python35\\venv&gt; python -m venv --without-pip py35 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将命令–without-pip添加进去时，则添加了一个不带pip指令的虚拟环境，因此需要自行安装pip指令，若不带–without-pip命令时，则不需要安装pip指令 开启虚拟环境window&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入刚创建好的py35/Scripts下运行activate.bat,如下图,开启虚拟环境 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在虚拟环境下退出deactivate.bat linux&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入刚创建好的py35,运行如下指令:12root@root#opt/py35: source ./bin/activate #开启虚拟环境deactivate #退出 pip指令的安装pip指令安装学习地址 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下载get-pip.py放入指定的虚拟环境内的Scripts文件夹中，开启虚拟环境，运行python get-pip.py,如图： virtualenv&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用第三方库创建虚拟环境时,需要安装virtualenv包 1pip install virtualenv &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;安装成功后可,使用virtualenv进行创建虚拟环境 12virtualenv –-no-site-packages py35 # --no-site-packages 用于创建一个不带任何第三方包干净的python虚拟环境virtualenv py35 虚拟环境中的包导入导出&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入指定的虚拟环境内运行pip freeze &gt; requirements.txt,将该环境内的所有的第三方库导出到requirements.txt文件内,可以使用pip list输出的包与requirements.txt文件的包对比一下 1pip freeze &gt; requirements.txt &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入指定的虚拟环境内运行pip install -r requirements.txt,将该文件内的第三方库安装到该虚拟环境内 1pip install -r requirements.txt","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://chenadminchen.github.io/tags/python/"},{"name":"venv","slug":"venv","permalink":"https://chenadminchen.github.io/tags/venv/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://chenadminchen.github.io/tags/virtualenv/"}]},{"title":"linux python install","slug":"linux-python-install","date":"2018-01-25T11:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/01/25/linux-python-install/","link":"","permalink":"https://chenadminchen.github.io/2018/01/25/linux-python-install/","excerpt":"","text":"下载python3.6.4安装包&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;python3.6.4安装包下载地址 linux下解压Python-3.6.4.tgz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将下载好的包放入linux下的opt文件夹内，使用如下命令解压包,完成后将会出现一个Python-3.6.4文件夹 1root@virtual-machine:/opt# tar -zvxf Python-3.6.4.tgz 创建存Python环境的文件夹&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;个人将python安装在opt文件夹内，因此进行opt文件夹内创建python3文件夹 1root@virtual-machine:/opt# mkdir python3 入解压后的目录，编译安装(Python-3.6.4)12#./configure --prefix 是设定软件安装到哪里。设置好参数，运行./configure，会生成makefile文件#root@virtual-machine:/opt/Python3.6.4# ./configure --prefix=/opt/python3 make 编译&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Configure 生成了makefile文件，运行make就可以完成编译。make是将读入所有由configure脚本程序建立的制作文件。这些制作文件会告诉make哪些文件需要被编译以及按照怎样的顺序对它们进行编译，因为可能会有上百个源程序文件。当make工作的时候，会在屏幕上显示出正在执行的每一个命令，以及与这个命令相关的全部参数。这些输出通常都是编译器的调用声明和所有传递给编译器的参数。如果编译器顺利地完成了工作，就不会出现什么错误信息。大多数编译器的错误信息十分清楚和明确，因此不用担心可能会漏掉一个错误。如果确实看到有一错误，也不用慌张。大多数错误信息并不反映出程序本身出现了一个问题，通常都是系统这里或者那里的问题。典型情况下，这些信息大多是因为文件访问权限不正确而产生的或者是因为文件没有找到 1root@virtual-machine:/opt/Python3.6.4# make make install&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;执行make install，这个命令将启动安装脚本程序。因为make命令会在执行每一个命令的时候把它显示出来，所以将会看到许许多多的文字掠过眼前。如果没有看到什么错误信息，就说明这个软件包安装好了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;卸载：make uninstall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意：如果下载的包里已经有了makefile 文件，就说明已经configure过了，直接安装就可以了。 1root@virtual-machine:/opt/Python3.6.4# make install 设置PATH路径&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进入ect文件夹中的profile，添加PATH路径,如下图的内容 12345#进入文件夹内# i: 进行文件内编辑文件内容 # 按ESC，输入:wq回车退出。root@virtual-machine:/ect# vim profileroot@virtual-machine:/ect# source ./ect/profile #对文件进行保存，并保证文件内容生效 检查python的版本信息12root@virtual-machine:python3 -V 学习地址 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注： 另一种安装方式 123sudo add-apt-repository ppa:jonathonf/python-3.6sudo apt-get updatesudo apt-get install python3.6","categories":[],"tags":[{"name":"install","slug":"install","permalink":"https://chenadminchen.github.io/tags/install/"},{"name":"python","slug":"python","permalink":"https://chenadminchen.github.io/tags/python/"},{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/tags/linux/"}]},{"title":"java isInstance instanceof isAssignableFrom","slug":"java-isinstance-instanceof-isAssignableFrom","date":"2018-01-15T12:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/01/15/java-isinstance-instanceof-isAssignableFrom/","link":"","permalink":"https://chenadminchen.github.io/2018/01/15/java-isinstance-instanceof-isAssignableFrom/","excerpt":"","text":"isInstance1B.class.isInstance(a) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;动态等价，用于检查泛型，jdk中的CheckedMap里面用到这个检查Map里面的key、value类型是否和约定一样 instanceof1class1 instanceof class &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;class1是class的实例，class是类的或者接口，父类或父接口，即B b = a成立 isAssignableFrom&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;两个class类型关系判断，判断B是不是A的子类或子接口1a instanceof B test12345678910111213User: 用户基类PublicUser extend User: PublicUser用户子类，继承User类PublicUser prUser = new PublicUser();#isintanceSystem.out.println(User.class.isintance prUser) //trueSystem.out.println(prUser intanceof User) //trueSystem.out.println(PublicUser.class.isAssignableFrom(User.class)) //trueSystem.out.println(User.class.isAssignableFrom(PublicUser.class)) //false","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"isInstance","slug":"isInstance","permalink":"https://chenadminchen.github.io/tags/isInstance/"},{"name":"instanceof","slug":"instanceof","permalink":"https://chenadminchen.github.io/tags/instanceof/"},{"name":"isAssignableFrom","slug":"isAssignableFrom","permalink":"https://chenadminchen.github.io/tags/isAssignableFrom/"}]},{"title":"javaScript Regular Expression","slug":"javaScript-RegExp","date":"2018-01-10T01:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2018/01/10/javaScript-RegExp/","link":"","permalink":"https://chenadminchen.github.io/2018/01/10/javaScript-RegExp/","excerpt":"","text":"Regular Expression&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在javaScript中正则表达式也是一个Object,学习地址 创建一个RegExp&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;javaScript中创建一个RegExp，有两种方法：12345# 利用RegExp对象创建var re = new RegExp('abc')# 利用特别的标记创建 /RegExp/var re = /abc/ 特殊字符的用意特殊字符 | 用法 | example | 出现0次或者多次 | re = /a*bc/ :”abc” is true, “bc” is true | 出现1次或者多次 | re = /a+bc/ :”abc” is true, “bc” is false? | 出现0次或者一次 | re = /e?le?/ :”angle” is le, “angele” is ele, “angl” is l, “angeel” is el\\ | 对于\\后面的字符不进行转译，当作原来的意途用 | re = /\\// :查找包括/的字符串。^ | 当它出现在表达式的最前面时，则表式紧跟它后面的字符必须出来在字符串的最前面 | re = /^A/ : “an A” is false, “A B” is true$ | 以什么结尾 | re = /t$/ :”eater” is false, “eat” is true","categories":[],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"RegExp","slug":"RegExp","permalink":"https://chenadminchen.github.io/tags/RegExp/"},{"name":"未写完","slug":"未写完","permalink":"https://chenadminchen.github.io/tags/未写完/"}]},{"title":"hbase shell","slug":"big-data-hbase-shell","date":"2018-01-01T08:36:45.000Z","updated":"2020-02-10T13:02:20.535Z","comments":true,"path":"2018/01/01/big-data-hbase-shell/","link":"","permalink":"https://chenadminchen.github.io/2018/01/01/big-data-hbase-shell/","excerpt":"","text":"shellscript1234567891011121314151617181920212223create 't1', 'f' # 创建表 tdescribe 't1' # 查看表信息scan 't1' #查看表数据put 't1', 'row5', 'f:f','value3',&#123;VERSIONS=&gt;1&#125; #插入数据,指定versionput 't1', 'row5', 'f:f','value1' #普通插入数据alter 't1', &#123;NAME=&gt;'f', VERSIONS=&gt;3&#125; # update cloumn famliy = `f` versionalter 't1', &#123;NAME=&gt;'f', MIN_VERSIONS=&gt;3&#125; # update cloumn famliy = `f` min version must not is 0 that version effect alter 't1', &#123;NAME=&gt;b&#125; # add a new familyget 't1', 'row5',&#123;COLUMN=&gt;'f:f'&#125; # get latest dataget 't1', 'row5',&#123;COLUMN=&gt;'f:f',VERSIONS=&gt;3&#125; # get three datadelete 't1', 'row5', 'b:a' #delete all datadelete 't1', 'row5', &#123;COLUMN='f:f', VERSIONS=&gt;1&#125; # delete VERSIONS is 1 , rowkey is row5, famliy name is 'f:f'","categories":[],"tags":[{"name":"big-data","slug":"big-data","permalink":"https://chenadminchen.github.io/tags/big-data/"},{"name":"hbase shell","slug":"hbase-shell","permalink":"https://chenadminchen.github.io/tags/hbase-shell/"}]},{"title":"java callBack function讲解","slug":"java-callBack","date":"2018-01-01T08:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2018/01/01/java-callBack/","link":"","permalink":"https://chenadminchen.github.io/2018/01/01/java-callBack/","excerpt":"","text":"模块调用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个软件系统都会存在模块与模块之间的调用，其之间的调用分为：同步调用，异步调用，回调 同步调用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同步调用是最简单也是最基本的一种调用方式，类A中的方法a()调用类B中的方法b()，等b()执行完成后再回到a()执行，该方式只适合执行完b()方法所需要的时间不长的情况，若b()执行所需要的时间过长时，a()方法处于等待状态，整个流程将会造成阻塞。 异步调用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异步调用是为解决同步调用时造成的阻塞，类A中的方法a()通过启用一个线程调用类B中的方法b(),其a()方法的代码继续执行，无论b()方法执行多长时间都不会影响a()的执行，则解决了b()方法执行过程则造成的阻塞情况。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异步调用中，a()方法不等待b()执行完，若a()方法中需要b()执行后返回的结果继续往下走，因此需要在a()内对b()方法执行的结果进行监听，a()获得结果后对其做出相应的操作。在java可以使用Futrue + Callable做到。 回调&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回调是指：类A的a()方法调用类B的b()方法，类B的b()方法执行完毕后主动调用类A的c()，方法其c()称为callback方法 java callBack实现实现两个整数相加简单的回调方法 回调类接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//回调接口类public interface CallBackTest &#123; int add(int a, int b);&#125;---------------------------------------------------------------------------------------//A类中方法public class CallBackTestA implements CallBackTest &#123; private CallBackTestB callBackTestB; public CallBackTestA(CallBackTestB callBackTesB)&#123; this.callBackTestB = callBackTesB; &#125; public void question(int a, int b)&#123; System.out.println(\"callBackTestA中的question函数 start\"); callBackTestB.addB(CallBackTestA.this ,a, b); System.out.println(\"callBackTestA中的question函数 end\"); &#125; //回调方法的实现 @Override public int add(int a, int b) &#123; System.out.println(\"callBackTestA中的回调函数\"); return a + b; &#125;&#125;//内部类的实现public class CallBackTestD &#123; private CallBackTestB callBackTestB; public CallBackTestA(CallBackTestB callBackTesB)&#123; this.callBackTestB = callBackTesB; &#125; public void question(int a, int b)&#123; System.out.println(\"callBackTestA中的question函数 start\"); callBackTestB.addB(new CallBackTestC() ,a, b); System.out.println(\"callBackTestA中的question函数 end\"); &#125; class CallBackTestC implements CallBackTest&#123; //回调方法的实现 @Override public int add(int a, int b) &#123; System.out.println(\"callBackTestA中的回调函数\"); return a + b; &#125; &#125;&#125;---------------------------------------------------------------------------------------//B类中c的方法public class CallBackTestB &#123; public void addB(CallBackTest callBackTest, int a, int b)&#123; System.out.println(\"调用CallBackTestB中的addB start\"); callBackTest.add(a, b); System.out.println(\"调用CallBackTestB中的addB end\"); &#125;&#125;//测试 @Test public void callBackTest()&#123; CallBackTestB callBackTestB = new CallBackTestB(); CallBackTestA callBackTestA = new CallBackTestA(callBackTestB); callBackTestA.question(1, 2); &#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"module call","slug":"module-call","permalink":"https://chenadminchen.github.io/tags/module-call/"},{"name":"callBack","slug":"callBack","permalink":"https://chenadminchen.github.io/tags/callBack/"}]},{"title":"Obsevable parttern","slug":"Obsevable-parttern","date":"2017-12-25T12:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2017/12/25/Obsevable-parttern/","link":"","permalink":"https://chenadminchen.github.io/2017/12/25/Obsevable-parttern/","excerpt":"","text":"观察者模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;观察者模式是对象的行为模式，又叫发布-订阅(Publish/Subscribe)模式、模型-视图(Model/View)模式、源-监听器(Source/Listener)模式或从属者(Dependents)模式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 观察者模式组成1.抽象主题角色：把所有对观察者对象的引用保存在一个集合中，每个抽象主题角色都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。2.抽象观察者角色：为所有具体的观察者定义一个接口，在得到主题的通知时更新自己。3.具体主题角色：在具体主题内部状态改变时，给所有登记过的观察者发出通知。具体主题角色通常用一个子类实现。4.具体观察者角色：该角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态相协调。通常用一个子类实现。如果需要，具体观察者角色可以保存一个指向具体主题角色的引用。## 观察者模式优点 第一、观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口。 由于被观察者和观察者没有紧密地耦合在一起，因此它们可以属于不同的抽象化层次。如果被观察者和观察者都被扔到一起，那么这个对象必然跨越抽象化和具体化层次。 第二、观察者模式支持广播通讯。被观察者会向所有的登记过的观察者发出通知 观察者模式有下面的缺点： 第一、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 第二、如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。 第三、如果对观察者的通知是通过另外的线程进行异步投递的话，系统必须保证投递是以自恰的方式进行的。 第四、虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的。### java库的observable与observer&nbsp;&nbsp;&nbsp;&nbsp;学习地址：https://docs.oracle.com/javase/8/docs/api/java/util/Observable.html&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在java中观察者模式存在被观察者与观察者的接口类，若需要实现观察者模式时，可以继承java.util.Observable及实现java.util.Observer两个接口就可以完成了，以下为实现两个接口的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// observerpublic class ConcretObserver implements Observer&#123; @Override public void update(Observable o, Object arg) &#123; System.out.println(o+ \"\\t\\t\"+ arg); &#125;&#125;//observablepublic class ConcretObservable extends Observable &#123; private String data = \"\"; public String retrieveData() &#123; return data; &#125; public void changeData(String data) &#123; if ( !this.data.equals( data) ) &#123; this.data = data; setChanged(); //记录上一次广播的数据与这一次的是否一样，若一样则不广播 &#125; notifyObservers(data); &#125;&#125;//testpublic class TestObservable &#123; public static void main(String args[]) &#123; ConcretObservable observable = new ConcretObservable(); Observer observer = new ConcretObserver(); Observer observer1 = new ConcretObserver(); Observer observer2 = new ConcretObserver(); Observer observer3 = new ConcretObserver(); observable.addObserver(observer); observable.addObserver(observer1); observable.addObserver(observer2); observable.addObserver(observer3); observable.changeData(\"测试\"); observable.changeData(\"测试\"); observable.changeData(\"测试1\"); &#125;&#125;### 自定义实现观察者模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;若将观察者模式提升到一个协议层，可以大概认为只要做到以下两个原则，便可认为它是一个观察者模式 一个观察者类中存在一个动作方法 被观察者类中应存在一个存观察者的set集合，添加观察者的方法、删除观察者的方法及循环调用观察者的动作的方法 java实现观察者模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778//observblepublic interface Watched &#123; void addWatch(Watcher watcher); void removeWatch(Watcher watcher); void notifyWatchers(String str);&#125;/** * 具体的被观察者 * Created by chen on 2017/12/19. */public class ConcretWatched implements Watched &#123; private List&lt;Watcher&gt; watchers = new ArrayList&lt;&gt;(); @Override public void addWatch(Watcher watcher) &#123; if(!watchers.contains(watcher))&#123; watchers.add(watcher); &#125; &#125; @Override public void removeWatch(Watcher watcher) &#123; watchers.remove(watcher); &#125; /** * 自动调用实际上是主题进行调用的 * @param str */ @Override public void notifyWatchers(String str) &#123; for (Watcher watcher : watchers) &#123; watcher.update(str); &#125; &#125;&#125;//observerpublic interface Watcher &#123; void update(String str);&#125;/** * 具体的观察者 * Created by chen on 2017/12/19. */public class ConcretWatcher implements Watcher &#123; @Override public void update(String str) &#123; System.out.println(str); &#125;&#125;//testpublic class TestWatch &#123; public static void main(String args[]) &#123; Watched wathced = new ConcretWatched(); Watcher watcher = new ConcretWatcher(); Watcher watcher1 = new ConcretWatcher(); Watcher watcher2 = new ConcretWatcher(); Watcher watcher3 = new ConcretWatcher(); wathced.addWatch(watcher); wathced.addWatch(watcher1); wathced.addWatch(watcher2); wathced.addWatch(watcher3); wathced.notifyWatchers(\"测试\"); &#125;&#125; javaScript实现观察者模式1234567891011121314151617181920212223242526272829303132#订阅者class Subscriber&#123; constructor(name)&#123; this.name = name; &#125; update(message)&#123; console.log (this.name + “收到通知消息”+ message); &#125;&#125;#生产者class publisher&#123; constructor()&#123; this.observers = new Set(); &#125; register(who)&#123; this.observers.add(who); &#125; unregister(who)&#123; this.observers.delete(who); &#125; dispatch(message)&#123; for (let observer of this.observers)&#123; observer.update(message); &#125; &#125;&#125; python实现观察者模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;学习地址：http://www.giantflyingsaucer.com/blog/?p=511712345678910111213141516171819202122232425262728class Subscriber: def __init__(self, name): self.name = name def update(self, message): print('&#123;&#125; got message \"&#123;&#125;\"'.format(self.name, message))class Publisher: def __init__(self): self.subscribers = set() def register(self,who): self.subscribers.add(who) def unregister(self, who): self.subscribers.discard(who) def dispathc(self, message): for subscriber in self.subscribers: subscriber.update(message)pub = Publisher()bob = Subscriber('Bob')alice = Subscriber('Alice')john = Subscriber('John')pub.register(bob)pub.register(alice)pub.register(john)pub.dispatch(\"It's lunchtime!\")pub.unregister(john)pub.dispatch(\"Time for dinner\")","categories":[],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"python","slug":"python","permalink":"https://chenadminchen.github.io/tags/python/"},{"name":"observable","slug":"observable","permalink":"https://chenadminchen.github.io/tags/observable/"}]},{"title":"tigase pubsub的xml格式","slug":"tigase-pubsub","date":"2017-12-25T08:53:56.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/12/25/tigase-pubsub/","link":"","permalink":"https://chenadminchen.github.io/2017/12/25/tigase-pubsub/","excerpt":"","text":"pubsub地址：https://xmpp.org/extensions/xep-0060.html 创建pubsub节点12345&lt;iq type='set' from='00000032@im.com/swm-mac' to='pubsub.im.com' id='create1'&gt; &lt;pubsub xmlns='http://jabber.org/protocol/pubsub'&gt; &lt;create node='story tell'/&gt; # story tell 为节点名称 &lt;/pubsub&gt;&lt;/iq&gt; 订阅节点12345&lt;iq type='set' from='00000010@im.com' to='pubsub.im.com' id='sub1'&gt; &lt;pubsub xmlns='http://jabber.org/protocol/pubsub'&gt; &lt;subscribe node='story tell' jid='00000010@im.com'/&gt; #订阅story tell节点 &lt;/pubsub&gt;&lt;/iq&gt; 所有者查看订阅人员12345&lt;iq type='get' from='12345677@im.com/elsinore' to='pubsub.im.com' id='subman1'&gt; &lt;pubsub xmlns='http://jabber.org/protocol/pubsub#owner'&gt; &lt;subscriptions node='story tell'/&gt; &lt;/pubsub&gt;&lt;/iq&gt; 查询某个pubsub的订阅者12345&lt;iq type='get' from='00000011@im.com' to='pubsub.im.com' id='subscriptions2'&gt; &lt;pubsub xmlns='http://jabber.org/protocol/pubsub'&gt; &lt;subscriptions node='story tell'/&gt; &lt;/pubsub&gt;&lt;/iq&gt; 向节点内发送消息123456789&lt;iq type =\"set\" from =\"00000010@im.com\" to=\"pubsub.im.com\" id=\"publish1\"&gt; &lt;pubsub xmlns =\"http://jabber.org/protocol/pubsub\"&gt; &lt;publish node =\"story tell\"&gt; &lt;item id=\"bnd81g37d61f49fgn581\"&gt; &lt;presence xmlns='http://yfaf.com/xmpp-ext/persence' jid=\"00000010@im.com\"&gt;20&lt;/presence&gt; &lt;/item&gt; &lt;/publish&gt; &lt;/pubsub&gt;&lt;/iq&gt; 删除订阅的节点12345&lt;iq type ='set'from ='12345678_yf.com@im.com/elsinore' to ='pubsub.im.com' id ='delete1 '&gt; &lt;pubsub xmlns ='http://jabber.org/protocol/pubsub#owner'&gt; &lt;delete node ='story tell'/ &gt; &lt;/ pubsub &gt;&lt;/iq &gt;","categories":[],"tags":[{"name":"tigase","slug":"tigase","permalink":"https://chenadminchen.github.io/tags/tigase/"},{"name":"pubsub","slug":"pubsub","permalink":"https://chenadminchen.github.io/tags/pubsub/"}]},{"title":"java equals","slug":"java-equal","date":"2017-11-28T12:36:45.000Z","updated":"2019-07-06T08:45:58.774Z","comments":true,"path":"2017/11/28/java-equal/","link":"","permalink":"https://chenadminchen.github.io/2017/11/28/java-equal/","excerpt":"","text":"== 与 equals基本比较&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)基本类型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本数据类型，也称原始数据类型。byte,short,char,int,long,float,double,boolean。他们之间的比较，应用双等号（==）,比较的是他们的值 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)复合数据类型(类)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当他们用（==）进行比较的时候，比较的是他们在内存中的存放地址，所以，除非是同一个new出来的对象，他们的比较后的结果为true，否则比较后结果为false。 JAVA当中所有的类都是继承于Object这个基类的，在Object中的基类中定义了一个equals的方法，这个方法的初始行为是比较对象的内存地址，但在一些类库当中这个方法被覆盖掉了，如String,Integer,Date在这些类当中equals有其自身的实现，而不再是比较类在堆内存中的存放地址了。对于复合数据类型之间进行equals比较，在没有覆写equals方法的情况下，他们之间的比较还是基于他们在内存中的存放位置的地址值的，因为Object的equals方法也是用双等号（==）进行比较的，所以比较后的结果跟双等号（==）的结果相同。 jdk中equals12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Indicates whether some other object is \"equal to\" this one. * &lt;p&gt; * The &#123;@code equals&#125; method implements an equivalence relation * on non-null object references: * &lt;ul&gt; * &lt;li&gt;It is &lt;i&gt;reflexive&lt;/i&gt;: for any non-null reference value * &#123;@code x&#125;, &#123;@code x.equals(x)&#125; should return * &#123;@code true&#125;. * &lt;li&gt;It is &lt;i&gt;symmetric&lt;/i&gt;: for any non-null reference values * &#123;@code x&#125; and &#123;@code y&#125;, &#123;@code x.equals(y)&#125; * should return &#123;@code true&#125; if and only if * &#123;@code y.equals(x)&#125; returns &#123;@code true&#125;. * &lt;li&gt;It is &lt;i&gt;transitive&lt;/i&gt;: for any non-null reference values * &#123;@code x&#125;, &#123;@code y&#125;, and &#123;@code z&#125;, if * &#123;@code x.equals(y)&#125; returns &#123;@code true&#125; and * &#123;@code y.equals(z)&#125; returns &#123;@code true&#125;, then * &#123;@code x.equals(z)&#125; should return &#123;@code true&#125;. * &lt;li&gt;It is &lt;i&gt;consistent&lt;/i&gt;: for any non-null reference values * &#123;@code x&#125; and &#123;@code y&#125;, multiple invocations of * &#123;@code x.equals(y)&#125; consistently return &#123;@code true&#125; * or consistently return &#123;@code false&#125;, provided no * information used in &#123;@code equals&#125; comparisons on the * objects is modified. * &lt;li&gt;For any non-null reference value &#123;@code x&#125;, * &#123;@code x.equals(null)&#125; should return &#123;@code false&#125;. * &lt;/ul&gt; * &lt;p&gt; * The &#123;@code equals&#125; method for class &#123;@code Object&#125; implements * the most discriminating possible equivalence relation on objects; * that is, for any non-null reference values &#123;@code x&#125; and * &#123;@code y&#125;, this method returns &#123;@code true&#125; if and only * if &#123;@code x&#125; and &#123;@code y&#125; refer to the same object * (&#123;@code x == y&#125; has the value &#123;@code true&#125;). * &lt;p&gt; * Note that it is generally necessary to override the &#123;@code hashCode&#125; * method whenever this method is overridden, so as to maintain the * general contract for the &#123;@code hashCode&#125; method, which states * that equal objects must have equal hash codes. * * @param obj the reference object with which to compare. * @return &#123;@code true&#125; if this object is the same as the obj * argument; &#123;@code false&#125; otherwise. * @see #hashCode() * @see java.util.HashMap */ public boolean equals(Object obj) &#123; return (this == obj); &#125; class类中不重写equals方法1234567891011121314151617181920212223public class TestEquals &#123; public static void main(String[] args) &#123; Value value1 = new Value(); Value value2 = new Value(); value1.i = value2.i = \"sss\"; System.out.println(\"value1.equals(value2): \" + value1.equals(value2)); System.out.println(\"value1 == value2: \" + (value1 == value2 )); System.out.println(\"value1.i:\" + value1.i); System.out.println(\"value2.i:\" + value2.i); &#125;&#125;class Value&#123; String i;&#125;#结果value1.equals(value2): falsevalue1 == value2: false class类中重写equals12345678910111213141516171819202122232425262728293031323334353637public class TestEquals &#123; public static void main(String[] args) &#123; Value value1 = new Value(); Value value2 = new Value(); value1.i = value2.i = \"sss\"; System.out.println(\"value1.equals(value2): \" + value1.equals(value2)); System.out.println(\"value1 == value2: \" + (value1 == value2 )); System.out.println(\"value1.i:\" + value1.i); System.out.println(\"value2.i:\" + value2.i); &#125;&#125;class Value&#123; String i; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Value value = (Value) o; return i != null ? i.equals(value.i) : value.i == null; &#125; @Override public int hashCode() &#123; return i != null ? i.hashCode() : 0; &#125;#结果value1.equals(value2): truevalue1 == value2: false","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"equals","slug":"equals","permalink":"https://chenadminchen.github.io/tags/equals/"}]},{"title":"mysql SQL定义","slug":"mysql-SQL","date":"2017-11-28T12:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/28/mysql-SQL/","link":"","permalink":"https://chenadminchen.github.io/2017/11/28/mysql-SQL/","excerpt":"","text":"TCL（Transaction Control Language）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事务控制语言 1234SAVEPOINT #设置保存点ROLLBACK #回滚START TRANSACTION #开始事务COMMIT #提交事务 DML（data manipulation language）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据操作语言 它们是SELECT、UPDATE、INSERT、DELETE，这4条命令是用来对数据库里的数据进行操作的语言 1234CREATE - to create objects in the database #创建ALTER - alters the structure of the database #修改DROP - delete objects from the database #删除TRUNCATE - remove all records from a table, including all spaces allocated for the records are removed DDL（data definition language）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DDL比DML要多，主要的命令有CREATE、ALTER、DROP等，DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用 1234567SELECT - retrieve data from the a database #查询INSERT - insert data into a table #添加UPDATE - updates existing data within a table #更新DELETE - deletes all records from a table, the space for the records remain #删除CALLEXPLAIN PLANLOCK TABLE - control concurrency #锁，用于控制并发 DCL（Data Control Language）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。在默认状态下，只有sysadmin,dbcreator,db_owner或db_securityadmin等人员才有权力执行DCL 123GRANT #授权REVOKE #取消授权 mysql远程连接1mysql -h127.0.0.1 -u root -p -D databaseName SHOW VARIABLES LIKE ‘%innodb_lock_wait%’;SET innodb_lock_wait_timeout=600;","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"SQL","slug":"SQL","permalink":"https://chenadminchen.github.io/tags/SQL/"}]},{"title":"mysql表的列、外键与索引","slug":"mysql-table-column","date":"2017-11-28T12:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/28/mysql-table-column/","link":"","permalink":"https://chenadminchen.github.io/2017/11/28/mysql-table-column/","excerpt":"","text":"查看表结构1show create tabel table_name; 对列的操作12345678#查看列show full columns from table_name#删除一列alter table 表名 drop column 列名#添加一列alter table 表名 add 列名 varchar(20) default 0 对外键的操作外键的使用条件： 两个表必须是InnoDB表，MyISAM表暂时不支持外键（据说以后的版本有可能支持，但至少目前不支持）。 外键列必须建立了索引，MySQL 4.1.2以后的版本在建立外键时会自动创建索引，但如果在较早的版本则需要显示建立，若外键不存在索引则会容易引起死锁。 外键关系的两个表的列必须是数据类型相似，也就是可以相互转换类型的列，比如int和tinyint可以，而int和char则不可以。 外键的好处：可以使得两张表关联，保证数据的一致性和实现一些级联操作。 12345#增加表外键# [ON DELETE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;]# [ON UPDATE &#123;RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT&#125;]alter table table_name add constraint foreign_key_name foreign key (column_name) references table_name(column_name) on delete on action; 该语法可以在 CREATE TABLE 和 ALTER TABLE 时使用，如果不指定CONSTRAINT symbol，MYSQL会自动生成一个名字。ON DELETE、ON UPDATE表示事件触发限制，可设参数： RESTRICT（限制外表中的外键改动） CASCADE（跟随外键改动） SET NULL（设空值） SET DEFAULT（设默认值） NO ACTION（无动作，默认的） 1234#删除外键alter table table_name drop foreign key foreign_key_name;drop foreign key foreign_key_name on table_name; 对索引的操作123456789101112#查看表索引show index from table_name;#增加表唯一索引ALTER TABLE table_name ADD UNIQUE INDEX `index_name` (`columns_name` ASC)#增加表的主键ALTER TABLE table_name ADD PRIMARY KEY (columns_name)#删除表索引alter table table_name drop index index_name;drop index index_name on table_name","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"SQL","slug":"SQL","permalink":"https://chenadminchen.github.io/tags/SQL/"},{"name":"DDL","slug":"DDL","permalink":"https://chenadminchen.github.io/tags/DDL/"}]},{"title":"window cmd 总结","slug":"window-cmd","date":"2017-11-22T08:58:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/22/window-cmd/","link":"","permalink":"https://chenadminchen.github.io/2017/11/22/window-cmd/","excerpt":"","text":"window cmd 指令查看端口是否是用12345#后接需要查寻的端口netstat -aon|findstr \"49157\"#查看网速是否连接成功ping 127.0.0.1","categories":[{"name":"window","slug":"window","permalink":"https://chenadminchen.github.io/categories/window/"}],"tags":[{"name":"window cmd","slug":"window-cmd","permalink":"https://chenadminchen.github.io/tags/window-cmd/"}]},{"title":"mysqlx json function","slug":"mysql-mysqlx-1","date":"2017-11-22T01:40:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/22/mysql-mysqlx-1/","link":"","permalink":"https://chenadminchen.github.io/2017/11/22/mysql-mysqlx-1/","excerpt":"","text":"mysqlx对json类型的基本操作生成json格式的数据生成json格式的普通数据123456mysql&gt; SELECT JSON_OBJECT('id', 87, 'name', 'carrot');+-----------------------------------------+| JSON_OBJECT('id', 87, 'name', 'carrot') |+-----------------------------------------+| &#123;\"id\": 87, \"name\": \"carrot\"&#125; |+-----------------------------------------+ 生成array型的数据123456mysql&gt; SELECT JSON_ARRAY(1, \"abc\", NULL, TRUE, CURTIME());+---------------------------------------------+| JSON_ARRAY(1, \"abc\", NULL, TRUE, CURTIME()) |+---------------------------------------------+| [1, \"abc\", null, true, \"11:30:24.000000\"] |+---------------------------------------------+ 生成array包括json型的数据123456mysql&gt; SELECT JSON_ARRAY(JSON_OBJECT('id', 87, 'name', 'carrot'), JSON_OBJECT('id', 87, 'name', 'carrot'));+---------------------------------------------+| JSON_ARRAY(JSON_OBJECT('id', 87, 'name', 'carrot'), JSON_OBJECT('id', 87, 'name', 'carrot')) |+---------------------------------------------+| [&#123;\"id\": 87, \"name\": \"carrot\"&#125;, &#123;\"id\": 87, \"name\": \"carrot\"&#125;] |+---------------------------------------------+ 修改json格式的操作mysql表中的结构12345678910111213141516171819202122CREATE TABLE `consult` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(45) NOT NULL, `specialist_id` varchar(45) DEFAULT NULL, `public` int(11) DEFAULT NULL, `title` varchar(45) DEFAULT NULL, `content` varchar(45) DEFAULT NULL, `resouce` json DEFAULT NULL, #格式：&#123;&#125; `reply` json DEFAULT NULL, #格式：[&#123;&#125;,&#123;&#125;] PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;``` #### 修改普通格式的json数据``` bash#添加update consult set doc = JSON_INSERT(resouce,'$.resouce',\"http://img/imgs.jpg\") where id = 1;#修改update consult set doc = JSON_REPLACE(resouce,'$.resouce',\"http://img/imgs.jpg\") where id = 1;#删除update consult set doc = JSON_remove(resouce,'$.resouce') where id = 1; 修改带arrag的json数据1234567891011121314151617181920#reply中具体格式reply:[ &#123; \"time\": \"2017-11-21 16:49:42.000000\", \"comment\": \"可以多运动\", \"user_id\": \"456@yf.com\", \"index\":0 //该index的值是这条数据在数组中的下标，自行添加并管理 &#125;]# 对json里的数组进行操作update consult set reply = NULL where id =1;update consult set reply = '[&#123;\"time\": \"2017-11-21 16:49:42.000000\", \"comment\": \"可以多运动\", \"user_id\": \"456@yf.com\",\"index\":0&#125;]' where id = 1;#在json格式里的数组添加值update consult set reply = JSON_ARRAY_INSERT(reply,concat('$[',JSON_LENGTH(reply),']'),JSON_OBJECT('user_id','12355@yf.com','time',now(),'comment','但是感觉没有太多的作用','index',JSON_LENGTH(reply))) where id = 1;#修改json格式里的数组信息update consult set reply = JSON_REPLACE(reply,'$[2]',JSON_OBJECT('user_id','12355@yf.com','time',now(),'comment','测试修改','index',2)) where id =1; 删除json内的数据123456#指定删除json里数组的某个值update consult set reply = JSON_REMOVE(reply,'$[2]') where id = 1;db.collection.update(&#123;'id': , 'reply.user_id': &#125;,&#123;$set:&#123; &#125;&#125;)db.collection.update(&#123;'id':1 , 'reply.user_id：\"123@yf.com\" &#125;,&#123;$set:&#123;'reply.' &#125;&#125;) 获得json中array的长度1select JSON_LENGTH(reply) from consult where id = 1;","categories":[{"name":"mysqlx","slug":"mysqlx","permalink":"https://chenadminchen.github.io/categories/mysqlx/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"mysqlx","slug":"mysqlx","permalink":"https://chenadminchen.github.io/tags/mysqlx/"}]},{"title":"mysql error 总结","slug":"mysql-error","date":"2017-11-22T01:35:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/22/mysql-error/","link":"","permalink":"https://chenadminchen.github.io/2017/11/22/mysql-error/","excerpt":"","text":"ERROR 1728 (HY000)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ERROR 1728 (HY000) CANNOT LOAD FROM MYSQL.PROC. THE TABLE IS PROBABLY CORRUPTED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在对mysql软件进行升级后，可能存在mysql内的内置表没有升级成功，因此需要自动更新数据库，进入cmd内，执行如下代码： 12mysql_upgrade -u root -p passward 数据导入出错&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当A表的数据由B表的数据插入时用触发器生成时，若向A导入数据时可能会出现错： 触发器可能会导致主键重复的错误，原因是A表中的数据由此触发器插入，但数据导入脚本也导入了已有数据，导致冲突。 因此，在触发器中增加对用户自定义变量 @disable_triggers 的检查，此变量为null时才执行动作。当需要禁止触发器动作时，设置此变量为1即可。 然后修改数据导入脚本，在前、后分别增加 禁止触发器 和 恢复触发器 的设置。","categories":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"mysql-error","slug":"mysql-error","permalink":"https://chenadminchen.github.io/tags/mysql-error/"}]},{"title":"javaScript （一）","slug":"javaScript-1","date":"2017-11-21T01:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/21/javaScript-1/","link":"","permalink":"https://chenadminchen.github.io/2017/11/21/javaScript-1/","excerpt":"","text":"调用fun 与 fun ()区别&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在javaScript中调用方法时加（）与不加（）时，都不会出错，会出现两种不同的结果，当方法名加上（）调用时，可会执行方法中的逻辑，但如果不加（）时，则会将方法本身的信息打印出来，如下： 12345678&lt;script&gt; function add(x , y)&#123; return x+y; &#125; console.log(add(7, 8)); #15 console.log(add); # function add(x , y)&#123; return x+y;&#125; &lt;/script&gt; javaScript中给某个标签赋值操作12345678# demo is tag id namedocument.getElementById(\"demo\").innerHTML = \"content\";#demo is tag class namedocument.getElementsByClassName(\"demo\").innerHTML = \"content\";# demo is tag name namedocument.getElementsByName(\"demo\").innerHTML = \"content\";# input is tag namedocument.getElementsByTagName(\"input\").innerHTML = \"content\"; getElementByName&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法与 getElementById() 方法相似，但是它查询元素的 name 属性，而不是 id 属性。另外，因为一个文档中的 name 属性可能不唯一（如 HTML 表单中的单选按钮通常具有相同的 name 属性），所有 getElementsByName() 方法返回的是元素的数组，而不是一个元素。 getElementsByTagName&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getElementsByTagName() 方法可返回带有指定标签名的对象的集合。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getElementsByTagName() 方法返回元素的顺序是它们在文档中的顺序。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果把特殊字符串 “*” 传递给 getElementsByTagName() 方法，它将返回文档中所有元素的列表，元素排列的顺序就是它们在文档中的顺序。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;传递给 getElementsByTagName() 方法的字符串可以不区分大小写。 function object对象12345678910#person is objectvar person = &#123; age: 13, name: \"test\", sex: \"男\"&#125;#第一种取值方法var age1 = person.age; # age1 is 13#第二种取值方法var age2 = person[\"age\"]; # age2 is 13 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当变量声明时使用了“new”关键字是，则代表为object对象 String的特殊方法slice()（python）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;空格也算一个字符串123456789101112var str = 'Apple, Banana, Kiwi';#slice(start,end) 可以从后往前数var pos = str.slice(-12,-9); # pos = Banvar pos1 = str.slice(-12); # pos1 = Banana, Kiwi``` ### concat()(mysql)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;两个字符串拼接``` bashvar text1 = \"Apple\";var text2 = \"Banana\";var text3 = text1.concat(\" \",text2); #Apple Banana charAt() &amp; charCodeAt()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;charAt从一个字符串中获得一个字符&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;charCodeAt从一个字符串中获得一个字符unicode number的特殊方法toExponential()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法是将number转换成string,参数为小数点后的几位1234var x = 9.656;x.toExponential(2); // returns 9.66e+0x.toExponential(4); // returns 9.6560e+0x.toExponential(6); // returns 9.656000e+0 toFixed()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法是将number转换成string,参数为该数的小数点后的位数，像数学里的四舍五入，但它是指定小数点后的位数12345var x = 9.656;x.toFixed(0); // returns 10x.toFixed(2); // returns 9.66x.toFixed(4); // returns 9.6560x.toFixed(6); // returns 9.656000 toPrecision()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该方法是将number转换成string,参数为该数的位数，像数学里的四舍五入，但它是指定数的位数12345var x = 9.656;x.toPrecision(); // returns 9.656x.toPrecision(2); // returns 9.7x.toPrecision(4); // returns 9.656x.toPrecision(6); // returns 9.65600 number中的类型转换&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;都是从第一位开始转换，若第一个字符串不是数字的则不能转换，返回NaN(Not-a-Number)123456789101112131415161718Number(\"12\") # 12parseFloat(\"12.5\") #12.5parseInt(\"12.5\") #12x = true; //在javaScript中 true为1，其他的数据都为falseNumber(x); // returns 1x = false; Number(x); // returns 0x = new Date();Number(x); // returns 1404568027739x = \"10\"Number(x); // returns 10x = \"10 20\"Number(x); // returns NaNx = \"10 test\";Number(x); // returns 10x = \"test 10\";Number(x) // returns NaN number的特殊几个类型 属性 结果 MAX_VALUE Returns the largest number possible in JavaScript MIN_VALUE Returns the smallest number possible in JavaScript NEGATIVE_INFINITY Represents negative infinity (returned on overflow) NaN Represents a “Not-a-Number” value POSITIVE_INFINITY Represents infinity (returned on overflow) Array三种方法判断是否是Array&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Array.isArray()判断某个变量是否是数组 true /false&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用关键判断instanceof (var instanceof Array)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自定义方法判断 123function isArray(x) &#123; return x.constructor.toString().indexOf(\"Array\") &gt; -1;&#125; 将Array的值转换成string1234567// toString()var fruits = [\"Banana\", \"Orange\", \"Apple\", \"Mango\"];document.getElementById(\"demo\").innerHTML = fruits.toString();//join()var fruits = [\"Banana\", \"Orange\", \"Apple\", \"Mango\"];document.getElementById(\"demo\").innerHTML = fruits.join(); pop()与push()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;javaScript中对array的操作像对队列一样，使用pop()与push()两种函数可以对数据进行操作","categories":[],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"https://chenadminchen.github.io/tags/javaScript/"},{"name":"function","slug":"function","permalink":"https://chenadminchen.github.io/tags/function/"}]},{"title":"linux mysql java time","slug":"linux-mysql-java-time","date":"2017-11-20T11:36:45.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/20/linux-mysql-java-time/","link":"","permalink":"https://chenadminchen.github.io/2017/11/20/linux-mysql-java-time/","excerpt":"","text":"linuxlinux查看当前系统时间1root@localhost# date 引用TZ包1root@localhost# export TZ #(TZ：time zone) linux tzselect的学习teselect的介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;teselect命令用于选择时区，但是tzselect只是帮助我们把选择的时区显示出来，并不会实际生效，也只是说我们按照它的提示去选择，结果只会告诉我们如何去设置环境变量TZ。如果要永久更改主时区，按照tzselect命令的信息,在.profile或者/etc/profile中设置正确的TZ环境变量。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@new55 ~]# tzselect Please identify a location so that time zone rules can be set correctly.Please select a continent or ocean. 1) Africa 2) Americas 3) Antarctica 4) Arctic Ocean 5) Asia 6) Atlantic Ocean 7) Australia 8) Europe 9) Indian Ocean10) Pacific Ocean11) none - I want to specify the time zone using the Posix TZ format.#? 5 Please select a country. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan#? 9 Please select one of the following time zone regions.1) east China - Beijing, Guangdong, Shanghai, etc.2) Heilongjiang (except Mohe), Jilin3) central China - Sichuan, Yunnan, Guangxi, Shaanxi, Guizhou, etc.4) most of Tibet &amp; Xinjiang5) west Tibet &amp; Xinjiang#? 1The following information has been given: China east China - Beijing, Guangdong, Shanghai, etc.Therefore TZ='Asia/Shanghai' will be used.Local time is now: Mon Dec 6 09:40:35 CST 2010.Universal Time is now: Mon Dec 6 01:40:35 UTC 2010.Is the above information OK?1) Yes2) No#? 1You can make this change permanent for yourself by appending the line TZ='Asia/Shanghai'; export TZ to the file '.profile' in your home directory; then log out and log in again.Here is that TZ value again, this time on standard output so that youcan use the /usr/bin/tzselect command in shell scripts:Asia/Shanghai 然后按照上面的选择后的结果 1TZ='Asia/Shanghai'; export TZ #在系统文件中将配置并生效 cd etc/sysconfig/clock使用zdump读取/etc/localtime1root@localhost# zdump -v /etc/localtime zoneinfo介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;zoneinfo另一种查看时间信息的方法，其代码如下： 123root@localhost# cd /usr/share/zoneinfo/root@localhost/usr/share/zoneinfo# ls #查看该文件中所有的信息root@localhost/usr/share/zoneinfo# cat PRC # 查看当前时间设置的信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如下配置的linux无法读取时间 export TZ=’GMT+8’ mysql12345678#查看当前时区show variables like 'time_zone';#查看mysql的时间配置信息show variables like '%time%'#重启服务器service mysql restart java时间123456789101112export TZ='GMT+8'#java 代码获得当前系统的时间import java.util.Date;import java.text.SimpleDateFormat;public class NowString &#123; public static void main(String[] args) &#123; SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");//设置日期格式 System.out.println(df.format(new Date()));// new Date()为获取当前系统时间 &#125;&#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://chenadminchen.github.io/tags/java/"},{"name":"mysql","slug":"mysql","permalink":"https://chenadminchen.github.io/tags/mysql/"},{"name":"linux","slug":"linux","permalink":"https://chenadminchen.github.io/tags/linux/"}]},{"title":"mongodb 安装","slug":"mongodb -install","date":"2017-11-18T14:51:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/18/mongodb -install/","link":"","permalink":"https://chenadminchen.github.io/2017/11/18/mongodb -install/","excerpt":"","text":"mongodb的下载（1）从官网地址上找到系统相应的安装文件，然后下载（2）安装运行 mongodb的安装(1)下载服务器，安装运行(2)自行创建存储数据的文件夹，一般用data\\db作名字(3)创建存储日志的文件 将mongodb做成window系统中内置的服务（1）用管理的身份运用命令行（2）将mongodb运行于window服务内，命令如下： 1mongod.exe --install --logpath D:\\data\\log.txt --serviceName mongodb （3)将启动mongodb服务 运行mongodb","categories":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/categories/mongodb/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/tags/mongodb/"},{"name":"未写完","slug":"未写完","permalink":"https://chenadminchen.github.io/tags/未写完/"}]},{"title":"mongodb aggregation 总结","slug":"mongodb-aggregation","date":"2017-11-18T08:58:34.000Z","updated":"2019-07-06T08:45:58.790Z","comments":true,"path":"2017/11/18/mongodb-aggregation/","link":"","permalink":"https://chenadminchen.github.io/2017/11/18/mongodb-aggregation/","excerpt":"","text":"Mongodb Aggregation Pipline介绍管道概念POSIX多线各的使用方式中，有一种很重要的方式—流水线（”管理”）方式，“数据元素”流串行地被一组线程按顺序执行。它的使用架构参考如图片：","categories":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/categories/mongodb/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://chenadminchen.github.io/tags/mongodb/"},{"name":"未写完","slug":"未写完","permalink":"https://chenadminchen.github.io/tags/未写完/"}]},{"title":"hexo搭建博客","slug":"hexo搭建博客","date":"2017-09-10T05:48:42.000Z","updated":"2019-11-07T11:49:00.256Z","comments":true,"path":"2017/09/10/hexo搭建博客/","link":"","permalink":"https://chenadminchen.github.io/2017/09/10/hexo搭建博客/","excerpt":"1.在github上新建项目：项目名称：github用户名称.github.ioexample: aloneSingingStar.github.io 注意:最好创建空项目，不带一个文件 2.本地新建目录1随意创建，我的是aloneSingingStar.github.io 3.进入aloneSingingStar.github.io目录，初始化hexo1hexo init","text":"1.在github上新建项目：项目名称：github用户名称.github.ioexample: aloneSingingStar.github.io 注意:最好创建空项目，不带一个文件 2.本地新建目录1随意创建，我的是aloneSingingStar.github.io 3.进入aloneSingingStar.github.io目录，初始化hexo1hexo init 4.安装依赖1npm install 5.安装博客部署插件1npm install hexo-deployer-git --save 6.配置_comfig.xml，设置部署分支为master1234deploy: type: git repository: git@github.com:aloneSingingStar/aloneSingingStar.github.io.git branch: master 7.将项目添加到github 初始化为git项目 1git init 添加该目录下的所有文件到本地仓库（会根据.ignore文件过滤） 1git add . 提交代码到本地仓库 1git commit -m ‘初始化hexo’ 关联本地仓库代码到远程仓库 1git remote add origin git@github.com:aloneSingingStar/aloneSingingStar.github.io.git 提交本地仓库代码到远程仓库 1git push -u origin master -f (必须加上-f,而且执行这句后，之前在github上的原有文件会丢失) 在github上创建项目时，里面有一个readme.md文件，而本地项目git init时，里面没有这个文件，当使用（git push -u origin master）把本地文件提交上，就会有如下问题：To github.com:aloneSingingStar/aloneSingingStar.github.io.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to &#39;git@github.com:aloneSingingStar/aloneSingingStar.github.io.git’hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: ‘git pull …’) before pushing again.hint: See the ‘Note about fast-forwards’ in ‘git push –help’ for details. 8.在本地和远程创建hexo分支,并且本地切换到hexo分支,并拉取代码 本地仓库创建hexo分支 1git checkout -b hexo 推送本地hexo分支到远程仓库 1git push origin hexo 从远程hexo分支拉取代码 1git pull origin hexo (从hexo分支拉取代码，git pull无效果，可以git branch –set-upstream-to=origin/hexo(跟踪hexo的流)，并且git branch –unset-upstream master(取消对master的跟踪)，这样的话，就可以直接执行git pull、git push直接提交代码到hexo分支) 9.启动本地服务器测试123hexo server访问 http://localhost:4000/ 预览效果 10.预览没有问题后，执行如下操作部署到github hexo clean hexo generate hexo deploy 访问http://aloneSingingStar.github.io 11.配置主题主题网址：主题网址我使用的是yilia,步骤如下： 1.使用ssh方式克隆项目到themes目录下的yilia目录git clone git@github.com:litten/hexo-theme-yilia.git themes/yilia 2.修改aloneSingingStar.github.io目录下的_config.yml中的主题theme:yilia 3.具体样式可以修改yilia目录下的_config.yml文件 12.配置百度统计（只能后台统计，无法前台展示） 注册百度统计站长版 注册成功后，会得到一段代码，其中有一段是：hm.src = “https://hm.baidu.com/hm.js?这里是你的唯一code;把code填写到yilia主题目录下的_config.yml中的 123# Miscellaneousbaidu_analytics: &apos;填写你的code&apos;google_analytics: false 百度统计网址 13.配置不蒜子，在网页显示访问量我修改的是/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/themes/yilia/layout/_partial/footer.ejs文件其中不蒜子我没有下载到本地，是直接引用的 参考的是这个人的配置（https://github.com/sssvip/blog-data/blob/master/themes/yilia/layout/_partial/footer.ejs） 14.提交hexo分支上的修改 1.git status 查看代码修改 ➜ /Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io git:(hexo) ✗ &gt;git statusOn branch hexoChanges to be committed: (use “git reset HEAD …” to unstage) modified: _config.yml modified: package.json new file: &quot;source/_posts/hexo\\346\\220\\255\\345\\273\\272\\345\\215\\232\\345\\256\\242.md&quot; Untracked files: (use “git add …” to include in what will be committed) themes/hexo-theme-spfk/ themes/next/ themes/yilia/ 2.可以看到，有2个modified,一个new file,还有未被加入本地仓库的文件夹，这3个文件夹是我下载的主题，其中我配置了一些私密信息，比如，百度统计的唯一code、支付宝、微信打赏图片等，我不想上传，如果你想上传，可以使用:[git add .]将所有这个文件夹下的文件提交到本地仓库 3.git commit -m “描述”如果这个文件已经提交到了远程仓库，本地做了修改，想再提交到远程仓库，如果只执行 git commit -m “描述” 是不行的，会报如下问题： ➜ /Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io git:(hexo) ✗ &gt;git commit -m “配置说明修改”On branch hexoChanges not staged for commit: modified: “source/_posts/hexo\\346\\220\\255\\345\\273\\272\\345\\215\\232\\345\\256\\242.md” Untracked files: themes/hexo-theme-spfk/ themes/next/ themes/yilia/ no changes added to commit 说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 git add 命令，然后再提交 4.如果修改了很多个文件，那么一个个的去[git add 被修改的文件],然后再提交，会很麻烦，所以可以先使用[git status],查看所有未提交的文件，然后把不想提交的文件或者文件夹在[.gitignore]文件中过滤掉，这样的话，就可以直接使用[git add .]将所有未提交的提交到本地仓库 5.git push origin hexo 6.git pull origin hexo 15.在博客的md文件中，加入截断标签如果没有加，一篇博客有多长，就展示多长，我们想要的效果是，在主页每篇博客只显示一部分，点击more后再进入详细页面 1.在需要截断的地方加入如下标签： 2.在/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/themes/yilia/_config.yml文件中，加入：excerpt_link: more 16 给文章设置tag,用于搜索每篇生成的博客都有如下格式：可添加多个tag title: hexo搭建博客date: 2017-09-10 13:48:42tags: tag1 tag2 tag3 17 绑定域名 1.购买域名，我购买的是阿里云的 2.域名解析：进入阿里云控制台，点击添加解析，【记录类型：A】【主机记录：@】【解析线路：默认】【记录值：ip(ping alonesingingstar.github.io得到的IP）】，然后保存即可注：记录类型:CNAME , 记录值:alonesingingstar.github.io 是不行的，因为alonesingingstar.github.io不是顶级域名，没有备案的 3.在alonesingingstar.github.io/source目录下新建CNAME文件，里面内容是你买的域名 4.重新部署，然后用你的域名访问网站，我的是：http://alonesingingstar.site 18 网站SEO优化方式一http://zhanzhang.baidu.com/college/articleinfo?id=1003 1.进入百度站长平台：http://zhanzhang.baidu.com/dashboard/index 2.点击添加站点，输入你购买的域名 3.勾选站点属性 4.验证网站，我选择的是【CNAME验证】,具体做法：在购买域名的网站（我的是阿里云）进行域名解析：点击添加解析，【记录类型：CNAME】【主机记录：C3bHznfyDD(这个值我乱写的，真实值按百度站长平台提供的来写)】【解析线路：默认】【记录值：zz.baidu.com(必须是这个，之前我写成了我自己的域名)】，然后保存即可 CNAME验证请将 C3bHznfyDD.alonesingingstar.site 使用CNAME解析到zz.baidu.com完成操作后请点击“完成验证”按钮。为保持验证通过的状态,成功验证后请不要删除该DNS记录 结果：不到一分钟前alonesingingstar.site使用CNAME验证验证失败，原因：没有找到对应的DNS CNAME记录。问题分析&amp;解决办法： 请检查dns域名指向是否正确，dns生效一般需要几分钟到1天左右，请耐心等待。 等待一段时间后： alonesingingstar.site验证成功！该网站为主站，您可以批量添加子站并查看数据，无需再次验证。帮助 5.打开百度，搜索 【site:你的域名】，看能不能搜索到 方式二进入百度统计的管理页面：https://tongji.baidu.com点击新增网站，【网站域名：你购买的域名】,其他随便填，然后你点击获取代码,找到如下代码：hm.src = “https://hm.baidu.com/hm.js?这里是你的唯一code;然后可参照上面 12.配置百度统计（只能后台统计，无法前台展示）的配置 结果：一直没有统计数据 可能原因：可能要等一段时间，待验证 19 生成网站地图 1.安装插件：npm i hexo-generator-sitemap hexo-generator-baidu-sitemap -S 2.配置根目录下的_config.yml sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml url: http://alonesingingstar.site/(你的网址)root: /permalink: :year/:month/:day/:title/permalink_defaults: 3.部署，部署后会生成sitemap.xml、baidusitemap.xml文件（这两者的区别在于 baidusitemap.xml 是百度搜索引擎的专用文件,另一个是通用） 20 向百度提交链接(在百度站长平台设置)http://zhanzhang.baidu.com/linksubmit/index 推送方式 1、主动推送：最为快速的提交方式，推荐您将站点当天新产出链接立即通过此方式推送给百度，以保证新链接可以及时被百度收录。 2、自动推送：最为便捷的提交方式，请将自动推送的JS代码部署在站点的每一个页面源代码中，部署代码的页面在每次被浏览时，链接会被自动推送给百度。可以与主动推送配合使用。 3、sitemap：您可以定期将网站链接放到sitemap中，然后将sitemap提交给百度。百度会周期性的抓取检查您提交的sitemap，对其中的链接进行处理，但收录速度慢于主动推送。 4、手动提交：一次性提交链接给百度，可以使用此种方式。 具体配置方式可以参考百度站长平台/网页抓取/链接提交 中 推送方式–主动推送 1.安装插件:npm i hexo-baidu-url-submit -S 2.根目录下配置_config.yml 1234567891011deploy:- type: git repository: git@github.com:aloneSingingStar/aloneSingingStar.github.io.git branch: master- type: baidu_url_submitter#主动提交链接到百度baidu_url_submit: count: 10 # 提交最新的链接数 host: alonesingingstar.site # 在百度站长平台中注册的域名,虽然官方推荐要带有 www, 但可以不带. token: 密钥值 # 你的秘钥,每个人都不一样,在百度站长平台/网页抓取/链接提交/自动提交/主动推送 下面可以找到 path: baidu_urls.txt # 文本文档的地址,新链接会保存在此文本文档里 3.重新部署，新的链接就会被推送上去部署成功可以看到控制台有如下信息： 123456INFO Deploying: baidu_url_submitterINFO Submitting urlshttp://alonesingingstar.site/2017/09/10/hexo搭建博客/http://alonesingingstar.site/2017/09/09/hello-world/&#123;&quot;remain&quot;:4999998,&quot;success&quot;:2&#125;INFO Deploy done: baidu_url_submitter 到百度站长/站点管理/网页抓取/链接提交 中并没有看到提交的链接，需要等一段时间（可能要一两天），然后使用site:你的域名，才能搜索到具体原因如下：http://tengj.top/2016/03/14/baidunoshouluresson/ 9/12 下午16:29，使用百度搜索：site:alonesingingstar.site，已经可以搜索到了 21 向谷歌提交链接具体步骤：进入谷歌站长页面（https://www.google.com/webmasters/，用你的谷歌账户登录，然后点击添加属性，输入你的网址）1.下载HTML验证文件（在内容中加入layout: false,网上说hexo会编译这个文件，设置这个不让它编译）2.将该文件放到/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/source目录下。3.重新部署网站4.通过在浏览器中访问 http://alonesingingstar.site/google2f21809f4cc6b2ea.html 确认上传成功。6.点击验证7.进入谷歌的Search Console，点击站点地图/添加站点地图,比如我的是http://alonesingingstar.site/sitemap.xml,添加后就能抓取到结果：您无权使用此资源。请验证此资源，或请资源所有者将您添加为用户，要等一段时间等一段时间后：恭喜！您已成功验证您对 http://alonesingingstar.site/ 网站的所有权。继续 使用谷歌搜索：site:alonesingingstar.site，暂时还搜索不到，先等吧 进入站长页面的Search Console，点击Google抓取工具，点击抓取，一定要请求将网址和链接页编入索引，然后使用site:alonesingingstar.site搜索，就能搜索到了 22.提升排名 博客根目录 _config.yml 文件进行如下修改，关键字英文逗号隔开： 12345678# Sitetitle: 网站名称description: 网站描述author: 作者姓名subtitle: 作者简介language: zh-CNtimezone:keywords: Web,HTML # 博客关键字 文章中加入关键字 12345678---title: ###date: ###categories: ###tags: ###keywords: ###description: ###--- 文章路径简化 12Hexo 默认的文章链接形式为 domain/year/month/day/postname，默认就是一个四级 url，并且可能造成 url 过长，对搜索引擎是十分不友好的。我们可以改成 domain/postname 的形式。编辑站点 _config.yml 文件，修改其中的 permalink 字段改为:permalink: :title.html 23 加入友言评论系统 1.注册账号：http://www.uyan.cc/ 2.注册成功后，可以看到一段代码，复制下来，在/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/themes/yilia/layout/_partial/post下新建uyan.ejs文件,将内容粘贴进去 3.找到/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/themes/yilia/layout/_partial/article.ejs文件，找到【&lt;% if (!index &amp;&amp; post.comments){ %&gt;】这行代码,在后面加入：【&lt;% if (theme.uyan){ %&gt;&lt;%- partial(‘post/uyan’, {key: post.slug,title: post.title,url: config.url+url_for(post.path)}) %&gt;&lt;% } %&gt; 】 4.进入后台管理，可以看到你的用户ID，复制这个ID，然后在/Users/aloneSingingStar/xyb/blog/aloneSingingStar.github.io/themes/yilia/_config.yml中加入：uyan: ‘你的ID’ 5.重新部署 24 博客中引用图片 1._config.xml中开启文章资源文件夹 1post_asset_folder: true 2.每次执行 hexo new “文章名字” 生成md文件时，会在同级生成”文章名字”文件夹,将资源放入该文件夹即可 3.引用方式 12345678910111213&#123;% asset_img 资源名称 描述 %&#125;比如：&#123;% asset_img example.jpg This is an example image %&#125;上面这种方式在网页端访问没有问题，但是手机RSS订阅会有问题，上面那种写法，atom.xml中显示为&lt;img src=&quot;/Tigase开发-Tigase服务器搭建/serverConfiguration.gif&quot;&gt;,根本无法访问该链接，可以使用如下方式访问：![ServerConfguration](http://alonesingingstar.site/Tigase开发-Tigase服务器搭建/serverConfiguration.gif)或者：&#123;% img http://alonesingingstar.site/Tigase开发-Tigase服务器搭建/serverConfiguration.gif %&#125; 4.修改node_modules/hexo/lib/models/post_asset.js文件将如下代码进行修改 123456789PostAsset.virtual(&apos;path&apos;).get(function() &#123; var Post = ctx.model(&apos;Post&apos;); var post = Post.findById(this.post); if (!post) return; // PostAsset.path is file path relative to `public_dir` // no need to urlescape, #1562 return pathFn.join(post.path, this.slug); &#125;); 改为：123456789101112131415PostAsset.virtual(&apos;path&apos;).get(function() &#123; var Post = ctx.model(&apos;Post&apos;); var post = Post.findById(this.post); if (!post) return; // PostAsset.path is file path relative to `public_dir` // no need to urlescape, #1562 //如果生成的文章路径是以html结尾的, 如: 2016/10/13/byte-order.html, // 则对应的资源路径应该是: 2016/10/13/byte-order + this.slug var reg = new RegExp(&quot;html&quot; + &quot;$&quot;); if(reg.test(post.path)) &#123; var assetPath = post.path.substr(0, post.path.lastIndexOf(&quot;.&quot;)); return pathFn.join(assetPath, this.slug); &#125; return pathFn.join(post.path, this.slug); &#125;); 如果不改，执行hexo generate时会报错：Error: ENOTDIR: not a directory 参考(https://leokongwq.github.io/2016/10/14/hexo-post-asset-folder-html.html)","categories":[{"name":"hexo","slug":"hexo","permalink":"https://chenadminchen.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://chenadminchen.github.io/tags/hexo/"}]}]}